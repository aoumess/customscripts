#..............#
#### HEADER ####
#..............#

##  This is a collection of functions to perform various RNA expression analyses
##  . Differential expression
##    . DEA testing for simple and complex designs [DESeq2]
##    . QC plots (M-A, p-value distribution, sample boxplot, PCA, ...)
##    . Results plot (volcano, feature boxplot, expression heatmap, ...)
##  . GSEA/ORA analysis [clusterProfiler]
##  . Immune deconvolution [immunedeconv]
##  . GSVA [GSVA]
##  . Clustering
##    . Hierarchical
##    . skmeans [skmeans]
##    . NMF [NMF]
##  Tested on R v4.3.2
##  PACKAGES :
##  . REQUIRED :
##    . CRAN : 'tidyverse' [1.3.0], 'ggnewscale' [0.4.5], 'vroom' [1.4.0], rsvg
##    . Bioconductor : 'clusterProfiler' [3.18.1] (will import other required packages as dependencies, like 'DOSE' and 'enrichplot'), 'org.Xx.eg.db' (species-specific, like 'org.Hs.eg.db' [3.12.0])
##  . SUGGESTED :
##    . Bioconductor : 'msigdbr' [7.2.1] (to assess MSigDB databases), 'meshes' [1.16.0] (to assess MeSH databases), 'MeSH.Xxx.eg.db' (species-specific, like 'MeSH.Hsa.eg.db' [1.15.0], required to query MeSH databases), 'pathview' [1.30.1] (to plot KEGG pathways if 'clusterProfiler::enrichKEGG' or 'clusterProfiler::gseKEGG' functions are used)


#...................#
#### DEPENDENCES ####
#...................#

## Handling needed packages
cran_list <- c('BiocManager', 'stringr', 'BiocParallel', 'matrixStats', 'circlize', 'BiocParallel', 'ggplot2', 'amap', 'knitr', 'readxl', 'writexl', 'randomcoloR', 'data.table', 'RColorBrewer', 'EnvStats', 'openxlsx', 'purrr', 'coop', 'rsvg')
for (pkgn in sort(unique(cran_list))) if(! pkgn %in% installed.packages()) install.packages(pkgn)

bioc_list <- c('DESeq2', 'ComplexHeatmap', 'IHW', 'limma', 'msigdbr', 'clusterProfiler', 'ReactomePA', 'meshes', 'GSVA', 'ReactomePA', 'meshes', 'pathview')
for (pkgn in sort(unique(bioc_list))) if(! pkgn %in% installed.packages()) install.packages(pkgn)

gith_list <- list('omnideconv' = 'omnideconv/immunedeconv')
for (pkgn in sort(unique(names(gith_list)))) if(! pkgn %in% installed.packages()) remotes::install_github(gith_list[[pkgn]])

#.................#
# SOURCES ####
#.................#

## Functions to write plots to SVG that automatically generates a PNG too.
source_files <- c('svg_png.R')
source_remote_dir <- 'https://github.com/aoumess/customscripts/raw/refs/heads/main/R'
source_local_dir <- '/home/job/gits/customscripts/R'
for (sf in source_files) {
  try_sf <- try(source(paste(c(source_remote_dir, sf), collapse = '/')), silent = TRUE)
  if (is(try_sf, class2 = 'try-error')) {
    try_sf <- try(source(paste(c(source_local_dir, sf), collapse = '/')), silent = TRUE)
    if (is(try_sf, class2 = 'try-error')) {
      stop(paste0('Could not source script [', sf, '] (remotely nor localy'))
    }
  }
}


#.................#
# FUNCTIONS ####
#.................#

## . I/O ====

## Read the "Raw.genes.tsv(.gz)" output matrix generated by the bulk RNAseq pipeline ====
## output_feature_type can be 'default' (first column) or 'symbol' (will look for a 'Hugo_ID' column)
read_pipeline_matrix <- function(file = NULL, output_feature_type = 'Symbol') {
  ## Checks
  if (is.null(file)) stop('Input files are required !')
  if (!file.exists(file)) stop('Provided file does not exist !')
  
  ## Load file
  datal <- read.table(file = file, header = TRUE, sep = '\t', na.strings = 'NA', check.names = FALSE, as.is = TRUE)
  
  ## Check the presence of the symbol column if requested
  if (tolower(output_feature_type) == 'symbol') {
    if (! 'Hugo_ID' %in% colnames(datal)) stop('Requested output feature type is SYMBOL, but no Hugo_ID column found !')
    datal <- datal[!datal$Hugo_ID == 'Unknown',]
    rowc <- matrixStats::rowCounts(x = as.matrix(datal[,-c(1, which(colnames(datal) == 'Hugo_ID'))]), value = 0)
    ## Remove replicated symbols (keeping the most expressed)
    symbtbl <- table(datal$Hugo_ID)
    dupsymb <- names(symbtbl[symbtbl > 1])
    for (dp in dupsymb) {
      dp_rowc <- rowc[datal$Hugo_ID == dp]
      # print(dp_rowc)
      dp_torem <- names(dp_rowc)[-which.min(dp_rowc)[1]]
      datal <- datal[!rownames(datal) %in% dp_torem,]
      rowc <- rowc[!names(rowc) %in% dp_torem]
    }
    ret_mat <- as.matrix(datal[,-c(1, which(colnames(datal) == 'Hugo_ID'))])
    rownames(ret_mat) <- datal$Hugo_ID
  } else {
    ret_mat <- as.matrix(datal[,-c(1, which(colnames(datal) == 'Hugo_ID'))])
    rownames(ret_mat) <- datal[,1]
  }
  ret_mat <- round(ret_mat)
  ret_mat <- ret_mat[,order(colnames(ret_mat))]
  return(ret_mat)
}

## Load one or multiple GeoMX DSP xlsx output file (at the background correction step) ====
## This file should contain at least the 'SegmentProperties' panel (which contain QC metrics at the ROI/AOI level), the 'TargetCountMatrix' panel (which contains background-corrected raw counts) and the 'Dataset summary' panel (which exhibits which data QC/modifications were performed in DSP).
## All 3 tables are extracted for each provided path
## . geomx_files      [vec(char)]       Path(s) to the DSP xlsx file(s)
## . split_qcflags    [logical]         If QC multiple flags are found, split them to multiple new columns
## . qcflags_colname  [char]            Name of the column to find QC flags
## . batch_colname    [char]            How to name the batch column (created when multiple geomx_files are provided)
## . add_aoilabel     [logical]         When repeated ROI labels are found for a same slide, create the AOILabel column
geomx_xlsx_parser <- function(geomx_files = NULL, split_qcflags = TRUE, qcflags_colname = 'QCFlags', batch_colname = 'Batch', add_aoilabel = TRUE) {
  ## Check params
  if (is.null(geomx_files)) stop('At least one input files is required !')
  if (!is.logical(split_qcflags)) stop('The "split_qcflags" parameter should be logical !')
  if (!is.character(batch_colname)) stop('The output batch column name should be a character !')
  ## Check files
  if (!all(vapply(geomx_files, file.exists, TRUE))) stop('At least one of the provided GeoMX input file(s) do(es) not exist !')
  
  panel.names <- c('SegmentProperties', 'TargetCountMatrix', 'Dataset summary')
  
  ## SegmentProperties
  ### Reading the panel
  sp_list <- lapply(geomx_files, function(xl) { as.data.frame(readxl::read_excel(path = xl, sheet = panel.names[1], na = c('', 'na', 'NA'), trim_ws = TRUE, progress = FALSE)) })
  ## Check repeted ROI levels
  if (add_aoilabel) {
    for (xl in seq_along(geomx_files)) {
      slidenames <- unique(sp_list[[xl]][['SlideName']])
      repcheck <- any(sapply(unique(sp_list[[xl]][['SlideName']]), function(x) { any(duplicated(sp_list[[xl]][sp_list[[xl]][['SlideName']] == x,'ROILabel'])) }))
      if(!repcheck) {
        message('No replicated ROI found in ROILabel, so no addition of AOILabel.')
      } else {
        sp_list[[xl]][['AOILabel']] <- ''
        for (sn in slidenames) {
          snidx <- which(sp_list[[xl]][['SlideName']] == sn)
          sp_list[[xl]][['AOILabel']][snidx] <- sprintf("%03i", seq.int(1,length(snidx)))
        }
      }
    }
  }
  ### Adding the batch number
  for (xl in seq_along(geomx_files)) sp_list[[xl]][[batch_colname]] <- xl
  ### Merging (WARNING, the files may have different column amount and names !)
  sp_df <- Reduce(f = function(x,y) merge(x, y, all = TRUE), sp_list)
  ## Re-sorting
  if ('AOILabel' %in% colnames(sp_df)) sort_col <- 'AOILabel' else 'ROILabel'
  sp_df <- sp_df[order(sp_df[['SlideName']], sp_df[[sort_col]]),]
  rm(sp_list)
  ### Splitting QC flags when requested
  if (split_qcflags) {
    flags.list <- lapply(sp_df[[qcflags_colname]], function(x) { unlist(strsplit(x = x, split = ',')) })
    cur.flags <- sort(unique(unlist(flags.list)))
    if (length(cur.flags) == 0) {
      message('No QC flag to merge !')
    } else {
      for (fl in cur.flags) {
        fl2 <- paste(c('QC', unlist(strsplit(x = fl, split = '\\s+', fixed = FALSE))), collapse = '_')
        sp_df[[fl2]] <- vapply(flags.list, function(x) fl %in% x, TRUE)
        rm(fl2)
      }
      rm(flags.list)
    }
  }
  
  ## TargetCountMatrix
  ### Reading the panel
  tc_list <- lapply(geomx_files, function(xl) { as.data.frame(readxl::read_excel(path = xl, sheet = panel.names[2], na = c('', 'na', 'NA'), trim_ws = TRUE, progress = FALSE)) })
  ### Merging 
  tc_df <- Reduce(function(x,y) { y[['TargetName']] <- NULL; cbind(x, y) }, tc_list)
  rm(tc_list)
  tc_mat <- as.matrix(x = tc_df[,-1])
  dimnames(tc_mat) <- list(tc_df$TargetName, colnames(tc_df)[-1])
  rm(tc_df)
  
  ## Dataset summary
  ### Read the panel
  ds_list <- lapply(geomx_files, function(xl) { as.data.frame(readxl::read_excel(path = xl, sheet = panel.names[3], na = c('', 'na', 'NA'), trim_ws = TRUE, progress = FALSE, col_names = c('Key', 'Value'))) })
  names(ds_list) <- geomx_files
  
  ## Return list
  out.list <- list(sp_df, tc_mat, ds_list)
  names(out.list) <- panel.names
  rm(sp_df, tc_mat, ds_list)
  return(out.list)
  
}

## Import HTG expression table(s) ====
htgxls_import <- function(xls.files = NULL, n.samples = c(24), samplenames.row = c(10), data.startline = c(12)) {
  if (length(xls.files) > 1) {
    if (length(n.samples) == 1) n.samples <- rep(n.samples, length(xls.files))
    if (length(samplenames.row) == 1) samplenames.row <- rep(samplenames.row, length(xls.files))
    if (length(data.startline) == 1) data.startline <- rep(data.startline, length(xls.files))
  }
  ## Import file(s)
  xlz <- sapply(seq_along(xls.files), function(x) { .xl2htg(xls.file = xls.files[x], samplenames.row = samplenames.row[x], n.samples = n.samples[x], data.startline = data.startline[x]) }, simplify = FALSE)
  
  ## Formatting
  `%>%` <- dplyr::`%>%`
  xlz2 <- xlz %>% purrr::map(tibble::rownames_to_column) %>% purrr::reduce(dplyr::left_join, by = "rowname")
  xlz2 <- as.data.frame(xlz2, row.names = rownames(xlz[[1]]))
  rm(xlz)
  rownames(xlz2) <- xlz2[,1]
  return(as.matrix(xlz2[,-1]))
}

## Internal function to read a single HTG MS Excel file
.xl2htg <- function(xls.file = NULL, n.samples = 24, samplenames.row = 10, data.startline = 12) {
  message('Reading [', xls.file, '] ...')
  rowmax <- suppressMessages(nrow(readxl::read_excel(path = xls.file, sheet = 1, progress = FALSE)))
  last.col <- letters[n.samples + 1]
  xl.title <- suppressMessages(unlist(readxl::read_excel(path = xls.file, sheet = 1, range = paste0('B', samplenames.row, ':', last.col, samplenames.row), col_names = FALSE, progress = FALSE)))
  xl.gnames <- suppressMessages(unlist(readxl::read_excel(path = xls.file, sheet = 1, range = paste0('A', data.startline, ':A', rowmax), col_names = FALSE, progress = FALSE)))
  xl.df <- suppressMessages(readxl::read_excel(path = xls.file, sheet = 1, range = paste0('B', data.startline, ':', last.col, rowmax), col_names = FALSE, progress = FALSE))
  dimnames(xl.df) <- list(xl.gnames, xl.title)
  return(xl.df)
}



## . Graphics ====

## Generate a vetor of distinctive colors ====
distinct_color_maker <- function(n_colors = 10, my_seed = 1337, ...) {
  set.seed(my_seed)
  cvec <- randomcoloR::distinctColorPalette(k = n_colors, ...)
  return(cvec)
}

## Wrapper for boxplots with stripchart, except for outliers [LIST VERSION] ====
boxplot2l <- function(x = list(), col = 'lightgray', fill = NULL, main = 'boxplot2', xlab = '', ylab = 'Y', vertical = TRUE, ylim = NULL, cex = 1, line.type = 'medsd') {
  x.meds <- sapply(x, function(i) { median(i, na.rm = TRUE) })
  glob.med <- median(unlist(x), na.rm = TRUE)
  glob.sd <- sd(unlist(x), na.rm = TRUE)
  x.Q1 <- sapply(x, function(i) { quantile(x = i, probs = .25, na.rm = TRUE) })
  x.Q3 <- sapply(x, function(i) { quantile(x = i, probs = .75, na.rm = TRUE) })
  x.IQR <- x.Q3 - x.Q1
  x.len <- sapply(x, length)
  x.noO <- lapply(seq_along(x), function(i) { x[[i]][x[[i]] >= (x.Q1[i] - (1.5 * x.IQR[i])) &  (x[[i]] <= x.Q3[i] + (1.5 * x.IQR[i]))] })
  names(x.noO) <- names(x)
  ## Setting ylim
  if (is.null(ylim)) ylim = range(unlist(x), na.rm = TRUE)
  marb <- round(max(nchar(names(x)))*.75)
  par(mar=c(marb, 4, 2, 2) + 0.1)
  boxplot(x = x, col = fill, border = col, main = paste0(main, ' (', sum(x.len), ')'), ylab = ylab, names = NA, lwd = 2, ylim = ylim, pch = 20, cex = cex)
  stripchart(x = x.noO, method = 'jitter', vertical = vertical, add = TRUE, col = col, pch = 20, cex = cex)
  if(!is.null(line.type)) { if(line.type == 'medsd') abline(h = glob.med + c(0, glob.sd, -glob.sd), col = 2, lty = c(2,3,3), lwd = 2) else if(line.type == 'quantiles') abline(h = c(x.Q1, x.Q3), col = 2, lty = c(3,3), lwd = 2)
  }
  axis(1, at=1:length(x), labels=paste0(names(x), ' (', x.len, ')'), las = 2)
}

## Draws boxplots from a matrix with custom ordering/coloring from a factor annotation in a df ====
### WARNING : x and annot_df must be synched !
categ.boxplot <- function(x = NULL, annot_df = annot_df, col_item = 'Batch', title = "Boxplot", y_lab = "Y label", my_seed = 1337) {
  if (!is.matrix(x)) stop('x must be a matrix !')
  if (!is.data.frame(annot_df)) stop ('annot_df must be a data.frame !')
  if (! col_item %in% colnames(annot_df)) stop ('There is no [', col_item, '] column in annot_df !')
  annot_vec <- as.factor(annot_df[[col_item]])
  medz <- matrixStats::colMedians(x, na.rm = TRUE)
  ord_annot <- order(annot_vec, medz, decreasing = c(FALSE, TRUE))
  col_pal <- distinct_color_maker(n_colors = max(as.numeric(annot_vec), na.rm = TRUE))
  nblocks = ceiling(sqrt(length(col_pal)))
  ori_par <- par(no.readonly = TRUE)
  par(xaxs = 'i')
  boxplot(x[, ord_annot], col = col_pal[as.numeric(annot_vec[ord_annot])], main = title, xaxt = "n", xlab = "Samples", ylab = y_lab)
  legend('topleft', legend = unique(annot_vec[ord_annot]), text.col = col_pal, cex = 1, title.col = 1, title.cex = 1, y.intersp = .75, ncol = nblocks, x.intersp = 0, text.font = 2)
  par(ori_par)
}

## Barplot for immunedeconv results ====
immunedeconv_barplot <- function(id_res = NULL, title = 'ImmuneDeconv') {
  id_plotdata <- tidyr::gather(data = id_res, key = sample, value = fraction, -cell_type)
  id_plot <- ggplot2::ggplot(data = id_plotdata, mapping = ggplot2::aes(x = sample, y = fraction, fill = cell_type)) + ggplot2::geom_bar(stat = "identity") + ggplot2::coord_flip() + ggplot2::scale_fill_manual(values = colorRampPalette(RColorBrewer::brewer.pal(name = "Set1", n = 8))(nrow(id_res))) + ggplot2::scale_x_discrete(limits = rev(levels(id_res))) + ggplot2::ggtitle(title)
  print(id_plot)
}

## . Maths ====

## Get medoids of a vector ====
get_medoid <- function(x = NULL, split = NULL) {
  split[is.na(split)] <- "NA"
  xsplit <- split(x, as.factor(split))
  xmed <- vapply(X = xsplit, function(y) { median(y, na.rm = TRUE)}, .1)
  return(xmed)
}

## Computes sparsity of a (int) matrix (globally, per-column, per-line) ====
matrix_sparsity <- function(mat = NULL) {
  sparse_list <- list(
    ## Global sparsity
    global = coop::sparsity(x = mat),
    ## Per-sample
    columns = matrixStats::colCounts(x = mat, value = 0) / nrow(mat),
    ## Per-feature
    rows = matrixStats::rowCounts(x = mat, value = 0) / ncol(mat)
  )
  return(sparse_list)
}


## . Data acquisition ====

## Get the list of msigdbr available collections ====
get_msigdbr_collections <- function() {
  return(as.data.frame(msigdbr::msigdbr_collections()))
}

## Get KEGG GMT ====
get_kegg_gmt <- function(org = 'hsa', gmt_file = NULL, gene_id_type = 'ENTREZID', return_gmt = TRUE) {
  kegg_gmt <- EnrichmentBrowser::getGenesets(org = 'hsa', db = 'kegg', cache = FALSE, gene.id.type = gene_id_type)
  if(!is.null(gmt_file)) EnrichmentBrowser::writeGMT(gs = kegg_gmt, gmt.file = gmt_file)
  if(!is.null(return_gmt)) return(kegg_gmt)
}

## Convert GMT entries (symbols to Entrez, inversely)
gmt_convert <- function(gmt_file_in = NULL, gmt_file_out = NULL, gene_type_in = 'SYMBOL', gene_type_out = 'ENTREZID', species = 'Homo sapiens') {
  if(is.null(gmt_file_in)) stop('An input GMT file is required !')
  if(!file.exists(gmt_file_in)) stop('Input GMT not found !')
  if(is.null(gmt_file_out)) stop('An output GMT file is required !')
  
  good_types <- c('ENTREZID', 'SYMBOL', 'ENSEMBL')
  if (!gene_type_in %in% good_types) stop('Input gene type is not valid !')
  if (!gene_type_out %in% good_types) stop('Output gene type is not valid !')
  
  ## Read GMT
  in_gmt <- clusterProfiler::read.gmt(gmtfile = gmt_file_in)
  
  ## Get conversion df from bitr
  gmult <- as.data.frame(base::as.list(clusterProfiler::bitr(unique(in_gmt$gene), fromType = toupper(gene_type_in), toType = toupper(gene_type_out), OrgDb = paste0(msigdbr2org(species), '.db'))))
  ## Filter multi-hits
  gmult <- gmult[Biobase::isUnique(gmult[[gene_type_in]]) & Biobase::isUnique(gmult[[gene_type_out]]),]
  ## Set conversion vector
  gconv <- setNames(object = gmult[[gene_type_out]], nm = gmult[[gene_type_in]])
  ## Restrict input gmt to convertible genes
  in_gmt <- in_gmt[in_gmt$gene %in% names(gconv),]
  ## Convert
  in_gmt$gene <- gconv[in_gmt$gene]
  ## Remove levels if some terms are not covered anymore
  in_gmt$term <- droplevels(in_gmt$term)
  
  ## Write converted GMT
  out_gmt <- lapply(levels(in_gmt$term), function(x) {
    in_gmt$gene[in_gmt$term == x]
  })
  names(out_gmt) <- levels(in_gmt$term)
  EnrichmentBrowser::writeGMT(gs = out_gmt, gmt.file = gzfile(gmt_file_out))
}


## . Data transformation ====

## Convert raw intensities/counts to log (custom base) with an added epsilon (by exemple : counts to log10(counts+1)) ====
raw2log <- function(x = NULL, log_base = 10, epsilon = 1) {
  if (!is.matrix(x)) stop ('x must be a matrix !')
  return(log( x + epsilon ) / log(log_base))
}

## Load a MSigDb bank from msigdbr and generate the term2table ====
### . 'species' : character ; a species name, as in the 'species_name' column of msigdbr::msigdbr_species()
### . 'category' : character ; an MSigDB category, as in the 'gs_cat' column of msigdbr::msigdbr_collections()
### . 'subcategory' : character ; an MSigDB category, as in the 'gs_subcat' column of msigdbr::msigdbr_collections()
msigdb_to_t2g <- function(species = 'Homo sapiens', category = NULL, subcategory = NULL) {
  ## Checking species
  valid.species <- msigdbr::msigdbr_species()
  if (!species %in% valid.species$species_name) stop(paste0("Unsupported species. Expecting any of '", paste(valid.species$species_name, collapse = "', '"), "'. See ?msigdbr::msigdbr"))
  ## Getting the bank data
  message(paste0('Loading MSigDB data for ', category, ' ', subcategory))
  msigdb <- msigdbr::msigdbr(species = species, category = category, subcategory = subcategory)
  ## Generating the output table
  t2g <- data.frame(term = as.factor(msigdb$gs_name), gene = as.character(msigdb$entrez_gene), stringsAsFactors = FALSE)
  return(t2g)
}


## Load a custom .gmt bank from file and generate the term2table ====
### . 'gmt_file' : character ; complete path to a GMT file
gmt_to_t2g <- function(gmt_file = NULL) {
  ## Checking gmt
  if (!file.exists(gmt_file)) stop('A GMT file is required !')
  t2g <- clusterProfiler::read.gmt(gmtfile = gmt_file)
  # t2g$term <- as.character(t2g$term)
  return(t2g)
}



## Convert species name (SPECIES, ORGANISM, TAXID) ===
### Input is an OrgDb object
### Supported types (from, to) = 'SPECIES', 'ORGANISM, 'TAXID'
convert_species_name <- function(OrgDb = NULL, from = 'SPECIES', to = 'ORGANISM') {
  if (is.null(OrgDb)) stop('OrgDb is required !')
  if (!'OrgDb' %in% is(OrgDb)) stop('OrgDb should be an OrgDb object (see AnnotationDbi::AnnotationDb) !')
  if (from == to) stop("Parameters 'from' and 'to' are the same !")
  org.meta <- metadata(OrgDb)
  if (!all(c(from, to) %in% org.meta$name)) stop("Provided 'from' and 'to' parameters should be metadata of 'OrgDb' !")
  return(org.meta[org.meta$name == from,]$value)
}

## Convert [msigdbr] species name to [AnnotationForge] ====
## FUNCTION TO CONVERT AN msigdbr SPECIES NAME TO AN AnnotationForge ORGANISM PACKAGE ROOTNAME (ie, the package name without the '.db' suffix)
### . 'species' : character ; a species name, as in the 'species_name' column of msigdbr::msigdbr_species()
### NOTE1 : This converter should work with all available species in msigdbr, with the exception of saccharomyces cerevisiae (which does not have 'eg' in its organism name)
### NOTE 2 : See MSigDB collections description here : http://www.gsea-msigdb.org/gsea/msigdb/collections.jsp
msigdbr2org <- function(species = NULL) {
  return(paste0('org.', paste0(stringr::str_sub(unlist(base::strsplit(species, ' ')), 1, 1), collapse = ''), '.eg'))
}


## Create input objects for gsea_run() and ora_run() from an output of our rna-salmon-deseq2 pipeline ====
### . 'deseq2.res.data' : data.frame ; output table from the rna-salmon-deseq2 pipeline
### . 'species' : character ; species name (Homo sapiens, Mus musculus, etc ...)
### . 'geneid.colname' : character ; column name in 'deseq2.res.file' input for the gene identifier.
### . 'geneid.type' : character ; type of gene identifier. Should be one value of the output of clusterProfiler::idType("org.Xx.eg.db") (with 'Xx' corresponding as the species of interest). Usually 'SYMBOL' or 'ENSEMBL'.
### . 'stat.colname' : character ; column name in 'deseq2.res.file' input for the (numeric/integer) values to use in GSEA (ie, logFoldChange).
### . 'topN.max' : integer ; maximum number of significant genes to keep for ORA (may be inferior if fewer genes were found as differentially expressed)
### . 'p.colname' : character ; column name in 'deseq2.res.file' input to use to order the table before selecting the 'topN' genes for ORA.
### . 'p.cutoff' : numeric ; cutoff to use to select 'topN' genes on 'p.colname' when there are less significant genes than 'topN'.
### . 'stat.keep.operator' : character ; operator (given as a character) to keep genes when evaluating their 'p.colname' value to 'p.cutoff' (usually one of '<', '<=', '>', '>=').
### . '...' : any parameter to read.table() to handle the input file (usually 'sep = "\t", header = TRUE, as.is = TRUE')
table2enr <- function(deseq2.res.data = NULL, species = "Homo sapiens", geneid.colname = 'Gene_Name', geneid.type = 'SYMBOL', stat.colname = 'stat_change', stat.keep.operator = '>', stat.cutoff = 0, stat.abs = TRUE, topN.max = 100, p.colname = 'Adjusted_PValue', p.cutoff = 5E-02) {
  ## Checks
  ## Loading the DE table
  deres <- deseq2.res.data
  ## Forcing gene ID to be a character
  deres[[geneid.colname]] <- as.character(deres[[geneid.colname]])
  ## Converting non-Entrez IDs to Entrez IDs
  if (geneid.type != 'ENTREZID') {
    ## Building the gene ID conversion vector
    gconv <- base::as.list(clusterProfiler::bitr(deres[[geneid.colname]], fromType = geneid.type, toType = 'ENTREZID', OrgDb = paste0(msigdbr2org(species), '.db')))
    names(gconv$ENTREZID) <- gconv[[geneid.type]]
    names(gconv[[geneid.type]]) <- gconv$ENTREZID
    deres$ENTREZID <- gconv$ENTREZID[as.character(deres[[geneid.colname]])]
  } else {
    gconv <- list(ENTREZID = setNames(deres$ENTREZID, deres$ENTREZID))
    deres$ENTREZID <- deres[[geneid.colname]]
  }
  ## Removing entries without EntrezID
  na.entrez <- is.na(deres$ENTREZID)
  deres <- deres[!na.entrez,]
  message(paste0('Removed ', length(which(na.entrez)), ' lines without EntrezID value.'))
  ## Removing entries with duplicated EntrezID
  dup.entrez.names <- unique(deres$ENTREZID[duplicated(deres$ENTREZID)])
  dup.entrez <- deres$ENTREZID %in% dup.entrez.names
  deres <- deres[!dup.entrez,]
  message(paste0('Removed ', length(which(dup.entrez)), ' lines (', length(dup.entrez.names), ' genes) with replicated EntrezID value.'))
  ## Formatted input
  ## GSEA
  gsea.genevec <- sort(setNames(deres[[stat.colname]], deres$ENTREZID), decreasing = TRUE)
  ## ORA
  if (!is.null(topN.max)) {
    deres2 <- deres[!is.na(deres[[p.colname]]) & !is.na(deres[[stat.colname]]),]
    if (stat.abs) {
      deres2$abs <- abs(deres2[[stat.colname]])
      stat.colname <- 'abs'
    }
    deres2 <- deres2[deres2[[p.colname]] < p.cutoff & eval(parse(text = paste0('deres2[["', stat.colname, '"]] ', stat.keep.operator, ' stat.cutoff'))),,drop = FALSE]
    top.keep <- min(nrow(deres2), topN.max)
    ora.genevec <- if(top.keep > 0) setNames(deres2$ENTREZID[1:top.keep], deres2[[geneid.colname]][1:top.keep]) else c()
  } else ora.genevec <- NULL
  
  return(list(gsea.genevec = gsea.genevec,
              ora.genevec = ora.genevec,
              gene2Symbol = gconv$ENTREZID))
}

## Wrapper to table2enr that takes as input the results file (the *_complete.tsv table) from our salmon+DESeq2 pipeline (by Thibault Dayris) ====
## ... = any parameter for table2enr()
pipe2enr <- function(deseq2.res.file = NULL, ...) {
  ## Checks
  ## Loading the DE table
  deres <- read.table(file = deseq2.res.file, header = TRUE, sep = "\t", quote = '', as.is = TRUE)
  ## Launching table2enr()
  table2enr(deseq2.res.data = deres, ...)
}


## Normalize a RAW COUNTS DEseq2 object (DESeqDataSet) with vst, return the normalized counts matrix ====
## Extra parameters (...) are passed to DESeq2::vst()
## Requires DESeq2 and clusterProfiler packages# source('/home/job/gits/customscripts/R/diffexp2gsea.R')
DE2obj_to_norm_matrix <- function(DE2obj = NULL, feature_in = 'ENSEMBL', feature_out = 'SYMBOL', species = 'Homo sapiens', out.dir = getwd(), ...) {
  ## Normalizing (vst)
  DE2obj.norm <- DESeq2::vst(object = DE2obj, ...)
  ## Extracting the normalized count matrix
  norm.mat <- SummarizedExperiment::assay(DE2obj.norm)
  ## Converting feature names if requested
  if(feature_out != feature_in) {
    ## Creating the converting object
    gconv <- as.list(clusterProfiler::bitr(rownames(norm.mat), fromType = feature_in, toType = feature_out, OrgDb=paste0(msigdbr2org(species), '.db')))
    ## Converting features
    names(gconv[[feature_out]]) <- gconv[[feature_in]]
    names(gconv[[feature_in]]) <- gconv[[feature_out]]
    rownames(norm.mat) <- unname(gconv[[feature_out]][as.character(rownames(norm.mat))])
  }
  ## Filtering
  na.tf <- is.na(rownames(norm.mat))
  if(any(na.tf)) norm.mat <- norm.mat[!na.tf,]
  ## Removing duplicates
  dup.tf <- duplicated(rownames(norm.mat))
  if(any(dup.tf)) norm.mat <- norm.mat[!dup.tf,]
  ## Sorting features
  norm.mat <- norm.mat[order(rownames(norm.mat)),]
  ## Converting to a df
  norm.df <- data.frame(Feature = rownames(norm.mat), norm.mat, check.names = FALSE)
  colnames(norm.df)[1] <- feature_out
  ## Writing out df
  if (!is.null(out.dir)) write.table(norm.df, file = paste0(out.dir, '/normalized_counts_', feature_out, ".txt"), sep = "\t", quote = FALSE, row.names = FALSE)
  ## Return
  return(norm.mat)
}

## Convert TSV(GZ) DEA output to XLSX ====
tsv2xlsx <- function(tsv_file = NULL) {
  if (is.null(tsv_file)) stop('No input file provided !')
  tsv_df <- read.table(file = tsv_file, header = TRUE, sep = "\t", as.is = TRUE)
  out_file <- paste0(dirname(tsv_file), '/', gsub(pattern = '\\.tsv.*', replacement = '.xlsx', x = basename(tsv_file)))
  comp_name <- sub(pattern = '_results.*', replacement = '', x = basename(tsv_file))
  WriteXLS::WriteXLS(x = tsv_df, ExcelFileName = out_file, SheetNames = comp_name, AdjWidth = TRUE, AutoFilter = TRUE, BoldHeaderRow = TRUE, FreezeCol = 1, FreezeRow = 1, na = c(NA, '', 'NA', 'na'))
  return()
}

## . Analysis ====

## Perform ArrayQualityMetrics ====
AQM_run <- function(mat = NULL, pheno_df = NULL, pheno_colnames = NULL, to_log = FALSE, title = 'AQM_RAW', out_dir = getwd(), save_results = FALSE) {
  
  title <- gsub(pattern = '\\W', replacement = '_', x = title)
  
  ## Checks
  if(is.null(mat)) stop('An expression matrix is required !')
  if(base::xor(is.null(pheno_df), is.null(pheno_colnames))) stop('pheno_df and pheno_colnames should be either both set to null, or both set to any value !')
  if(!is.logical(to_log)) stop('to_log must be logical !')
  if(is.null(title)) stop('A title is required for both the AQM report and naming the outlier flag columns !')
  if(!dir.exists(paths = out_dir)) stop('Output directory does not exist !')
  if(!is.logical(save_results)) stop('save_results must be logical !')
  
  if(save_results) warning('AQM results will be saved as RDS, but may take some hard drive space...')
  
  ## Create temporary eset
  temp_eset <- if(!is.null(pheno_df)) Biobase::ExpressionSet(assayData = mat, annotation = title, phenoData = new("AnnotatedDataFrame", data = pheno_df)) else Biobase::ExpressionSet(assayData = mat, annotation = title)
  if(is.null(pheno_colnames)) pheno_colnames <- character(0)
  rm(mat)
  ## Running AQM
  aqm_res <- arrayQualityMetrics::arrayQualityMetrics(
    expressionset = temp_eset
    , outdir = out_dir
    , do.logtransform = to_log
    , intgroup = pheno_colnames
    , reporttitle = title
    , force = TRUE
  )
  rm(eset)
  
  ## Saving results
  if(save_results) saveRDS(object = aqm_res, file = paste0(out_dir, '/AQM_results.RDS'))
  
  ## Adding outlier results as new flags
  aqm_mods <- c('heatmap', 'boxplot', 'pca', 'density', 'meansd', 'maplot')
  for (am in aqm_mods) {
    ol_tag <- paste(c('OL', title, am), collapse = '_')
    pheno_df[[ol_tag]] <- FALSE
    pheno_df[[ol_tag]][unname(aqm_res$modules[[am]]@outliers@which)] <- TRUE
    # pheno_df[[ol_tag]] <- as.factor(pheno_df[[ol_tag]])
  }
  
  return(pheno_df)
}

## Assess the weight of annotation covariates in a (sample x annotations) data.frame, on a (feature x sample) data matrix, through correlation (for a continuous covariate) or Kruskal-Wallis statistic (for factors) ====
## . mat                [f x s num matrix]      A normalized numeric matrix
## . annot.df           [s x a data.frame]      A data.frame with covariates as columns (numeric or factor)
## . factor.names       [vec(char)]             Column names of annot.df corresponding to factor covariates
## . conti.colnames     [vec(char)]             Column names of annot.df corresponding to contiunous covariates
## . red.method         [char]                  Dimension reduction method ['PCA', 'MDS.euc', 'MDS.spear']
## . ndim.max           [int>0]                 Number of dimensions to compute and plot
## . center             [bool]                  Center mat ?
## . scale              [bool]                  Scale mat ?
## . coef.cut           [0<=num<1]              Do not display coefficients inferior to this value on the heatmap
## . color.palette      [vec(col)]              Color vector (length 2) for the heatmap
## . out.file           [char]                  Output PNG file name (and path)
assess_covar <- function(mat = NULL, annot.df = NULL, factor.names = NULL, conti.names = NULL, red.method = 'pca', ndim.max = 10, topvar = NULL, center = TRUE, scale = TRUE, coef.cut = 0, color.palette = c("white", "orangered3"), out.file = paste0(getwd(), '/Assess_covariates.svg'), width = 800, height = 1000) {
  ## Checks
  ### Mandatory
  if (is.null(mat)) stop('A (f feature by s sample) matrix [mat] is required.')
  if (is.null(annot.df)) stop('An annotation data.frame [annot.df] is required.')
  if (all(is.null(c(factor.names, conti.names)))) stop('At least one of [factor.names] or [conti.colnames] should not be NULL.')
  if (ndim.max <= 0) stop('[ndim.max] should be a non-null positive integer (and <= s samples).')
  if (!dir.exists(dirname(out.file))) stop('Path to [out.file] does not exist.')
  if (!tolower(red.method) %in% c('pca', 'mds.euc', 'mds.spear')) stop('Unknown reduction method')
  ### Compatibility
  if (ndim.max > ncol(mat)) {
    message('WARNING : requested [ndim.max] is higher than samples in [mat]. Reducing it to [mat] samples.')
    ndim.max <- ncol(mat)-1
  }
  # message(ndim.max)
  if (nrow(annot.df) != ncol(mat)) stop('There should be the same number of samples in [mat] (columns) and [annot.df] (rows)')
  if(!is.null(factor.names)) {
    if(!all(factor.names %in% colnames(annot.df))) stop('All [factor.names] should be in colnames of [annot.df].')
  }
  if(!is.null(conti.names)) {
    if(!all(conti.names %in% colnames(annot.df))) stop('All [conti.names] should be in colnames of [annot.df].')
  }
  
  ## RUN
  
  ## Restrict to topvar ?
  if(!is.null(topvar)) {
    message('Restricting to the Top ', topvar, ' features ...')
    svmat <- matrixStats::rowVars(mat)
    mat <- mat[order(svmat) <= topvar,]
  }
  
  ## Convert conti to Zscores
  if (!is.null(conti.names)) {
    for (x in conti.names) annot.df[[x]] <- (annot.df[[x]] - mean(annot.df[[x]], na.rm = TRUE)) / sd(annot.df[[x]], na.rm = TRUE)
  }
  
  ## Center / scale the matrix ?
  if (any(c(center, scale))) mat <- base::scale(x = mat, center = center, scale = scale)
  ## Dimension reduction
  if (tolower(red.method) == 'pca') norm.red <- base::svd(x = mat, nv = ndim.max)$v
  if (tolower(red.method) == 'mds.euc') norm.red <- stats::cmdscale(d = dist(x = t(mat), method = 'euclidean'), k = ndim.max)
  if (tolower(red.method) == 'mds.spear') norm.red <- stats::cmdscale(d = as.dist(1-cor(mat, method = 'spearman')), k = ndim.max)
  col.names <- c(factor.names, conti.names)
  col.types <- c(rep('factor', length(factor.names)), rep('continuous', length(conti.names)))
  ## Setting output matrix
  bc.mat <- matrix(NA, ncol = length(col.names), nrow = ndim.max, dimnames = list(paste0(toupper(red.method), seq_len(ndim.max)), col.names))
  ## Filling matrix
  for (cn in seq_along(col.names)) {
    # message(col.names[cn])
    if (col.names[cn] %in% conti.names) {
      cv2cor <- annot.df[[col.names[cn]]]
      nona <- !is.na(cv2cor)
      bc.mat[, cn] <-  abs(cor(x = cv2cor[nona], y = norm.red[nona,], method = 'spearman'))
    } else if (col.names[cn] %in% factor.names & length(unique(annot.df[[col.names[cn]]])) > 1) {
      b2kw <- annot.df[[col.names[cn]]]
      nona <- !is.na(b2kw)
      for (si in seq_len(ndim.max)) {
        k_test <- try(k_res <- kruskal.test(x = norm.red[nona,si], g = as.factor(b2kw[nona])), silent = TRUE)
        if (!is(k_test, class2 = 'try-error')) {
          bc.mat[si,cn] <- k_res$statistic / nrow(norm.red)
        } else bc.mat[si,cn] <- 0
      }
    }
  }
  bc.mat[bc.mat < coef.cut] <- 0
  ## Heatmap
  myRamp.col <- circlize::colorRamp2(c(0, 1), color.palette)
  BC.hm <- ComplexHeatmap::Heatmap(matrix = bc.mat,
                                   name = 'Weight',
                                   col = myRamp.col,
                                   na_col = 'grey75',
                                   cluster_rows = FALSE,
                                   cluster_columns = FALSE,
                                   rect_gp = grid::gpar(col = "darkgrey", lwd=0.5),
                                   column_title = 'Batch factors and covariates weight on dataset',
                                   row_title = paste0(toupper(red.method), ' dimensions'),
                                   column_split = col.types,
                                   top_annotation = ComplexHeatmap::HeatmapAnnotation(Type = col.types, col = list(Type = setNames(object = c('lightblue','pink'), nm = c('factor', 'continuous')))))
  svg(filename = out.file, width = width/96, height = height/96)
  ComplexHeatmap::draw(BC.hm)
  svg_off()
}


## Convert a factor to a design dataframe to be used in DE_run ====
## Function to generated a "full" comparison design from a minimalistic dataframe containing samplenames and factor(s) to compare, to use in DE.test
## . init_df            [data.frame]      A data.frame with at least 2 columns, one of which should be named as defined in [samples_colname], the others being the factors to use to generate the comparison design
## . samples_colname    [char]            Name of the column to use from init_df as sample names
## . covar_colnames     [list(vec(char))]       Name of the column(s) to use in the design as covariates to regress. They should not be in [init_df] !
## . add_inverted       [logical]         Add the inverted comparisons of the default factor ones (ie, B_vs_A if A_vs_B is the default one)
## . add_others         [logical]         Add the 'X vs Other' type of comparisons if the factor has more than 2 levels
## . only_others        [logical]         Only generate the 'X vs Other' type of comparisons if the factor has more than 2 levels
full_design_generator <- function(init_df = NULL, samples_colname = NULL, covar_colnames = NULL, add_inverted = TRUE, only_inverted = FALSE, add_others = TRUE, only_others = FALSE) {
  
  ## Checks
  if(is.null(init_df)) stop('A starting dataframe containing sample names and factors to compare is  required !')
  if(is.null(samples_colname)) stop('A column name to identify samples in init_df is required !')
  if(!samples_colname %in% colnames(init_df)) stop('Column name [', samples_colname, '] not found in init_df !')
  if(!add_others & only_others) stop("Can't restrict to 'vs_Other' comparisons if add_others is not set to TRUE !")
  if(length(covar_colnames) != (ncol(init_df)-1)) stop ('length(covar_colnames) != nrow(init_df) !')
  
  ## Cleaning bad chars
  ### Column names in initial df
  colnames(init_df) <- gsub(pattern = "\\W", replacement = '.', x = colnames(init_df))
  ### Content of initial df
  for (myc in seq_len(ncol(init_df))) init_df[[myc]] <- gsub(pattern = "\\W", replacement = '.', x = init_df[[myc]])
  ### samples_colname & covar_colnames
  # covar_colnames <- gsub(pattern = "\\W", replacement = '.', x = covar_colnames)
  covar_colnames[vapply(covar_colnames, is.null, TRUE)] <- ''
  covar_colnames <- lapply(covar_colnames, function(x) { gsub(pattern = "\\W", replacement = '.', x = x) })
  samples_colname <- gsub(pattern = "\\W", replacement = '.', x = samples_colname)
  
  
  
  factor_colnames <- colnames(init_df)[!colnames(init_df) %in% samples_colname]
  
  des.df <- sapply(seq_along(factor_colnames), function(f) {
    factor_name <- factor_colnames[f]
    message(factor_name)
    my_factor <- init_df[[factor_name]]
    if(!is.factor(my_factor)) my_factor <- as.factor(my_factor)
    
    mylevels <- levels(my_factor)
    # combn.res <- if(invert_levels) combn(mylevels, 2) else combn(rev(mylevels), 2)
    combn.res <- combn(rev(mylevels), 2)
    if(add_inverted) {
      inv_combn.res <- combn(mylevels, 2)
      if (only_inverted) {
        combn.res <- inv_combn.res
      } else {
        combn.res <- cbind(combn.res, inv_combn.res)
      }
    }
    all.combz <- sapply(1:ncol(combn.res), function(x) {list(combn.res[1,x], combn.res[2,x])}, simplify = FALSE)
    names(all.combz) <- vapply(1:ncol(combn.res), function(x) { paste(combn.res[, x, drop = TRUE], collapse = '_vs_') }, 'a')
    if(length(mylevels) > 2 & add_others) {
      XvsO.combz <- sapply(as.character(mylevels), function(x) { list(x, mylevels[!mylevels == x])}, simplify = FALSE)
      names(XvsO.combz) <- vapply(mylevels, function(x) { paste0(x, '_vs_Other') }, 'a')
      all.combz <- if(only_others) XvsO.combz else c(all.combz, XvsO.combz)
      rm(XvsO.combz)
    }
    
    ## Filtering comparisons with a class comprised by an unique sample
    for (mycomb in names(all.combz)) {
      class.len <- vapply(all.combz[[mycomb]], function(x) { length(which(my_factor %in% x))}, 1L)
      if(any(class.len == 1)) all.combz[[mycomb]] <- NULL
    }
    
    ## Generated design table
    f.df <- sapply(seq_along(all.combz), function(x) {
      comb_df <- data.frame(
        'Samples_colname' = samples_colname
        , 'Covar_colnames' = paste(covar_colnames[[f]], collapse = ',')
        , 'Condition_colname' = factor_name
        , 'Condition_A' = paste(all.combz[[x]][[1]], collapse = ',')
        , 'Condition_B' = paste(all.combz[[x]][[2]], collapse = ',')
        , 'Comparison_name' = names(all.combz)[x]
      )
      return(comb_df)
    }, simplify = FALSE)
    f.df = Reduce(f = rbind, x = f.df)
    return(f.df)
  }, simplify = FALSE)
  des.df <- Reduce(f = rbind, x = des.df)
  return(des.df)
}


## Regress a matrix with covariates ====
## mat : a numeric matrix of expression data. Can be of type 'counts' (raw counts, to apply sva::Combat_seq), or 'norm' (normalized data, to apply sva::Combat or limma::removeBatchEffect)
## type : ['counts'|'norm'] for raw counts or normalized data. The output matrix will be of the same type !
## covar_factor_df : data.frame that contains factors to regress (synched with the mat columns)
## covar_conti_df : data.frame that contains continuous data to regress (synched with the mat columns)
matrix_covar_regress <- function(mat = NULL, type = 'counts', covar_factor_df = NULL, covar_conti_df = NULL, group = NULL) {
  ## Checks
  if (is.null(mat)) stop('A matrix is required !')
  if (!tolower(type) %in% c('counts', 'norm')) stop('type should be one of "counts" (raw counts) or "norm" (normalized data) !')
  if (all(is.null(c(covar_factor_df, covar_conti_df)))) stop('covar_factor_df and covar_conti_df should not be simultaneously NULL !')
  if (!is.matrix(mat)) stop('mat should be a matrix !')
  if (!is.numeric(as.vector(mat))) stop('mat should be a numeric matrix !')
  if (!is.null(covar_factor_df)) {
    if (!is.data.frame(covar_factor_df)) stop('covar_factor_df should be a data.frame !')
    if (tolower(type) %in% 'counts') {
      if (!is.null(covar_conti_df)) {
        stop('On counts data, only sva::Combat_seq can be used, and is compatible with a single factor, not continuous data !')
      } else if (ncol(covar_factor_df) > 1) {
        stop('On counts data, only sva::Combat_seq can be used, and is compatible with a single factor, not multiple !')
      }
    } else if (ncol(covar_factor_df) > 2) {
        stop('On normalized data, limma::removeBatchEffect can be used, and is compatible with a 2 factor covariates at most (there is no limit on continous covariates, though) !')
    }
  }
  if (!is.null(covar_conti_df) & !is.data.frame(covar_conti_df)) stop('covar_conti_df should be a data.frame !')
  if (!all(vapply(covar_factor_df, is.factor, TRUE))) stop('All columns in covar_factor_df should be factors !')
  if (!all(vapply(covar_conti_df, is.numeric, TRUE))) stop('All columns in covar_conti_df should be numerics !')
  
  fr_mm <- list()
  
  ## Handling factors
  if(!is.null(covar_factor_df)) {
    # ## Add contrasts to factors
    # for (x in 1:(min(ncol(covar_factor_df), 2))) stats::contrasts(covar_factor_df[,x]) <- stats::contr.sum(levels(covar_factor_df[,x]))
    # 
    # ## Generate factors model matrices
    # for (x in 1:min(ncol(covar_factor_df), 2)) fr_mm[[x]] <- model.matrix(~covar_factor_df[,x])[, -1, drop = FALSE]
    
    temp_factor_df <- if(is.null(group)) covar_factor_df else cbind(covar_factor_df, group)
    
    ## Add contrasts to factors
    for (x in seq_len(ncol(temp_factor_df))) stats::contrasts(temp_factor_df[,x]) <- stats::contr.sum(levels(temp_factor_df[,x]))
    ## Generate factors model matrices
    for (x in seq_len(ncol(temp_factor_df))) fr_mm[[x]] <- model.matrix(~temp_factor_df[,x])[, -1, drop = FALSE]
  }
  
  ## Handling conti
  if (!is.null(covar_conti_df)) fr_mm[['conti']] <- as.matrix(covar_conti_df)
  
  ## Merge
  X.batch <- Reduce(f = cbind, x = fr_mm)
  
  ## Checking if matrix is full-rank
  fr_check <- limma::nonEstimable(X.batch)
  if(!is.null(fr_check)) stop('Design is not full-rank !')

  # ## Regression
  # if(is.null(covar_conti_df) && ncol(covar_factor_df) == 1) {
  #   ### If we have a single factor, no conti
  #   if (tolower(type) %in% 'norm') {
  #     message('Regression with ComBat ...')
  #     # ber.mat <- sva::ComBat(dat = mat, batch = covar_factor_df[,1], group = group)
  #     ber.mat <- sva::ComBat(dat = mat, batch = covar_factor_df[,1], mod = model.matrix(~group)[, -1, drop = FALSE])
  #     
  #   } else if (tolower(type) %in% 'counts') {
  #     message('Regression with ComBatSeq ...')
  #     ber.mat <- sva::ComBat_seq(counts = mat, batch = covar_factor_df[,1], group = group, full_mod = !is.null(group))
  #   }
  # } else {
  #   ### If we have more than one factor, and/or conti
  #   message('Regression with limma ...')
  #   ber.mat <- limma::removeBatchEffect(x = mat, batch = if(!is.null(covar_factor_df)) covar_factor_df[,1] else NULL, batch2 = if(is.null(covar_factor_df)) NULL else if(ncol(covar_factor_df) > 1) covar_factor_df[,2] else NULL, covariates = if(!is.null(covar_conti_df)) as.matrix(covar_conti_df) else NULL, group = group)
  # }
  
  ## Regression
  if(is.null(covar_conti_df) && ncol(covar_factor_df) == 1 && (tolower(type) %in% 'counts')) {
    ### ComBatSeq mode
    message('Regression with ComBatSeq ...')
    ber.mat <- sva::ComBat_seq(counts = mat, batch = covar_factor_df[,1], group = group, full_mod = !is.null(group))
  } else {
    ### If we have more than one factor, and/or conti
    message('Regression with limma ...')
    ber.mat <- limma::removeBatchEffect(x = mat, batch = if(!is.null(covar_factor_df)) covar_factor_df[,1] else NULL, batch2 = if(is.null(covar_factor_df)) NULL else if(ncol(covar_factor_df) > 1) covar_factor_df[,2] else NULL, covariates = if(!is.null(covar_conti_df)) as.matrix(covar_conti_df) else NULL, group = group)
  }
  
  return(ber.mat)
}


## Perform DE analysis & functional enrichment for contrasts in pairs ====
## exp.mat                matrix(integer)     Sample x feature (gene) raw count matrix. Feature names as rownames.
## annot.df               data.frame          Sample annotations. Should contain a column with the same entries as colnames(exp.mat)
## design.df              data.frame          Design of comparisons to perform. Should contain these column names : [Samples_colname] = Column name of sample names ; [Covar_colnames] = Column name(s) of covariates to regress, coma-separated (can be empty if none to regress); [Condition_colname] = Column name of factor condition to explore for the differential analysis ; [Condition_A] = levels to consider as the condition A (test) ; [Condition_B] = levels to consider as the condition B (ref) ; [Comparison_name] = Name to use for results output.
## assess.factor          logical             Perform assessment of factor covariates using the provided column name(s) corresponding to factor data columns in annot.df
## assess.conti           logical             Perform assessment of continuous covariates using the provided column name(s) corresponding to continuous data columns in annot.df
## min_count              0<int>+inf          Minimum total counts to keep a feature (gene) : allows to discarded not/poorly expressed features
## per_class              logical             Apply the min_count filtering on each compared class rather than the total sample population
## adjp.max               0<numeric<1         BH FDR-adjusted p-value cut-off to consider differential genes as significant
## lfc.min                numeric+            Minimal logFoldChange to consider differential genes
## ihw                    logical             Apply Independent Hypothesis Weighting (see IHW::ihw) [TRUE]
## outdir                 character           Path of the output directory
## samples.dist.method    character           Name of the distance method to use for the hierarchical clustering of samples
## samples.hclust.method  character           Name of the aggregation method to use for the hierarchical clustering of samples
## genes.dist.method      character           Name of the distance method to use for the hierarchical clustering of genes
## genes.hclust.method    character           Name of the aggregation method to use for the hierarchical clustering of genes
## msigdb.do              c(bool, bool)       Use the MSigDb dataset collection to perform GSEA/ORA
## go.do                  c(bool, bool)       Use the GeneOntology dataset to perform GSEA/ORA
## do.do                  c(bool, bool)       Use the DiseaseOntology + CancerGeneNetwork + DisGeNet datasets to perform GSEA/ORA
## kegg.do                c(bool, bool)       Use the KEGG dataset to perform GSEA/ORA
## wp.do                  c(bool, bool)       Use the WikiPathways dataset to perform GSEA/ORA
## reactome.do            c(bool, bool)       Use the Reactome dataset to perform GSEA/ORA
## cm.do                  c(bool, bool)       Use the CellMarker dataset to perform GSEA/ORA
## mesh.do                c(bool, bool)       Use the MeSHDb dataset collection to perform GSEA/ORA (warning, this may consume an astronomical amount of RAM. gsea.do is forced to false)
## species                character           Name of the species analyzed (namely, 'human' or 'mouse')
## enrp.max               0<numeric<1         BH FDR-adjusted p-value cut-off to consider enriched terms as significant
## enr.min.genes          numeric+            Minimum number of significant genes to perform GSEA/ORA
## or.top.max             numeric+            Maximum number of significant genes to consider as a signature for ORA. Also used for plots (boxplots, limited heatmap) using only a portion of all significant genes
## dotplot.maxterms       numeric+            Maximum number of enriched terms to plot in a dotplot (for readability)
## my.seed                numeric             Seed value for RNG (used for GSEA and heatmap annotation colors)
## boxplots               bool                If TRUE, draw boxplots of or.top.max genes
## save.wald              bool                If TRUE, save the DESeq2 object containing the results of the Wald test. This is FALSE by default, as the resulting object can be pretty big.
## color.palette          vec(color)          Vector of 3 colors used for the expression heatmap (lower values, middle, higher)
DEA_run <- function(exp.mat = NULL, annot.df = NULL, design.df = NULL, assess.factor = NULL, assess.conti = NULL, min_count = 5L, min_samples = 2L, per_class = TRUE, vst_nsub = 1000, adjp.max = 5E-02, lfc.min = .7, ihw = TRUE, lfcShrink = TRUE, enrp.max = 1E-02, enr.min.genes = 10, or.top.max = 100, outdir = getwd(), samples.dist.method = 'spearman', samples.hclust.method = 'ward.D', genes.dist.method = 'spearman', genes.hclust.method = 'ward.D', msigdb.do = c(TRUE, TRUE), do.do = c(TRUE, TRUE), go.do = c(TRUE, TRUE), kegg.do = c(TRUE, TRUE), wp.do = c(TRUE, TRUE), reactome.do = c(TRUE, TRUE), mesh.do = c(FALSE, FALSE), custom.do = c(FALSE, FALSE), custom_gmt_list = NULL, species = 'Homo sapiens', dotplot.maxterms = 50, my.seed = 1234L, boxplots = TRUE, save.wald = FALSE, heatmap.palette = c("royalblue3", "ivory", "orangered3"), BPPARAM = BiocParallel::SerialParam()) {
  
  if (tolower(species) == 'homo sapiens') {
    Org <- 'org.Hs'
  } else if (tolower(species) == 'mus musculus') {
    Org <- 'org.Mm'
  } else stop("Only 'Homo sapiens' and 'Mus musculus' species are supported !")
  
  ## Cleaning design
  for (x in seq_len(ncol(design.df))) design.df[,x] <- as.character(design.df[,x])
  design.df$Covar_colnames[design.df$Covar_colnames == ''] <- NA
  
  ## CHECKS ====
  ## Mandatory entries
  ### expression matrix
  if (is.null(exp.mat)) stop('An expression matrix is required !')
  if (!is.matrix(exp.mat)) stop('Expression data should be a matrix !')
  ### annotation
  if (is.null(annot.df)) stop('An annotation data.frame is required !')
  if (!is.data.frame(annot.df)) stop('Annotation data should be a data.frame !')
  ### design
  if (is.null(design.df)) stop('A design data.frame is required !')
  if (!is.data.frame(design.df)) stop('Design data should be a data.frame !')
  ## if exp.mat and annot.df have different size
  if (nrow(annot.df) != ncol(exp.mat)) stop("'exp.mat' and 'annot.df' do not have the same amount of samples!")
  ## if some annotation column names provided in design do not exist :
  ### samples :
  if (!all(unique(design.df$Samples_colname) %in% colnames(annot.df))) stop('All provided [Samples_colname] values should be in colnames(annot.df) !')
  ### covariates (outside design):
  #### Clean covariates names
  assess.factor <- gsub(pattern = "\\W", replacement = '.', x = assess.factor)
  if (!all(assess.factor %in% colnames(annot.df))) stop('All provided [assess.factor] values should be in colnames(annot.df) !')
  if (!all(assess.conti %in% colnames(annot.df))) stop('All provided [assess.conti] values should be in colnames(annot.df) !')
  ### covariates (from design):
  covars <- unique(unlist(lapply(seq_len(nrow(design.df)), function(x) unlist(strsplit(x = as.character(design.df$Covar_colnames[x]), split = ',')))))
  covars <- covars[!is.na(covars)]
  if(!all(is.na(covars))) {
    if (!all(covars[!is.na(covars)] %in% colnames(annot.df))) stop('All provided [Covar_colname] values should be in colnames(annot.df) !')
  }
  ### condition :
  if (!all(unique(design.df$Condition_colname) %in% colnames(annot.df))) stop('All provided [Condition_colname] values should be in colnames(annot.df) !')
  ## if samples are not identical
  # exp.mat <- exp.mat[,order(colnames(exp.mat))]
  # annot.df <- annot.df[order(annot.df[[samples.colname]]),]
  # if (!all(colnames(exp.mat) == annot.df[[samples.colname]])) stop(paste0("Content of the sample column '", samples.colname, "' is not identical to 'exp.mat' colnames !"))
  if (any(custom.do) & is.null(custom_gmt_list)) stop('GSEA/ORA on custom bank is requested, but no bank list (custom_gmt_list) provided !')
  if (!is.null(custom_gmt_list) & !is.list(custom_gmt_list)) stop('custom_gmt_list should be a named list of terms/genes data.frames as obtained from the clusterProfiler::read.gmt() function !')
  ## Feature filtering
  if(!is.integer(min_count)) stop('min_count should be a positive integer !')
  if(min_count < 0) stop('min_count should be a positive integer !')
  if(!is.logical(per_class)) stop('per_class should be a logical !')
  
  
  suppressPackageStartupMessages(library(DESeq2))
  suppressPackageStartupMessages(library(SummarizedExperiment))
  suppressPackageStartupMessages(library(ComplexHeatmap))
  suppressPackageStartupMessages(library(circlize))
  
  
  ## Looping on design entries
  for (cur.idx in seq_len(nrow(design.df))) {
    
    ## Limiting annot.df to required columns
    samples.colname <- design.df$Samples_colname[cur.idx]
    cur.cond <- design.df$Condition_colname[cur.idx]
    cur.covars <- unlist(strsplit(x = design.df$Covar_colnames[cur.idx], split = ','))
    cur.covars <- cur.covars[!is.na(cur.covars)]
    cur.condA <- unlist(strsplit(x = design.df$Condition_A[cur.idx], split = ','))
    cur.condB <- unlist(strsplit(x = design.df$Condition_B[cur.idx], split = ','))
    cur.annot.df <- annot.df[, colnames(annot.df) %in% c(samples.colname, cur.covars, cur.cond)]
    cur.name <- design.df$Comparison_name[cur.idx]
    cur.exp.mat <- exp.mat
    cur.annot.df <- annot.df
    
    
    ## Filtering special characters in cur.cond
    colnames(cur.annot.df) <- gsub(pattern = "\\W", replacement = '.', x = colnames(cur.annot.df))
    # message(paste(levels(cur.annot.df[[cur.cond]]), collapse = ' ; '))
    levels(cur.annot.df[[cur.cond]]) <- gsub(pattern = "\\W", replacement = '.', x = levels(cur.annot.df[[cur.cond]]))
    # message(paste(levels(cur.annot.df[[cur.cond]]), collapse = ' ; '))
    
    
    ## Adjusting the datasets if needed
    ## Handling NAs in current annotation
    na.check <- is.na(cur.annot.df[[cur.cond]])
    if (any(na.check)) {
      cur.exp.mat <- cur.exp.mat[,!na.check]
      cur.annot.df <- cur.annot.df[!na.check,]
    }
    ## Handling requested levels
    lev.checks <- cur.annot.df[[cur.cond]] %in% c(cur.condA, cur.condB)
    if (!all(lev.checks)) {
      cur.exp.mat <- cur.exp.mat[,lev.checks]
      cur.annot.df <- cur.annot.df[lev.checks,]
    }
    
    ## Forcing a relevel (if some levels were lost)
    cur.annot.df[[cur.cond]] <- droplevels(cur.annot.df[[cur.cond]])
    
    
    ## Creating design (factor then Batch, w/o intercept)
    my.textform <- paste(c('~0', unique(c(cur.cond, cur.covars))), collapse = '+')
    # my.textform <- paste(c('~0', unique(c(cur.covars, cur.cond))), collapse = '+')
    # my.textform <- paste0('~', paste(unique(c(cur.covars, cur.cond)), collapse = '+'))
    # my.textform <- paste0('~', paste(unique(c(cur.cond, cur.covars)), collapse = '+'))
    # my.textform <- paste(c('~0', unique(c(cur.cond, cur.covars))), collapse = '+')
    my.design <- as.formula(my.textform)
    
    ## Creating the main output dir
    fac.dir <- paste0(outdir, '/Differential_analysis')
    # factor.dir <- paste(c(fac.dir, paste0('adjp.', adjp.max, '_lfc.', lfc.min), my.textform), collapse = '/')
    factor.dir <- paste(c(fac.dir, my.textform), collapse = '/')
    # dir.create(path = factor.dir, recursive = TRUE)
    
    de.dir <- paste(c(factor.dir, cur.name), collapse = '/')
    cut.dir <- paste(c(de.dir, paste0('adjp.', adjp.max, '_lfc.', lfc.min)), collapse = '/')
    dir.create(path = cut.dir, recursive = TRUE)
    
    # ## Filtering features (BAK)
    # message('Features filtering ...')
    # message('Features PRE : ', nrow(cur.exp.mat))
    # if (per_class) {
    #   ## Minimum counts criterion
    #   ff_min <- as.data.frame(lapply(c(cur.condA, cur.condB), function(cc) {
    #     ccs <- cur.annot.df[[cur.cond]] == cc
    #     return(base::rowSums(x = cur.exp.mat[,ccs]) >= min_count)
    #   }))
    #   ## Minimum expressed samples criterion
    #   sf_min <- as.data.frame(lapply(c(cur.condA, cur.condB), function(cc) {
    #     ccs <- cur.annot.df[[cur.cond]] == cc
    #     return(length(which(ccs)) - matrixStats::rowCounts(x = cur.exp.mat[,ccs], value = 0) >= min(min_samples, length(which(ccs))))
    #   }))
    #   ff_feats <- base::rowSums(ff_min) > 0
    #   sf_feats <- base::rowSums(sf_min) > 0
    #   ok_feats <- ff_feats & sf_feats
    # } else {
    #   ok_feats <- base::rowSums(cur.exp.mat) >= min_count
    # }
    # cur.exp.mat <- cur.exp.mat[ok_feats,]
    # message('Features POST : ', nrow(cur.exp.mat))
    
    ## Filtering features ====
    message('Features filtering ...')
    message('Features PRE : ', nrow(cur.exp.mat))
    cf_min <- data.frame(COVAR = rep(FALSE, nrow(cur.exp.mat)))
    if (per_class) {
      ## Minimum counts criterion
      ff_min <- as.data.frame(lapply(c(cur.condA, cur.condB), function(cc) {
        ccs <- cur.annot.df[[cur.cond]] == cc
        return(base::rowSums(x = cur.exp.mat[,ccs, drop = FALSE]) >= min_count)
      }))
      colnames(ff_min) <- c(cur.condA, cur.condB)
      ## Handling factor covariates
      for (cc in cur.covars) {
        if(is.factor(cur.annot.df[[cc]])) {
          cur.annot.df[[cc]] <- droplevels(cur.annot.df[[cc]])
          tmp_min <- as.data.frame(lapply(levels(cur.annot.df[[cc]]), function(x) {
            ccs <- cur.annot.df[[cc]] == x
            return(base::rowSums(x = cur.exp.mat[,ccs, drop = FALSE]) == 0)
          }))
          colnames(tmp_min) <- levels(cur.annot.df[[cc]])
          cf_min <- cbind(cf_min, tmp_min)
        }
      }
      # message(str(cf_min))
      ## Minimum expressed samples criterion
      sf_min <- as.data.frame(lapply(c(cur.condA, cur.condB), function(cc) {
        ccs <- cur.annot.df[[cur.cond]] == cc
        return(length(which(ccs)) - matrixStats::rowCounts(x = cur.exp.mat[,ccs], value = 0) >= min(min_samples, length(which(ccs))))
      }))
      colnames(sf_min) <- c(cur.condA, cur.condB)
      ff_feats <- base::rowSums(ff_min) > 0
      cf_feats <- base::rowSums(cf_min) == 0
      sf_feats <- base::rowSums(sf_min) > 0
      ok_feats <- ff_feats & sf_feats & cf_feats
    } else {
      ok_feats <- base::rowSums(cur.exp.mat) >= min_count
    }
    cur.exp.mat <- cur.exp.mat[ok_feats,]
    message('Features POST : ', nrow(cur.exp.mat))
    
    ## Creating the DESeq2 object ====
    suppressMessages(DE2obj <- DESeq2::DESeqDataSetFromMatrix(countData = cur.exp.mat, colData = cur.annot.df, design = my.design))
    rm(cur.exp.mat, cur.annot.df)
    
    ## Saving the DESeq object
    # saveRDS(object = DE2obj, file = paste0(factor.dir, '/', cur.cond, '_rawcounts.RDS'), compress = 'bzip2')
    saveRDS(object = DE2obj, file = paste0(de.dir, '/', cur.cond, '_rawcounts.RDS'), compress = 'bzip2')
    
    ## Normalizing by vst (for PCA & heatmap) ====
    DE2obj.norm <- DESeq2::vst(object = DE2obj, blind = TRUE, nsub = vst_nsub)
    
    ## Defining the VST-normalized matrix as default normalized data
    norm.mat <- SummarizedExperiment::assay(DE2obj.norm)
    
    ## Save VST matrix 
    write.table(x = data.frame(Feature = rownames(norm.mat), norm.mat, check.names = FALSE), file = gzfile(paste0(de.dir, '/Normalized.vst_matrix.tsv.gz')), sep = '\t', quote = FALSE, row.names = FALSE)

    ## Assessing DESIGN covariates, and regressing if requested ====
    if (length(cur.covars) > 0) {
      ### Assessing covariates
      #### Splitting factor and continuous covariates
      factor.colnames <- conti.colnames <- NULL
      for (cn in cur.covars) {
        if (is.factor(DE2obj@colData[[cn]])) factor.colnames <- c(factor.colnames, cn) else if (is.numeric(DE2obj@colData[[cn]])) conti.colnames <- c(conti.colnames, cn) else stop(paste0('Covariate [', cn, '] is neither a factor nor a numeric/integer vector !'))
      }
      ### UNREGRESSED
      ## ALL genes
      try(assess_covar(
        mat = norm.mat
        , annot.df = as.data.frame(SummarizedExperiment::colData(DE2obj))
        , factor.names = c(cur.cond, factor.colnames)
        , conti.names = conti.colnames
        , red.method = 'pca'
        , ndim.max = min(round(ncol(norm.mat)/2), 20)
        , center = TRUE 
        , scale = TRUE 
        , out.file = paste(c(paste0(de.dir, '/', cur.cond), 'assess', 'covariates', 'All', '01', 'unregressed.svg'), collapse = '_')
        ))
      ## Topvar
      ## ALL genes
      try(assess_covar(
        mat = norm.mat
        , annot.df = as.data.frame(SummarizedExperiment::colData(DE2obj))
        , factor.names = c(cur.cond, factor.colnames) 
        , conti.names = conti.colnames
        , red.method = 'pca'
        , topvar = vst_nsub
        , ndim.max = min(round(ncol(norm.mat)/2), 20)
        , center = TRUE
        , scale = TRUE
        , out.file = paste(c(paste0(de.dir, '/', cur.cond), 'assess', 'covariates', paste0('Top', vst_nsub), '01', 'unregressed.svg'), collapse = '_')
      ))
      
      ### REGRESSED
      #### Performing regression
      ber_method <- NULL
      if (length(factor.colnames) == 1 & is.null(conti.colnames) && min(table(SummarizedExperiment::colData(DE2obj)[[factor.colnames[1]]])) > 1) {
        ## sva::Combat_seq case !
        ber.method <- 'CombatSeq'
        ber_mat <- try(
          DESeq2::vst(
            object = matrix_covar_regress(
              mat = SummarizedExperiment::assay(DE2obj)
              , type = 'counts'
              , covar_factor_df = if(is.null(factor.colnames)) NULL else as.data.frame(SummarizedExperiment::colData(DE2obj))[, factor.colnames, drop = FALSE]
              , covar_conti_df = if(is.null(conti.colnames)) NULL else as.data.frame(SummarizedExperiment::colData(DE2obj))[, conti.colnames, drop = FALSE]
              , group = as.factor(SummarizedExperiment::colData(DE2obj)[[cur.cond]])
              )
            , blind = TRUE
            , nsub = vst_nsub
            )
          , silent = TRUE)
      } else {
        ## limma::RemoveBatchEffect case !
        ber_method <- 'limma'
        ber_mat <- try(
          matrix_covar_regress(
            mat = norm.mat
            , type = 'norm'
            , covar_factor_df = if (is.null(factor.colnames)) NULL else as.data.frame(SummarizedExperiment::colData(DE2obj))[, factor.colnames, drop = FALSE]
            , covar_conti_df = if (is.null(conti.colnames)) NULL else as.data.frame(SummarizedExperiment::colData(DE2obj))[, conti.colnames, drop = FALSE]
            , group = as.factor(SummarizedExperiment::colData(DE2obj)[[cur.cond]])
            )
          , silent = TRUE)
      }
      
      ## If no error, one can assess the regression results
      if (!is(ber_mat, class2 = 'try-error')) {
        ## Save BER matrix 
        write.table(x = data.frame(Feature = rownames(ber_mat), ber_mat, check.names = FALSE), file = gzfile(paste0(de.dir, '/Normalized.vst.BER.', ber_method, '_matrix.tsv.gz')), sep = '\t', quote = FALSE, row.names = FALSE)
        
        ### Assessing covariates (after regression)
        ## All genes
        try(assess_covar(
          mat = ber_mat
          , annot.df = as.data.frame(DE2obj@colData)
          , factor.names = c(cur.cond, factor.colnames)
          , conti.names = conti.colnames
          , red.method = 'pca'
          , ndim.max = min(round(ncol(ber_mat)/2), 20)
          , center = TRUE
          , scale = TRUE
          , out.file = paste(c(paste0(de.dir, '/', cur.cond), 'assess', 'covariates', 'All', '02', paste(c('regressed', ber_method, 'svg'), collapse = '.')), collapse = '_')
        ))
        ## Topvar
        try(assess_covar(
          mat = ber_mat
          , annot.df = as.data.frame(DE2obj@colData)
          , factor.names = c(cur.cond, factor.colnames)
          , conti.names = conti.colnames
          , red.method = 'pca'
          , topvar = vst_nsub
          , ndim.max = min(round(ncol(ber_mat)/2), 20)
          , center = TRUE
          , scale = TRUE
          , out.file = paste(c(paste0(de.dir, '/', cur.cond), 'assess', 'covariates', paste0('Top', vst_nsub), '02', paste(c('regressed', ber_method, 'svg'), collapse = '.')), collapse = '_')
        ))
        
        ## Set the regressed matrix as default normalized data
        norm.mat <- ber_mat
      }
      
      # #### Running limma::removeBatchEffect the good way
      # limma.bc.batch2 <- limma.bc.batch1 <- limma.bc.covar <- NULL
      # ##### Handling factor covariates
      # for (fc in factor.colnames) {
      #   message(paste0('ASSESS COVAR FACTOR COVAR : ', fc))
      #   if (is.null(limma.bc.batch1)) {
      #     limma.bc.batch1 <- DE2obj@colData[[fc]]
      #   } else if (is.null(limma.bc.batch2)) {
      #     limma.bc.batch2 <- DE2obj@colData[[fc]]
      #   } else message(paste0('Factor [', fc, '] will not be considered for matrix regression by limma::removeBatchEffect as ony 2 factors can be used.'))
      # }
      # ##### Handling continuous covariates
      # for (cc in conti.colnames) {
      #   message(paste0('ASSESS COVAR CONTI COVAR : ', cc))
      #   if (is.null(limma.bc.covar)) limma.bc.covar <- as.matrix(DE2obj@colData[, cc, drop = FALSE]) else limma.bc.covar <- cbind(limma.bc.covar, as.matrix(DE2obj@colData[, cc, drop = FALSE]))
      # }
      # 
      # #### Testing if design matrix is full-rank
      # test.batch <- limma.bc.batch1
      # test.batch2 <- limma.bc.batch2
      # test.covariates <- limma.bc.covar
      # test.design = model.matrix(as.formula(paste0('~0+', cur.cond)), data = DE2obj@colData)
      # if (!is.null(test.batch)) {
      #   test.batch <- as.factor(test.batch)
      #   contrasts(test.batch) <- contr.sum(levels(test.batch))
      #   test.batch <- model.matrix(~test.batch)[, -1, drop = FALSE]
      # }
      # if (!is.null(test.batch2)) {
      #   test.batch2 <- as.factor(test.batch2)
      #   contrasts(test.batch2) <- contr.sum(levels(test.batch2))
      #   test.batch2 <- model.matrix(~test.batch2)[, -1, drop = FALSE]
      # }
      # if (!is.null(test.covariates)) test.covariates <- as.matrix(test.covariates)
      # X.batch <- cbind(test.batch, test.batch2, test.covariates)
      # test.designX = as.matrix(cbind(test.design, X.batch))
      # ne <- limma::nonEstimable(test.designX)
      # rm(test.batch, test.batch2, test.covariates, X.batch, test.designX)
      # 
      # if(!is.null(ne)) {
      #   message(paste(ne, collapse = ', '))
      #   ## Matrix is NOT full-rank, NO regression !
      #   message("Can't estimate ", fc, ' as design matrix is not full-rank !')
      #   # print(paste0("Can't estimate ", fc, ' as design matrix is not full-rank !'))
      # } else {
      #   ## Matrix is full-rank, one can regress !
      #   ber_method <- 'limma'
      #   if (is.null(limma.bc.batch2) & is.null(limma.bc.covar)) {
      #   ## If only ONE CATEGORIAL covariate, use sva::ComBat
      #     ber_method <- 'ComBat'
      #     norm.mat <- sva::ComBat(dat = norm.mat, batch = limma.bc.batch1, mod = model.matrix(as.formula(paste0('~', cur.cond)), data = SummarizedExperiment::colData(DE2obj)), BPPARAM = BPPARAM)
      #   } else {
      #   ## Else use limma::removeBatchEffect
      #   norm.mat <- limma::removeBatchEffect(x = norm.mat, batch = limma.bc.batch1, batch2 = limma.bc.batch2, covariates = limma.bc.covar, design = model.matrix(as.formula(paste0('~0+', cur.cond)), data = SummarizedExperiment::colData(DE2obj)))
      #   }
      #   
      #   ## Save BER matrix 
      #   write.table(x = data.frame(Feature = rownames(norm.mat), norm.mat, check.names = FALSE), file = gzfile(paste0(de.dir, '/Normalized.vst.BER.', ber_method, '_matrix.tsv.gz')), sep = '\t', quote = FALSE, row.names = FALSE)
      #   
      #   ### Assessing covariates (after regression)
      #   ## All genes
      #   try(assess_covar(
      #     mat = norm.mat
      #     , annot.df = as.data.frame(DE2obj@colData)
      #     , factor.names = c(cur.cond, factor.colnames)
      #     , conti.names = conti.colnames
      #     , red.method = 'pca'
      #     , ndim.max = round(ncol(norm.mat)/2)
      #     , center = TRUE
      #     , scale = TRUE
      #     , out.file = paste(c(paste0(de.dir, '/', cur.cond), 'assess', 'covariates', 'All', '02', 'regressed.svg'), collapse = '_')
      #     ))
      #   ## Topvar
      #   try(assess_covar(
      #     mat = norm.mat
      #     , annot.df = as.data.frame(DE2obj@colData)
      #     , factor.names = c(cur.cond, factor.colnames)
      #     , conti.names = conti.colnames
      #     , red.method = 'pca'
      #     , topvar = vst_nsub
      #     , ndim.max = round(ncol(norm.mat)/2)
      #     , center = TRUE
      #     , scale = TRUE
      #     , out.file = paste(c(paste0(de.dir, '/', cur.cond), 'assess', 'covariates', paste0('Top', vst_nsub), '02', 'regressed.svg'), collapse = '_')
      #   ))
      # }
    }
    
    ### PCAs for DESIGN covariates ====
    library(ggfortify)
    for (p in c(cur.cond, cur.covars)) {
      pf <- paste0(de.dir, '/PCA_vst_', p, '.svg')
      ph <- 1000
      pw <- 1100
      svg(filename = pf, width = pw/96, height = ph/96)
      try(print(ggplot2::autoplot(prcomp(t(norm.mat)), data = as.data.frame(SummarizedExperiment::colData(DE2obj)), colour = p, size = 3)), silent = TRUE)
      svg_off()
    }
    
    ## Assessing TEST covariates, and regressing if requested
    if (any(!is.null(c(assess.factor, assess.conti)))) {
      test.mat <- SummarizedExperiment::assay(DE2obj.norm)
      test.dir <- paste0(de.dir, '/Test_covariates')
      # dir.create(test.dir)
      
      tmp.annot <- as.data.frame(SummarizedExperiment::colData(DE2obj))
      
      ### plot PCA of normalized,unregressed data colored by TEST covariates
      Utest.dir <- paste0(test.dir, '/PCA_UNREGRESSED')
      dir.create(path = Utest.dir, recursive = TRUE)
      for (p in unique(c(cur.cond, assess.factor, assess.conti))) {
        pf <- paste0(Utest.dir, '/PCA_vst_UNREGRESSED_col.', p, '.svg')
        pw <- 1100
        ph <- 1000
        svg(filename = pf, width = pw/96, height = ph/96)
        library(ggfortify)
        try(print(ggplot2::autoplot(prcomp(t(test.mat)), data = tmp.annot, colour = p, size = 3)), silent = TRUE)
        svg_off()
      }
      
      Atest.dir <- paste0(test.dir, '/ASSESS_MAP')
      dir.create(path = Atest.dir, recursive = TRUE)
      
      ### Plotting UNREGRESSED assessment heatmap ====
      ## All
      try(assess_covar(
        mat = test.mat
        , annot.df = tmp.annot
        , factor.names = c(cur.cond, assess.factor)
        , conti.names = assess.conti
        , red.method = 'pca'
        , ndim.max = min(round(ncol(test.mat)/2), 20)
        , center = TRUE
        , scale = TRUE
        , out.file = paste(c(paste0(Atest.dir, '/', cur.cond), 'TEST', 'covariates', 'All', '01', 'unregressed.svg'), collapse = '_')
        ))
      
      ## Topvar
      try(assess_covar(
        mat = test.mat
        , annot.df = tmp.annot
        , factor.names = c(cur.cond, assess.factor)
        , conti.names = assess.conti
        , red.method = 'pca'
        , topvar = vst_nsub
        , ndim.max = min(round(ncol(test.mat)/2), 20)
        , center = TRUE
        , scale = TRUE
        , out.file = paste(c(paste0(Atest.dir, '/', cur.cond), 'TEST', 'covariates', paste0('Topvar', vst_nsub), '01', 'unregressed.svg'), collapse = '_')
      ))
      
      Rtest.dir <- paste0(test.dir, '/PCA_REGRESSED')
      dir.create(path = Rtest.dir, recursive = TRUE)
      
      #### 1) Handling CONTINUOUS covariates
      for (cc in assess.conti) {
        message(paste0('ASSESS COVAR UNREGRESSED CONTI COVAR : ', cc))
        
        #### 
        test.covariates <- tmp.annot[[cc]]
        if(all(!is.na(test.covariates))) {
          
          ber_mat <- try(
            matrix_covar_regress(
              mat = test.mat
              , type = 'norm'
              , covar_conti_df = as.data.frame(SummarizedExperiment::colData(DE2obj))[, cc, drop = FALSE]
              , group = as.factor(SummarizedExperiment::colData(DE2obj)[[cur.cond]])
            )
            , silent = TRUE)
          if (!is(ber_mat, class2 = 'try-error')) {
            ## Plotting REGRESSED assessment heatmap
            ## All
            try(assess_covar(
              mat = ber_mat
              , annot.df = as.data.frame(DE2obj@colData)
              , factor.names = c(cur.cond, assess.factor)
              , conti.names = assess.conti
              , red.method = 'pca'
              , ndim.max = min(round(ncol(ber_mat)/2), 20)
              , center = TRUE
              , scale = TRUE
              , out.file = paste0(paste(c(paste0(Atest.dir, '/', cur.cond), 'TEST', 'covariates', 'All', '02', 'REGRESSED', cc), collapse = '_'), '.svg')
            ))
            ## Topvar
            try(assess_covar(
              mat = ber_mat
              , annot.df = as.data.frame(DE2obj@colData)
              , factor.names = c(cur.cond, assess.factor)
              , conti.names = assess.conti
              , red.method = 'pca'
              , topvar = vst_nsub
              , ndim.max = min(round(ncol(ber_mat)/2), 20)
              , center = TRUE
              , scale = TRUE
              , out.file = paste0(paste(c(paste0(Atest.dir, '/', cur.cond), 'TEST', 'covariates', paste0('Topvar', vst_nsub), '02', 'REGRESSED', cc), collapse = '_'), '.svg')
            ))
            ## PCA of REGRESSED data colored by cur.cond
            pf <- paste0(Rtest.dir, '/PCA_vst_REGRESSED.limma.', cc, '_col.', cur.cond, '.svg')
            pw <- 1100
            ph <- 1000
            svg(filename = pf, width = pw/96, height = ph/96)
            library(ggfortify)
            try(print(ggplot2::autoplot(prcomp(t(ber_mat)), data = as.data.frame(SummarizedExperiment::colData(DE2obj)), colour = cur.cond, size = 3)), silent = TRUE)
            svg_off()
          }
        }
      }
      
      #### 2) Handling CATEGORICAL (FACTOR) covariates
      for (fc in assess.factor) {
          
        #### CombatSeq case
        test.covariates <- tmp.annot[[fc]]
        test.covariates <- droplevels(test.covariates)
        if(all(!is.na(test.covariates))) {
          if (min(table(test.covariates)) > 1) {
            ber_mat <- try(
              DESeq2::vst(
                object = matrix_covar_regress(
                  mat = SummarizedExperiment::assay(DE2obj)
                  , type = 'counts'
                  , covar_factor_df = as.data.frame(SummarizedExperiment::colData(DE2obj))[, fc, drop = FALSE]
                  , group = as.factor(SummarizedExperiment::colData(DE2obj)[[cur.cond]])
                )
                , blind = TRUE
                , nsub = vst_nsub
              )
              , silent = TRUE)
          } else {
            ber_mat <- try(
              matrix_covar_regress(
                mat = test.mat
                , type = 'norm'
                , covar_factor_df = as.data.frame(SummarizedExperiment::colData(DE2obj))[, fc, drop = FALSE]
                , group = as.factor(SummarizedExperiment::colData(DE2obj)[[cur.cond]])
              )
              , silent = TRUE)
          }
          if (!is(ber_mat, class2 = 'try-error')) {
            ## Plotting REGRESSED assessment heatmap
            ## All
            try(assess_covar(
              mat = ber_mat
              , annot.df = as.data.frame(DE2obj@colData)
              , factor.names = c(cur.cond, assess.factor)
              , conti.names = assess.conti
              , red.method = 'pca'
              , ndim.max = min(round(ncol(ber_mat)/2), 20)
              , center = TRUE
              , scale = TRUE
              , out.file = paste0(paste(c(paste0(Atest.dir, '/', cur.cond), 'TEST', 'covariates', 'All', '02', 'REGRESSED', fc), collapse = '_'), '.svg')
            ))
            ## Topvar
            try(assess_covar(
              mat = ber_mat
              , annot.df = as.data.frame(DE2obj@colData)
              , factor.names = c(cur.cond, assess.factor)
              , conti.names = assess.conti
              , red.method = 'pca'
              , topvar = vst_nsub
              , ndim.max = min(round(ncol(ber_mat)/2), 20)
              , center = TRUE
              , scale = TRUE
              , out.file = paste0(paste(c(paste0(Atest.dir, '/', cur.cond), 'TEST', 'covariates', paste0('Topvar', vst_nsub), '02', 'REGRESSED', fc), collapse = '_'), '.svg')
            ))
            
            ### plot PCA of REGRESSED data colored by cur.cond
            pf <- paste0(Rtest.dir, '/PCA_vst_REGRESSED.limma.', fc, '_col.', cur.cond, '.svg')
            pw <- 1100
            ph <- 1000
            svg(filename = pf, width = pw/96, height = ph/96)
            library(ggfortify)
            try(print(ggplot2::autoplot(prcomp(t(ber_mat)), data = tmp.annot, colour = cur.cond, size = 3)), silent = TRUE)
            svg_off()
          } else (message('FAIL2!'))
        }
      }
          
        ################################""
          
      #   #### Testing if design matrix is full-rank
      #   test.covariates <- tmp.annot[[cc]]
      #   if(all(!is.na(test.covariates))) {
      #     test.design = model.matrix(as.formula(paste0('~0+', cur.cond)), data = DE2obj@colData)
      #     test.covariates <- as.matrix(test.covariates)
      #     test.designX = as.matrix(cbind(test.design, test.covariates))
      #     ne <- limma::nonEstimable(test.designX)
      #     rm(test.covariates, test.designX)
      #     
      #     if(!is.null(ne)) {
      #       message(paste(ne, collapse = ', '))
      #       ## Matrix is NOT full-rank, NO regression !
      #       message("Can't estimate ", cc, ' as design matrix is not full-rank !')
      #       # print(paste0("Can't estimate ", cc, ' as design matrix is not full-rank !'))
      #     } else {
      #       ## Regressing the continuous covariate
      #       ber.try <- try(tmp.mat <- limma::removeBatchEffect(x = test.mat, batch = NULL, batch2 = NULL, covariates = tmp.annot[[cc]], design = model.matrix(as.formula(paste0('~0+', cur.cond)), data = DE2obj.norm@colData)), silent = TRUE)
      #       if (!is(ber.try, class2 = 'try-error')) {
      #         ## Plotting REGRESSED assessment heatmap
      #         ## All
      #         try(assess_covar(
      #           mat = tmp.mat
      #           , annot.df = as.data.frame(DE2obj@colData)
      #           , factor.names = c(cur.cond, assess.factor)
      #           , conti.names = assess.conti
      #           , red.method = 'pca'
      #           , ndim.max = round(ncol(tmp.mat)/2)
      #           , center = TRUE
      #           , scale = TRUE
      #           , out.file = paste0(paste(c(paste0(Atest.dir, '/', cur.cond), 'TEST', 'covariates', 'All', '02', 'REGRESSED', cc), collapse = '_'), '.svg')
      #           ))
      #         ## Topvar
      #         try(assess_covar(
      #           mat = tmp.mat
      #           , annot.df = as.data.frame(DE2obj@colData)
      #           , factor.names = c(cur.cond, assess.factor)
      #           , conti.names = assess.conti
      #           , red.method = 'pca'
      #           , topvar = vst_nsub
      #           , ndim.max = round(ncol(tmp.mat)/2)
      #           , center = TRUE
      #           , scale = TRUE
      #           , out.file = paste0(paste(c(paste0(Atest.dir, '/', cur.cond), 'TEST', 'covariates', paste0('Topvar', vst_nsub), '02', 'REGRESSED', cc), collapse = '_'), '.svg')
      #         ))
      #         ### plot PCA of REGRESSED data colored by cur.cond
      #         pf <- paste0(Rtest.dir, '/PCA_vst_REGRESSED.limma.', cc, '_col.', cur.cond, '.svg')
      #         pw <- 1100
      #         ph <- 1000
      #         svg(filename = pf, width = pw/96, height = ph/96)
      #         library(ggfortify)
      #         try(print(ggplot2::autoplot(prcomp(t(tmp.mat)), data = as.data.frame(SummarizedExperiment::colData(DE2obj)), colour = cur.cond, size = 3)), silent = TRUE)
      #         svg_off()
      #       }
      #     }
      #   }
      # }
      # 
      # #### 2) Handling CATEGORICAL (FACTOR) covariates
      # for (fc in assess.factor) {
      #   message(paste0('ASSESS COVAR UNREGRESSED FACTOR COVAR : ', fc))
      #   #### Testing if design matrix is full-rank
      #   tmp.annot[[fc]] <- droplevels(tmp.annot[[fc]])
      #   test.batch <- tmp.annot[[fc]]
      #   test.design = model.matrix(as.formula(paste0('~0+', cur.cond)), data = DE2obj@colData)
      #   test.batch <- as.factor(test.batch)
      #   if(nlevels(test.batch) < 2) {
      #     message("Can't estimate ", fc, ' as it only has one level !')
      #     # print(paste0("Can't estimate ", fc, ' as it only has one level !'))
      #   } else {
      #     # contrasts(test.batch) <- contr.sum(levels(test.batch))
      #     test.batch <- model.matrix(~test.batch)[, -1, drop = FALSE]
      #     ## Handling NA batches
      #     if (!nrow(test.batch) == nrow(test.design)) {
      #       message("Can't estimate ", fc, " as it doesn't have the same size as the evaluated comparison (due to NAs) !")
      #     } else {
      #       # test.designX = as.matrix(cbind(test.design, test.batch))
      #       ne <- limma::nonEstimable(test.design)
      #       rm(test.batch, test.design)
      #       
      #       if(!is.null(ne)) {
      #         message(paste(ne, collapse = ', '))
      #         ## Matrix is NOT full-rank, NO regression !
      #         message("Can't estimate ", fc, ' as design matrix is not full-rank !')
      #         # print(paste0("Can't estimate ", fc, ' as design matrix is not full-rank !'))
      #       } else {
      #         ## Matrix is full-rank, one can regress !
      #         ## Regressing
      #         # ber.try <- try(tmp.mat <- limma::removeBatchEffect(x = test.mat, batch = tmp.annot[[fc]], batch2 = NULL, covariates = NULL, design = model.matrix(as.formula(paste0('~0+', cur.cond)), data = tmp.annot)), silent = TRUE)
      #         
      #         ber.try <- try(tmp.mat <- sva::ComBat(dat = test.mat, batch = tmp.annot[[fc]], mod = model.matrix(as.formula(paste0('~', cur.cond)), data = SummarizedExperiment::colData(DE2obj)), BPPARAM = BPPARAM), silent = TRUE)
      #         if (!is(ber.try, class2 = 'try-error')) {
      #           ## Plotting REGRESSED assessment heatmap
      #           ## All
      #           try(assess_covar(
      #             mat = tmp.mat
      #             , annot.df = tmp.annot
      #             , factor.names = c(cur.cond, assess.factor)
      #             , conti.names = assess.conti
      #             , red.method = 'pca'
      #             , ndim.max = round(ncol(tmp.mat)/2)
      #             , center = TRUE
      #             , scale = TRUE
      #             , out.file = paste0(paste(c(paste0(Atest.dir, '/', cur.cond), 'TEST', 'covariates', 'All', '02', 'REGRESSED', fc), collapse = '_'), '.svg')
      #             ))
      #           ## Topvar
      #           try(assess_covar(
      #             mat = tmp.mat
      #             , annot.df = tmp.annot
      #             , factor.names = c(cur.cond, assess.factor)
      #             , conti.names = assess.conti
      #             , red.method = 'pca'
      #             , topvar = vst_nsub
      #             , ndim.max = round(ncol(tmp.mat)/2)
      #             , center = TRUE
      #             , scale = TRUE
      #             , out.file = paste0(paste(c(paste0(Atest.dir, '/', cur.cond), 'TEST', 'covariates', paste0('Topvar', vst_nsub), '02', 'REGRESSED', fc), collapse = '_'), '.svg')
      #           ))
      #           ### plot PCA of REGRESSED data colored by cur.cond
      #           pf <- paste0(Rtest.dir, '/PCA_vst_REGRESSED.limma.', fc, '_col.', cur.cond, '.svg')
      #           pw <- 1100
      #           ph <- 1000
      #           svg(filename = pf, width = pw/96, height = ph/96)
      #           library(ggfortify)
      #           try(print(ggplot2::autoplot(prcomp(t(tmp.mat)), data = tmp.annot, colour = cur.cond, size = 3)), silent = TRUE)
      #           svg_off()
      #         }
      #       }
      #     }
      #   }
      # }
    }
    
    ## Remove temporary VST object
    rm(DE2obj.norm)
    
    ## Performing the DE test ====
    set.seed(my_seed)
    htg.de.wald <- DESeq2::DESeq(DE2obj)
    
    ## Saving the Wald test DESeq object
    # if(save.wald) saveRDS(object = htg.de.wald, file = paste0(factor.dir, '/', cur.cond, '_wald.RDS'), compress = 'bzip2')
    if(save.wald) saveRDS(object = htg.de.wald, file = paste0(de.dir, '/', cur.cond, '_wald.RDS'), compress = 'bzip2')
    
    ## Creating output dir
    mycoef <- paste0(cur.cond, ' : ', paste(cur.condA, collapse='+'), ' -vs- ', paste(cur.condB, collapse='+'))
    message(mycoef)
    message(cur.name)
    
    ### Getting results table for current contrast ====
    # mycontrast <- sapply(all.combz[[mycomb]], function(x) { paste0(cur.cond, x)}, simplify = FALSE)
    # mycontrast <- list(cur.condA, cur.condB)
    mycontrast <- list(paste0(cur.cond, cur.condA), paste0(cur.cond, cur.condB))
    # myvalues <- c(rep(1/length(cur.condA), length(cur.condA)), rep(-1/length(cur.condB), length(cur.condB)))
    myvalues <- c(1, -1/length(cur.condB))
    if (ihw) {
      set.seed(my_seed)
      DEres <- DESeq2::results(htg.de.wald, contrast = mycontrast, listValues = myvalues, independentFiltering = TRUE, alpha = adjp.max, pAdjustMethod = "BH", parallel = TRUE, BPPARAM = BPPARAM, filterFun = IHW::ihw)
    } else {
      DESeq2::results(htg.de.wald, contrast = mycontrast, listValues = myvalues, independentFiltering = TRUE, alpha = adjp.max, pAdjustMethod = "BH", parallel = TRUE, BPPARAM = BPPARAM)
    }
    ## Saving the test results object
    saveRDS(object = DEres, file = paste0(de.dir, '/', cur.name, '_results.RDS'), compress = 'bzip2')
    
    ## Shrinking l2fc
    if (lfcShrink) {
      set.seed(my_seed)
      suppressMessages(DEres <- DESeq2::lfcShrink(htg.de.wald, contrast = mycontrast, type = 'ashr', res = DEres))
      ## Saving the test reults object
      saveRDS(object = DEres, file = paste0(de.dir, '/', cur.name, '_results_lfcShrink.RDS'), compress = 'bzip2')
    }
    # rm(htg.de.wald)
    
    ## Histogram of P-values
    pf <- paste0(cut.dir, '/', cur.name, '_phist.svg')
    pw <- 2048
    ph <- 768
    svg(filename = pf, width = pw/96, height = ph/96)
    par <- par(mfrow = c(1, 2))
    hist(DEres$pvalue, col = "lightblue", main = paste0("Histogram of raw P-values (DESeq2)\n", mycoef), breaks = 100, xlim = c(0,1), xlab = "P-value")
    hist(DEres$padj, col = "lightblue", main = paste0("Histogram of BH-adjusted P-values (DESeq2)\n", mycoef), breaks = 100, xlim = c(0,1), xlab = "P-value")
    abline(v = adjp.max, col = 2, lty = 2)
    svg_off()

    ## MAplot
    pf <- paste0(cut.dir, '/', cur.name, '_MA.svg')
    pw <- 1024
    ph <- 768
    svg(filename = pf, width = pw/96, height = ph/96)
    DESeq2::plotMA(DEres, alpha = adjp.max, main = paste0("M-A Plot\n", mycoef), cex = 1)
    svg_off()

    ## Volcano plot
    deg.idx <- DEres$padj <= adjp.max & abs(DEres$log2FoldChange) >= lfc.min
    pf <- paste0(cut.dir, '/', cur.name, '_volcano.svg')
    pw <- 1024
    ph <- 768
    svg(filename = pf, width = pw/96, height = ph/96)
    plot(x = DEres$log2FoldChange, y = -log10(DEres$padj), xlab = "log2(Fold-Change)", ylab = "-log10(adjusted P-value)", col = ifelse(deg.idx, "red", "black"), main = paste0("Volcano plot\n", mycoef), pch = 20)
    grid()
    abline(h = -log10(adjp.max), lty = 2, col = 4)
    abline(v = lfc.min * c(-1, 1), lty = 2, col = 4)
    svg_off()

    ## Computing per-class metrics
    mc.samp.idx <- lapply(levels(SummarizedExperiment::colData(DE2obj)[[cur.cond]]), function(mc.lev) {
      which(SummarizedExperiment::colData(DE2obj)[[cur.cond]] == mc.lev)
    })
    names(mc.samp.idx) <- levels(SummarizedExperiment::colData(DE2obj)[[cur.cond]])
    mc.metrics <- lapply(names(mc.samp.idx), function(mc.lev) {
      mydf <- data.frame(N = length(mc.samp.idx[[mc.lev]])
                         , Min = rowMins(norm.mat[,mc.samp.idx[[mc.lev]]], dims = 1)
                         , Max = rowMaxs(norm.mat[,mc.samp.idx[[mc.lev]]], dims = 1)
                         , Mean = rowMeans(norm.mat[,mc.samp.idx[[mc.lev]]], dims = 1)
                         , Median = matrixStats::rowMedians(x = norm.mat, cols = mc.samp.idx[[mc.lev]])
                         , matrixStats::rowQuantiles(x = norm.mat, cols = mc.samp.idx[[mc.lev]], probs = c(.25, .75)))
      colnames(mydf) <- paste0(mc.lev, '.', c(colnames(mydf)[1:(ncol(mydf)-2)], 'Q25', 'Q75'))
      return(mydf)
    })
    ## Output table
    DEres.df <- cbind(Symbol = rownames(DEres), as.data.frame(DEres), Reduce(f = cbind, x = mc.metrics))
    sig.word <- paste0('Sig_@adjp', adjp.max, '_lfc', lfc.min)
    DEres.df[[sig.word]] <- 0
    DEres.df[[sig.word]][deg.idx] <- 1
    DEres.df <- DEres.df[order(DEres.df$padj, abs(DEres.df$log2FoldChange), decreasing = c(FALSE, TRUE)),]
    write.table(DEres.df, file = gzfile(paste0(cut.dir, '/', cur.name, '_results.tsv.gz')), sep = '\t', quote = FALSE, row.names = FALSE)
    WriteXLS::WriteXLS(x = DEres.df, ExcelFileName = paste0(cut.dir, '/', cur.name, '_results.xlsx'), SheetNames = cur.name, AdjWidth = TRUE, AutoFilter = TRUE, BoldHeaderRow = TRUE, FreezeCol = 1, FreezeRow = 1, na = c(NA, '', 'NA', 'na'))
    
    sig.genes <- as.character(DEres.df$Symbol[DEres.df[sig.word] == 1])
    
    ## Draw gene boxplot
    if(boxplots & length(sig.genes) > 0) {
      gdir <- paste0(cut.dir, '/boxplots')
      dir.create(path = gdir, recursive = TRUE)
      for (g in sig.genes[1:(min(length(sig.genes), or.top.max))]) {
        pf <- paste0(gdir, '/', gsub(pattern = "\\W", replacement = '.', x = g), '_norm.exp_boxplot.svg')
        pw <- 800
        ph <- 600
        svg(filename = pf, width = pw/96, height = ph/96)
        sig.split <- split(norm.mat[g, ], droplevels(SummarizedExperiment::colData(DE2obj)[[cur.cond]]))
        boxplot2l(x = sig.split, col = seq_along(sig.split), main = paste0(g, ' normalized expression VS ', cur.cond, '\nDESeq2 : l2FC = ', round(DEres.df[g, 'log2FoldChange'], digits = 3), ' ; adjP = ', format(DEres.df[g, 'padj'], scientific = TRUE, digits = 3)), xlab = '', ylab = 'Normalized expression', vertical = TRUE, cex = 2)
        svg_off()
      }
    }
    
    ## Setting a color palette for the heatmaps
    myRamp <- circlize::colorRamp2(c(-2, 0, 2), heatmap.palette)
    
    if (length(sig.genes) >= enr.min.genes & length(sig.genes) < 2000) {
      
      cur.annot <- as.data.frame(SummarizedExperiment::colData(DE2obj)[,c(cur.cond, cur.covars), drop = FALSE])
      # cur.samples.idx <- cur.annot[[cur.cond]] %in% unlist(all.combz[[mycomb]])
      
      ## Heatmap
      ## data to plot
      plotDat <- norm.mat[rownames(norm.mat) %in% sig.genes,]
      # plotDat <- norm.mat[rownames(norm.mat) %in% sig.genes, SummarizedExperiment::colData(DE2obj)[[cur.cond]] %in% unlist(all.combz[[mycomb]])]
      z.mat <- (plotDat - rowMeans(plotDat)) / matrixStats::rowSds(plotDat)
      
      # Creating sample annotation
      # ha1 = ComplexHeatmap::HeatmapAnnotation(df = SummarizedExperiment::colData(DE2obj)[,c(cur.cond, covar.colnames), drop = FALSE][SummarizedExperiment::colData(DE2obj)[[cur.cond]] %in% unlist(all.combz[[mycomb]]),])
      
      set.seed(1)
      # ha1 = ComplexHeatmap::HeatmapAnnotation(df = cur.annot[cur.samples.idx,c(cur.cond, cur.covars), drop = FALSE])
      ha1 = ComplexHeatmap::HeatmapAnnotation(df = cur.annot[,c(cur.cond, cur.covars), drop = FALSE])
      
      ## Looping through requested clustering methods
      for (sdm in samples.dist.method) {
        for (shm in samples.hclust.method) {
          for (gdm in genes.dist.method) {
            for (ghm in genes.hclust.method) {
              ## Clustering samples
              hc.s <- hclust(amap::Dist(x = t(plotDat), method = sdm), method = shm)
              ## Clustering genes
              hc.g <- hclust(amap::Dist(x = plotDat, method = gdm), method = ghm)
              ## Compute heatmap
              set.seed(my.seed)
              myHM <- suppressMessages(ComplexHeatmap::Heatmap(z.mat, name = "Normalized counts"
                                                               # use my custom color palette
                                                               , col = myRamp
                                                               # do not show gene names
                                                               , show_row_name = TRUE
                                                               # do not clusterize samples
                                                               , cluster_columns = hc.s
                                                               , cluster_rows = hc.g
                                                               # add a nice grey border to cells
                                                               , rect_gp = grid::gpar(col = "darkgrey", lwd=0.5)
                                                               # add sample annotation
                                                               , top_annotation = ha1
                                                               , use_raster = TRUE
                                                               , raster_device = 'png'
              ))
              ## Draw heatmap
              pf_root <- paste0(cut.dir, '/', cur.name, '_sig.', nrow(z.mat), 'x', ncol(z.mat), '_', paste(c(gdm, ghm, sdm, shm), collapse = "_"))
              pw <- (max(min(ncol(z.mat) * 15, 2000), 600) + 200)
              ph <- (min(length(sig.genes) * 10, 5000) + 300)
              svg(filename = paste0(pf_root, '.heatmap.svg'), width = pw/96, height = ph/96)
              ComplexHeatmap::draw(myHM)
              svg_off()
              ## Save genes/samples clustering results
              ### Samples
              saveRDS(object = hc.s, file = paste0(pf_root, '.samples.hclust.rds'))
              cut_s <- cbind(Sample = hc.s$labels, as.data.frame(lapply(seq_along(hc.s$labels), function(k) as.factor(unname(stats::cutree(tree = hc.s, k = k))))))
              colnames(cut_s) <- c('Sample', paste0('cut.', seq_along(hc.s$labels)))
              WriteXLS::WriteXLS(x = cut_s, ExcelFileName = paste0(pf_root, '.samples.hclust.cutree.xlsx'), SheetNames = 'Hclust.cut', AdjWidth = TRUE, BoldHeaderRow = TRUE, FreezeRow = 1, FreezeCol = 1)
              ### Genes
              saveRDS(object = hc.g, file = paste0(pf_root, '.genes.hclust.rds'))
              cut_g <- cbind(Sample = hc.g$labels, as.data.frame(lapply(seq_along(hc.g$labels), function(k) as.factor(unname(stats::cutree(tree = hc.g, k = k))))))
              colnames(cut_g) <- c('Gene', paste0('cut.', seq_along(hc.g$labels)))
              WriteXLS::WriteXLS(x = cut_g, ExcelFileName = paste0(pf_root, '.genes.hclust.cutree.xlsx'), SheetNames = 'Hclust.cut', AdjWidth = TRUE, BoldHeaderRow = TRUE, FreezeRow = 1, FreezeCol = 1)
              
            }
          }
        }
      }
    }
    
    ## Shorter heatmap if more sig genes than requested "topN"
    if(length(sig.genes) > or.top.max) {
      
      cur.annot <- as.data.frame(SummarizedExperiment::colData(DE2obj)[,c(cur.cond, cur.covars), drop = FALSE])
      
      ## Heatmap
      ## data to plot
      sig.genes <- sig.genes[1:or.top.max]
      
      # sig.genes <- as.character(DEres.df$Symbol[DEres.df[[sig.word]] == 1][1:or.top.max])
      
      # sig.genes <- as.character(DEres.df$Symbol[DEres.df$cuts.in == 1][1:or.top.max])
      # plotDat <- norm.mat[rownames(norm.mat) %in% sig.genes, cur.samples.idx]
      plotDat <- norm.mat[rownames(norm.mat) %in% sig.genes,]
      # plotDat <- norm.mat[rownames(norm.mat) %in% sig.genes, SummarizedExperiment::colData(DE2obj)[[cur.cond]] %in% unlist(all.combz[[mycomb]])]
      z.mat <- (plotDat - rowMeans(plotDat)) / matrixStats::rowSds(plotDat)
      # Creating sample annotation
      # ha1 = ComplexHeatmap::HeatmapAnnotation(df = SummarizedExperiment::colData(DE2obj)[,c(cur.cond, covar.colnames)][annot.df[[cur.cond]] %in% unlist(all.combz[[mycomb]]),])
      set.seed(1)
      # ha1 = ComplexHeatmap::HeatmapAnnotation(df = cur.annot[cur.samples.idx,c(cur.cond, cur.covars), drop = FALSE])
      ha1 = ComplexHeatmap::HeatmapAnnotation(df = cur.annot[,c(cur.cond, cur.covars), drop = FALSE])
      ## Clustering samples
      for (sdm in samples.dist.method) {
        for (shm in samples.hclust.method) {
          for (gdm in genes.dist.method) {
            for (ghm in genes.hclust.method) {
              hc.s <- hclust(amap::Dist(x = t(plotDat), method = sdm), method = shm)
              ## Clustering genes
              hc.g <- hclust(amap::Dist(x = plotDat, method = gdm), method = ghm)
              ## Computing heatmap
              myHM <- suppressMessages(ComplexHeatmap::Heatmap(z.mat, name = "Normalized counts",
                                                               col = myRamp,
                                                               show_row_name = TRUE,
                                                               cluster_columns = hc.s,
                                                               cluster_rows = hc.g,
                                                               rect_gp = grid::gpar(col = "darkgrey", lwd=0.5),
                                                               top_annotation = ha1))
              ## Draw
              pf <- paste0(cut.dir, '/', cur.name, '_sig.TOP', nrow(z.mat), 'x', ncol(z.mat), '_', paste(c(gdm, ghm, sdm, shm), collapse = "_"), '.heatmap.svg')
              pw <- (max(min(ncol(z.mat) * 15, 2000), 600) + 200)
              ph <- (min(length(sig.genes) * 10, 5000) + 300)
(min(length(sig.genes) * 10, 5000) + 300)
              svg(filename = pf, width = pw/96, height = ph/96)
              ComplexHeatmap::draw(myHM)
              svg_off()
              # dev.off()
              # svg_convert(svg_files = pf, format = 'png', height = ph)
            }
          }
        }
      }
    }
    
    ## Functional enrichment
    ### Handle cases (force GSEA, minimum genes requirement, etc...)
    ## Convert all ".go" into a matrix
    # gsea_go <- 
    if (any(unlist(msigdb.do), kegg.do, do.do, go.do, wp.do, reactome.do, mesh.do, custom.do) & length(which(deg.idx)) >= enr.min.genes & !is.null(species)) {
      
      enr.inputs <- table2enr(deseq2.res.data = DEres.df, species = species, geneid.colname = 'Symbol', geneid.type = 'SYMBOL', stat.colname = 'log2FoldChange', topN.max = or.top.max, p.colname = 'padj', p.cutoff = adjp.max, stat.keep.operator = '>', stat.abs = TRUE, stat.cutoff = lfc.min)
      
      ## MSIGDB
      if (any(unlist(msigdb.do))) {
        ### Get collections
        msigdb.collec <- as.data.frame(msigdbr::msigdbr_collections())
        ### Add a tag to cross with provided msigdb.do names
        msigdb.collec$tag <- paste(msigdb.collec$gs_cat, msigdb.collec$gs_subcat, sep = '.')
        msigdb.collec$tag <- sub(pattern = '\\.$', replacement = '', x = msigdb.collec$tag)
        ### Restrict to requested names
        if (is.list(msigdb.do)) {
          msigdb.collec <- msigdb.collec[msigdb.collec$tag %in% names(msigdb.do),]
        } else if (length(msigdb.do) == 2 & all(is.logical(msigdb.do))) {
          msigdb.do <- lapply(msigdb.collec$tag, function(x) { return(msigdb.do) })
          names(msigdb.do) <- msigdb.collec$tag
        }
        ### Loop on collections
        for (mc in msigdb.collec$tag) {
          msc <- if(msigdb.collec[msigdb.collec$tag == mc,2] == '') msigdb.collec[msigdb.collec$tag == mc,1] else paste(c(msigdb.collec[msigdb.collec$tag == mc,1], msigdb.collec[msigdb.collec$tag == mc,2]), collapse = '_')
          ## Import the TERM2GENE object corresponding to the desired category/subcategory combo
          my.t2g <- msigdb_to_t2g(species = species, category = msigdb.collec[msigdb.collec$tag == mc,1], subcategory = msigdb.collec[msigdb.collec$tag == mc,2])
          ### GSEA
          if (msigdb.do[[mc]][1]) {
            my.gsea.res <- try(gsea_run(geneList = enr.inputs$gsea.genevec, species = species, func.name = 'clusterProfiler::GSEA', t2g = my.t2g, t2g.name = msc, gene2Symbol = enr.inputs$gene2Symbol, seed = my.seed, pvalueCutoff = enrp.max, minGSSize = enr.min.genes))
            ## Generate plots / outputs
            if (!is(my.gsea.res, class2 = 'try-error')) gsea_output(gseaResult = my.gsea.res, out.dir = cut.dir, comp.name = cur.name, heatplot = dotplot.maxterms, dotplot = dotplot.maxterms, barplot = dotplot.maxterms, gsea.plot = dotplot.maxterms, ridgeplot = dotplot.maxterms)
          }
          ### ORA
          if(msigdb.do[[mc]][2]) {
            my.ora.res <- try(ora_run(gene = enr.inputs$ora.genevec, universe = unname(enr.inputs$gene2Symbol), species = species, func.name = 'clusterProfiler::enricher', t2g = my.t2g, t2g.name = msc, gene2Symbol = enr.inputs$gene2Symbol, pvalueCutoff = enrp.max, minGSSize = enr.min.genes))
            ## Generate plots / outputs
            if (!is(my.ora.res, class2 = 'try-error')) if (!is.null(my.ora.res)) ora_output(enrichResult = my.ora.res, out.dir = cut.dir, comp.name = cur.name, geneList = enr.inputs$gsea.genevec, heatplot = dotplot.maxterms, dotplot = dotplot.maxterms, barplot = dotplot.maxterms)
          }
        }
      }
      
      ## GO (gene ontology)
      if (any(go.do)) {
        ### GSEA
        if(go.do[1]) {
          func.name <- 'clusterProfiler::gseGO'
          for (x in c('BP', 'CC', 'MF')) {
            my.org <- paste0(msigdbr2org(species), '.db')
            library(my.org, character.only = TRUE)
            my.gsea.res <- try(gsea_run(geneList = enr.inputs$gsea.genevec, species = species, func.name = func.name, t2g = NULL, t2g.name = NULL, gene2Symbol = enr.inputs$gene2Symbol, seed = my.seed, pvalueCutoff = enrp.max, minGSSize = enr.min.genes, OrgDb = get(my.org), ont = x))
            if (!is(my.gsea.res, class2 = 'try-error')) {
              my.gsea.res@setType <- paste(c(my.gsea.res@setType, x), collapse = '_')
              ## Simplify
              if(nrow(my.gsea.res) > 1) {
                my.gsea.res@setType <- x
                my.gsea.res <- enrichplot::pairwise_termsim(my.gsea.res)
                my.gsea.res.simp <- clusterProfiler::simplify(my.gsea.res, cutoff = 0.7, by = "p.adjust", select_fun = min)
                if(nrow(my.gsea.res.simp) < nrow(my.gsea.res)) {
                  my.gsea.res.simp@setType <- paste(c(func.name, x, 'simplified'), collapse = '_')
                  gsea_output(gseaResult = my.gsea.res.simp, out.dir = cut.dir, comp.name = cur.name, heatplot = dotplot.maxterms, dotplot = dotplot.maxterms, barplot = dotplot.maxterms, gsea.plot = dotplot.maxterms, ridgeplot = dotplot.maxterms)
                } else {
                  my.gsea.res@setType <- paste(c(func.name, x), collapse = '_')
                  gsea_output(gseaResult = my.gsea.res, out.dir = cut.dir, comp.name = cur.name, heatplot = dotplot.maxterms, dotplot = dotplot.maxterms, barplot = dotplot.maxterms, gsea.plot = dotplot.maxterms, ridgeplot = dotplot.maxterms)
                }
              }
            }
          }
        }
        ### ORA
        if(go.do[2]) {
          func.name <- 'clusterProfiler::enrichGO'
          for (x in c('BP', 'CC', 'MF')) {
            my.org <- paste0(msigdbr2org(species), '.db')
            library(my.org, character.only = TRUE)
            my.ora.res <- ora_run(gene = enr.inputs$ora.genevec, species = species, func.name = func.name, t2g = NULL, t2g.name = NULL, gene2Symbol = enr.inputs$gene2Symbol, pvalueCutoff = enrp.max, minGSSize = enr.min.genes, OrgDb = get(my.org), ont = x)
            if (!is(my.ora.res, class2 = 'try-error')) {
              my.ora.res@ontology <- paste(c(my.ora.res@ontology, x), collapse = '_')
              ## Simplify
              if(nrow(my.ora.res) > 1) {
                my.ora.res@ontology <- x
                my.ora.res <- enrichplot::pairwise_termsim(my.ora.res)
                my.ora.res.simp <- clusterProfiler::simplify(my.ora.res, cutoff = 0.7, by = "p.adjust", select_fun = min)
                if(nrow(my.ora.res.simp) < nrow(my.ora.res)) {
                  my.ora.res.simp@ontology <- paste(c(func.name, x, 'simplified'), collapse = '_')
                  ora_output(enrichResult = my.ora.res.simp, out.dir = cut.dir, comp.name = cur.name, geneList = enr.inputs$gsea.genevec, heatplot = dotplot.maxterms, dotplot = dotplot.maxterms, barplot = dotplot.maxterms)
                } else {
                  my.ora.res@ontology <- paste(c(func.name, x), collapse = '_')
                  ora_output(enrichResult = my.ora.res, out.dir = cut.dir, comp.name = cur.name, geneList = enr.inputs$gsea.genevec, heatplot = dotplot.maxterms, dotplot = dotplot.maxterms, barplot = dotplot.maxterms)
                }
              }
            }
          }
        }
      }
      
      ## DO (disease ontology)
      if (any(do.do)) {
        ### GSEA
        if (do.do[1]) {
          for (x in c('DOSE::gseDO', 'DOSE::gseNCG', 'DOSE::gseDGN')) {
            my.gsea.res <- try(gsea_run(geneList = enr.inputs$gsea.genevec, species = species, func.name = x, t2g = NULL, t2g.name = NULL, gene2Symbol = enr.inputs$gene2Symbol, seed = my.seed, pvalueCutoff = enrp.max, minGSSize = enr.min.genes))
            if (!is(my.gsea.res, class2 = 'try-error')) gsea_output(gseaResult = my.gsea.res, out.dir = cut.dir, comp.name = cur.name, heatplot = dotplot.maxterms, dotplot = dotplot.maxterms, barplot = dotplot.maxterms, gsea.plot = dotplot.maxterms, ridgeplot = dotplot.maxterms)
          }
          ### ORA
          if(do.do[2]) {
            for (x in c('DOSE::enrichDO', 'DOSE::enrichNCG', 'DOSE::enrichDGN')) {
              my.ora.res <- try(ora_run(gene = enr.inputs$ora.genevec, species = species, func.name = x, t2g = NULL, t2g.name = NULL, gene2Symbol = enr.inputs$gene2Symbol, pvalueCutoff = enrp.max, minGSSize = enr.min.genes))
              if (!is(my.ora.res, class2 = 'try-error')) if (!is.null(my.ora.res)) ora_output(enrichResult = my.ora.res, out.dir = cut.dir, comp.name = cur.name, geneList = enr.inputs$gsea.genevec, heatplot = dotplot.maxterms, dotplot = dotplot.maxterms, barplot = dotplot.maxterms)
            }
          }
        }
      }
      
      ## KEGG/MKEGG
      ### NOTE1 : It's the same way to call the 'gsea_run' / 'ora_run' as it is for 'DO', 'NCG' or 'DGN', but here it's compatible with many more species than homo sapiens.
      ### NOTE2 : for this case, additional KEGG pathway plots will be generated.
      ### NOTE3 : for this case, an internet connexion is required to query the KEGG website.
      if (any(kegg.do)) {
        ### GSEA
        if (kegg.do[1]) {
          for (x in c('clusterProfiler::gseKEGG', 'clusterProfiler::gseMKEGG')) {
            my.gsea.res <- try(gsea_run(geneList = enr.inputs$gsea.genevec, species = species, func.name = x, t2g = NULL, t2g.name = NULL, gene2Symbol = enr.inputs$gene2Symbol, seed = my.seed, pvalueCutoff = enrp.max, minGSSize = enr.min.genes))
            if (!is(my.gsea.res, class2 = 'try-error')) gsea_output(gseaResult = my.gsea.res, out.dir = cut.dir, comp.name = cur.name, heatplot = dotplot.maxterms, dotplot = dotplot.maxterms, barplot = dotplot.maxterms, gsea.plot = dotplot.maxterms, ridgeplot = dotplot.maxterms)
          }
          ### ORA
          if(kegg.do[2]) {
            for (x in c('clusterProfiler::enrichKEGG', 'clusterProfiler::enrichMKEGG')) {
              my.ora.res <- try(ora_run(gene = enr.inputs$ora.genevec, species = species, func.name = x, t2g = NULL, t2g.name = NULL, gene2Symbol = enr.inputs$gene2Symbol, pvalueCutoff = enrp.max, minGSSize = enr.min.genes))
              if (!is(my.ora.res, class2 = 'try-error')) if (!is.null(my.ora.res)) ora_output(enrichResult = my.ora.res, out.dir = cut.dir, comp.name = cur.name, geneList = enr.inputs$gsea.genevec, heatplot = dotplot.maxterms, dotplot = dotplot.maxterms, barplot = dotplot.maxterms)
            }
          }
        }
      }
      
      ## WP (wikipathways)
      if(any(wp.do)) { 
        if(wp.do[1]) {
          ### GSEA
          func.name <- 'clusterProfiler::gseWP'
          my.gsea.res <- try(gsea_run(geneList = enr.inputs$gsea.genevec, organism = species, func.name = func.name, t2g = NULL, t2g.name = NULL, gene2Symbol = enr.inputs$gene2Symbol, seed = my.seed, pvalueCutoff = enrp.max, minGSSize = enr.min.genes))
          if (!is(my.gsea.res, class2 = 'try-error')) gsea_output(gseaResult = my.gsea.res, out.dir = cut.dir, comp.name = cur.name, heatplot = dotplot.maxterms, dotplot = dotplot.maxterms, barplot = dotplot.maxterms, gsea.plot = dotplot.maxterms, ridgeplot = dotplot.maxterms)
        }
        ### ORA
        if(wp.do[2]) {
          func.name <- 'clusterProfiler::enrichWP'
          my.ora.res <- ora_run(gene = enr.inputs$ora.genevec, organism = species, func.name = func.name, t2g = NULL, t2g.name = NULL, gene2Symbol = enr.inputs$gene2Symbol, pvalueCutoff = enrp.max, minGSSize = enr.min.genes)
          if (!is(my.ora.res, class2 = 'try-error')) if (!is.null(my.ora.res)) ora_output(enrichResult = my.ora.res, out.dir = cut.dir, comp.name = cur.name, geneList = enr.inputs$gsea.genevec, heatplot = dotplot.maxterms, dotplot = dotplot.maxterms, barplot = dotplot.maxterms)
        }
      }
      
      ## REACTOME
      if (any(reactome.do)) {
        org.name <- paste0(msigdbr2org(species = species), '.db')
        library(org.name, character.only = TRUE)
        reactome.org <- tolower(convert_species_name(OrgDb = get(org.name)))
        if(reactome.do[1]) {
          ### GSEA
          func.name <- 'ReactomePA::gsePathway'
          my.gsea.res <- gsea_run(geneList = enr.inputs$gsea.genevec, organism = reactome.org, func.name = func.name, t2g = NULL, t2g.name = NULL, gene2Symbol = enr.inputs$gene2Symbol, seed = my.seed, pvalueCutoff = enrp.max, minGSSize = enr.min.genes)
          my.gsea.res@setType <- paste0(func.name, '_Reactome')
          gsea_output(gseaResult = my.gsea.res, out.dir = cut.dir, comp.name = cur.name, heatplot = dotplot.maxterms, dotplot = dotplot.maxterms, barplot = dotplot.maxterms, gsea.plot = dotplot.maxterms, ridgeplot = dotplot.maxterms)
        }
        if(reactome.do[2]) {
          ### ORA
          func.name <- 'ReactomePA::enrichPathway'
          my.ora.res <- ora_run(gene = enr.inputs$ora.genevec, organism = reactome.org, func.name = func.name, t2g = NULL, t2g.name = NULL, gene2Symbol = enr.inputs$gene2Symbol, pvalueCutoff = enrp.max, minGSSize = enr.min.genes)
          my.ora.res@ontology <- paste0(func.name, '_Reactome')
          if (!is(my.ora.res, class2 = 'try-error')) if (!is.null(my.ora.res)) ora_output(enrichResult = my.ora.res, out.dir = cut.dir, comp.name = cur.name, geneList = enr.inputs$gsea.genevec, heatplot = dotplot.maxterms, dotplot = dotplot.maxterms, barplot = dotplot.maxterms)
        }
      }
      
      ## CELLMARKER
      ### Assess cell types from an online table
      ### NOTE : It's the same way to call the 'gsea_run' / 'ora_run' functions as for MSIGDB, but with a single bank (so, no loop).
      # if (any(cm.do)) {
      #   ### GSEA
      #   if (cm.do[1]) {
      #     my.gsea.res <- try(gsea_run(geneList = enr.inputs$gsea.genevec, species = species, func.name = 'clusterProfiler::GSEA', t2g = cell_markers, t2g.name = 'CellMarker', gene2Symbol = enr.inputs$gene2Symbol, seed = my.seed, pvalueCutoff = enrp.max, minGSSize = enr.min.genes))
      #     if (!is(my.gsea.res, class2 = 'try-error')) gsea_output(gseaResult = my.gsea.res, out.dir = cut.dir, comp.name = mycomb)
      #   }
      #   #### ORA
      #   if (cm.do[2]) {
      #     my.ora.res <- try(ora_run(gene = enr.inputs$ora.genevec, species = species, func.name = 'clusterProfiler::enricher', t2g = cell_markers, t2g.name = 'CellMarkers', gene2Symbol = enr.inputs$gene2Symbol, pvalueCutoff = enrp.max, minGSSize = enr.min.genes))
      #     if (!is(my.ora.res, class2 = 'try-error')) ora_output(enrichResult = my.ora.res, out.dir = cut.dir, comp.name = mycomb, geneList = enr.inputs$gsea.genevec)
      #   }
      # }
      
      ## MESH (WARNING : MEMORY OGRE AND SLOW !! Big DBs, 3 sources, 16 categories ! 64 GB of RAM required for most bases !
      ### Requires additional parameters :
      ### . 'MeSHDb' : character ; name of a MeSH [NO : AUTO FROM SPECIES NAME]
      ### . 'database' : character ; MeSH source type (can be 'gendoo' = text-mining, 'gene2pubmed' = manual curation by NCBI team, 'RBBH' = sequence homology with BLASTP search @ E-value < 1E-50)
      ### . 'category' : character ; name of a MeSH category sub-db (namely 'A', 'B', 'C', 'D', 'G').
      ### NOTE : see https://yulab-smu.top/biomedical-knowledge-mining-book/meshes-semantic-similarity.html
      if (any(mesh.do)) {
        ### List of requested MeSH DBs
        mesh.dbs <- c('gendoo', 'gene2pubmed', 'RBBH') ## 'RBBH' is not available for Homo sapiens.
        ### List of requested MeSH categories
        mesh.categories <- toupper(letters[-c(15:21,23:25)]) ## More categories are available, but some do not seem to work with Homo sapiens for some of the DBs.
        ### Building the MeSH package name corresponding to the current species
        mesh.sp <- paste0(c('MeSH.', substr(unlist(strsplit(species, ' ')), c(1, 1), c(1,2)), '.eg.db'), collapse = '')
        ### Checking which MeSH DBs are available for the current species.
        mesh.dbs <- MeSHDbi::listDatabases(eval(parse(text = paste0(mesh.sp, '::', mesh.sp))))[,1]
        
        ### ORA
        #### WARNING !! the 'gene2pubmed' requires a lot of RAM (~12 GB) !!
        if (mesh.do[2]) {
          mesh.func.name <- 'meshes::enrichMeSH'
          for (y in mesh.dbs) {
            for (x in mesh.categories) {
              message(paste0(y, ' ', x))
              if (y %in% mesh.dbs) {
                my.ora.res <- try(ora_run(gene = enr.inputs$ora.genevec, species = species, func.name = mesh.func.name, t2g = NULL, t2g.name = NULL, gene2Symbol = enr.inputs$gene2Symbol, pvalueCutoff = enrp.max, minGSSize = enr.min.genes, database = y, category = x))
                if(!is(my.ora.res, class2 = 'try-error')) {
                  ## Little hack specific to MeSH results (as I was not able to get the value of extra parameters 'database' and 'category' from within the 'gsea_run()' function)
                  my.ora.res@ontology <- paste(c(mesh.func.name, y, x), collapse = '_')
                  if (!is(my.ora.res, class2 = 'try-error')) if (!is.null(my.ora.res)) ora_output(enrichResult = my.ora.res, out.dir = cut.dir, comp.name = cur.name, geneList = enr.inputs$gsea.genevec, heatplot = dotplot.maxterms, dotplot = dotplot.maxterms, barplot = dotplot.maxterms)
                }
              } else message(paste0("Unsupported MeSH database '", y, "'. Expecting one of : '", paste(mesh.dbs, collapse = "', '"), "'."))
            }
          }
        }
        
        ### GSEA
        #### WARNING !! Needs too much memory for a laptop (probably over 64 GB of RAM, easily...). SO, not recommended out of flamingo.
        if(mesh.do[1]) {
          mesh.func.name <- 'meshes::gseMeSH'
          for (y in mesh.dbs) {
            for (x in mesh.categories) {
              message(paste0(y, ' ', x))
              if (y %in% mesh.dbs) {
                my.gsea.res <- try(gsea_run(geneList = enr.inputs$gsea.genevec, species = species, func.name = mesh.func.name, t2g = NULL, t2g.name = NULL, gene2Symbol = enr.inputs$gene2Symbol, seed = my.seed, pvalueCutoff = enrp.max, minGSSize = enr.min.genes, database = y, category = x), silent = TRUE)
                if (!is(my.gsea.res, class2 = 'try-error')) {
                  ## Little hack specific to MeSH results (as I was not able to get the value of extra parameters 'database' and 'category' from within the 'gsea_run()' function)
                  my.gsea.res@setType <- paste(c(mesh.func.name, y, x), collapse = '_')
                  gsea_output(gseaResult = my.gsea.res, out.dir = cut.dir, comp.name = cur.name, heatplot = dotplot.maxterms, dotplot = dotplot.maxterms, barplot = dotplot.maxterms, gsea.plot = dotplot.maxterms, ridgeplot = dotplot.maxterms)
                }
              } else message(paste0("Unsupported MeSH database '", y, "'. Expecting one of : '", paste(mesh.dbs, collapse = "', '"), "'."))
            }
          }
        }
        
        ## CUSTOM
        if (any(custom.do) & !is.null(custom_gmt_list)) {
          for (cdb in names(custom_gmt_list)) {
            if(custom.do[1]) {
              ### GSEA
              func.name <- 'clusterProfiler::GSEA'
              my.gsea.res <- gsea_run(geneList = enr.inputs$gsea.genevec, species = species, func.name = func.name, t2g = custom_gmt_list[[cdb]], t2g.name = cdb, gene2Symbol = enr.inputs$gene2Symbol, seed = my.seed, pvalueCutoff = enrp.max, minGSSize = enr.min.genes)
              gsea_output(gseaResult = my.gsea.res, out.dir = cut.dir, comp.name = cur.name, heatplot = dotplot.maxterms, dotplot = dotplot.maxterms, barplot = dotplot.maxterms, gsea.plot = dotplot.maxterms, ridgeplot = dotplot.maxterms)
            }
            if(custom.do[2]) {
              ### ORA
              func.name <- 'clusterProfiler::enricher'
              my.ora.res <- ora_run(gene = enr.inputs$ora.genevec, species = species, func.name = func.name, t2g = custom_gmt_list[[cdb]], t2g.name = cdb, gene2Symbol = enr.inputs$gene2Symbol, pvalueCutoff = enrp.max, minGSSize = enr.min.genes)
              if (!is(my.ora.res, class2 = 'try-error')) if (!is.null(my.ora.res)) ora_output(enrichResult = my.ora.res, out.dir = cut.dir, comp.name = cur.name, geneList = enr.inputs$gsea.genevec, heatplot = dotplot.maxterms, dotplot = dotplot.maxterms, barplot = dotplot.maxterms)
            }
          }
        }
      }
    }
  }
}

## Perform glmmSeq (on a pseudocount/TPM expression matrix) ====
### tpm_mat : a pseudocount/TPM expression matrix
### formula : a text to convert to a formula (or directly a formula)
### metadata : a df with variables to use found in formula
### ... glmmSeq::glmmSeq additional parameters
glmmSeq_run <- function(tpm_mat = NULL, time_colname = 'TimePoint', covar_colname = 'Response', patient_colname = 'Patient_id', metadata = NULL, mode = 'interaction', adjp.max = 5E-02, ...) {
  ## Checks
  good_modes <- c('interaction', 'additive')
  if (!mode %in% good_modes) stop(paste0("Unsupported mode ! Supported : '", paste(good_modes, collapse = "', '"), "'"))
  ## Drop empty levels
  metadata[[time_colname]] <- droplevels(metadata[[time_colname]])
  tlev <- levels(metadata[[time_colname]])
  ## Plots won't work if time is not numeric
  metadata[[timecol]] <- as.numeric(metadata[[time_colname]])
  ## Compute sizeFactors
  sizeFactors <- colSums(tpm_mat)
  sizeFactors <- sizeFactors / mean(sizeFactors)
  ## Compute dispersion
  dispersions <- apply(tpm_mat, 1, function(x){ (var(x, na.rm = TRUE) - mean(x, na.rm = TRUE)) / (mean(x, na.rm = TRUE)**2) })
  ## Create formula
  my_formula <- as.formula(paste0('~ ', time_colname, ' * ', covar_colname , ' + (1 | ', patient_colname, ')'))
  ## Handle mode
  if(mode == 'interaction') {
    compname <- paste0(time_colname, ':', covar_colname)
    cname <-  paste0(compname, rev(levels(metadata[[covar_colname]]))[1])
  }
  if(mode == 'additive') {
    cname <- compname <- time_colname
  }
  
  ## Perform glmmSeq
  set.seed(my.seed)
  GS_res <- glmmSeq::glmmSeq(
    modelFormula = my_formula
    , countdata = tpm_mat
    , metadata = metadata
    , dispersion = dispersion
    , sizeFactors = sizeFactors
    , progress = TRUE
    , ...
  )
  ## Add Q-values
  GS_res <- glmmSeq::glmmQvals(object = GS_res, cutoff = adjp.max, verbose = FALSE)
  
  ## Get differentials interaction results
  Diff_res <- summary(GS_res)
  
  ## Differential DF
  out_df <- data.frame(Feature = rownames(Diff_res), Diff_res)
  rm(Diff_res)
  
  ## Add Estimated mean expression per class
  out_df <- cbind (out_df, GS_res@predict)
  
  ## Return
  return(out_df)
}


## EXAMPLE : glmmSeq_run(tpm_mat = count_mat, time_colname = "TimePoint", covar_colname = "Response", patient_colname = "Patient_id", metadata = annot_df, cores = 1, removeSingles = FALSE)


## Perform lmmSeq (on a log-normalized expression matrix) ====
### ln_mat : a log-normalized expression matrix
### formula : a text to convert to a formula (or directly a formula)
### metadata : a df with variables to use found in formula
### ... glmmSeq::glmmSeq additional parameters
### tpm_mat : a pseudocount/TPM expression matrix
### formula : a text to convert to a formula (or directly a formula)
### metadata : a df with variables to use found in formula
### ... glmmSeq::glmmSeq additional parameters
lmmSeq_run <- function(ln_mat = NULL, time_colname = 'TimePoint', covar_colname = 'Response', patient_colname = 'Patient_id', metadata = NULL, mode = 'interaction', adjp.max = 5E-02, lfc.min = 0, out_dir = getwd(), ...) {
  ## Checks
  good_modes <- c('interaction', 'additive')
  if (!mode %in% good_modes) stop(paste0("Unsupported mode ! Supported : '", paste(good_modes, collapse = "', '"), "'"))
  ## Drop empty levels
  metadata[[time_colname]] <- droplevels(metadata[[time_colname]])
  tlev <- levels(metadata[[time_colname]])
  ## Plots won't work if time is not numeric => NOT TRUE FOR lmmSeq, it seems to be ok with a true factor !
  # metadata[[time_colname]] <- as.numeric(metadata[[time_colname]])
  ## Create formula
  my_formula <- as.formula(paste(c('~', time_colname, '*', covar_colname , '+ (1 |', patient_colname, ')'), collapse = ' '))
  ## Handle mode
  if(mode == 'interaction') {
    compname <- paste0(time_colname, ':', covar_colname)
    cname <-  paste0(compname, rev(levels(metadata[[covar_colname]]))[1])
  }
  if(mode == 'additive') {
    cname <- compname <- time_colname
  }
  
  ## Perform lmmSeq
  set.seed(my.seed)
  LS_res <- glmmSeq::lmmSeq(
    modelFormula = my_formula
    , maindata = ln_mat
    , metadata = metadata
    , progress = TRUE
    , ...
  )
  ## Add Q-values
  LS_res <- glmmSeq::glmmQvals(object = LS_res, cutoff = adjp.max, verbose = FALSE)
  
  ## Get differentials interaction results
  Diff_res <- summary(LS_res)
  
  ## Differential DF
  out_df <- data.frame(Feature = rownames(Diff_res), Diff_res)
  rm(Diff_res)
  
  ## Add Estimated mean expression per class
  out_df <- cbind (out_df, LS_res@predict)
  
  ## Humn-readable column names
  ### RawP
  rawpcolz <- grep(pattern = '^P_', x = colnames(out_df))
  colnames(out_df)[rawpcolz] <- paste0('Raw', colnames(out_df)[rawpcolz])
  ### AdjP
  adjpcolz <- which(colnames(out_df) %in% c(time_colname, covar_colname, paste0(time_colname, '.', covar_colname)))
  colnames(out_df)[adjpcolz] <- paste0('AdjP_', colnames(out_df)[adjpcolz])
  ### Estimates
  ycolz <- grep(pattern = '^y_', x = colnames(out_df))
  colnames(out_df)[ycolz] <- paste0(sub(pattern = '^y_', replacement = '', colnames(out_df)[ycolz]), '_est.mean')
  ## Current logFCs
  ### Timepoint
  colnames(out_df)[colnames(out_df) == paste0(time_colname, levels(metadata[[time_colname]])[2])] <- paste0('Log2FC_', time_colname, ':', paste(rev(levels(metadata[[time_colname]])), collapse = '_vs_'))
  ### Covariate
  colnames(out_df)[colnames(out_df) == paste0(time_colname, levels(metadata[[covar_colname]])[2])] <- paste0('Log2FC_', covar_colname, ':', paste(rev(levels(metadata[[covar_colname]])), collapse = '_vs_'))
  ### Interaction
  colnames(out_df)[colnames(out_df) == paste0(time_colname, levels(metadata[[time_colname]])[2], '.', paste0(covar_colname, levels(metadata[[covar_colname]])[2]))] <- paste0('Log2FC_Interaction:', time_colname, '*', covar_colname)
  ## Add log2FCs
  combz <- combn(colnames(out_df)[ycolz], 2)
  for (x in seq_len(ncol(combz))) {
    newcol_name <- paste0('Log2FC_', paste(rev(sub(pattern = '_est.mean', replacement = '', combz[,x])), collapse = '_vs_'))
    out_df[[newcol_name]] <- log2(out_df[[combz[2,x]]] / out_df[[combz[1,x]]])
  }
  
  ## Save results
  WriteXLS::WriteXLS(x = out_df, ExcelFileName = paste0(out_dir, '/lmmSeq_results_', time_colname, '*', covar_colname, '.xlsx'), SheetNames = 'lmmSeq_results', AdjWidth = TRUE, AutoFilter = TRUE, BoldHeaderRow = TRUE, FreezeRow = 1, FreezeCol = 1)
  
  ## Volcano plot
  twadjp <- out_df[[paste0('AdjP_', time_colname, '.', covar_colname)]]
  out_df[[paste0('sig@AdjP.', adjp.max, '_lfc.', lfc.min)]] <- twadjp < adjp.max & abs(out_df[[paste0('Log2FC_Interaction:', time_colname, '*', covar_colname)]]) > lfc.min
  twadjp[twadjp == 0] <- 1E-323
  nsig <- length(which(out_df[[paste0('sig@AdjP.', adjp.max, '_lfc.', lfc.min)]]))
  svg(filename = paste0(out_dir, '/Volcano_plot.svg'), width = 1200/96, height = 1000/96)
  plot(
    x = out_df[[paste0('Log2FC_Interaction:', time_colname, '*', covar_colname)]], 
    y = -log10(twadjp), 
    pch = 20, 
    col = as.numeric(out_df[[paste0('sig@AdjP.', adjp.max, '_lfc.', lfc.min)]])+1, 
    xlab = 'Log2FC(interaction)', 
    ylab = '-log10(AdjP)', 
    main = paste0('Volcano plot\nNsig = ', nsig, ' (out of ', nrow(out_df), ' features)')
  )
  abline(v = lfc.min*c(-1, 1), col = 4, lty = 3)
  abline(h = -log10(adjp.max), col = 4, lty = 3)
  svg_off()
  
  ## Model plots
  plotColours <- c("skyblue", "goldenrod1", "mediumseagreen", "pink", 'red')[1:length(tlev)]
  modColours <- c("dodgerblue3", "goldenrod3", "seagreen4", 'pink3', 'darkred')[1:length(tlev)]
  if(mode == 'interaction') {
    mp_dir <- paste0(out_dir, '/Modelplots')
    dir.create(path = mp_dir, recursive = TRUE)
    shapes <- c(17, 19, 18, 16, 15)[1:nlevels(metadata[[time_colname]])]
    for (x in which(out_df[[paste0('sig@AdjP.', adjp.max, '_lfc.', lfc.min)]])) {
      xg <- out_df$Feature[x]
      svg(filename = paste0(mp_dir, '/', sprintf(fmt = "%03i", x), '_', xg, '.svg'), width = 1200/96, height = 1000/96)
      LStmp <- LS_res
      LStmp@metadata[[time_colname]] <- as.numeric(LStmp@metadata[[time_colname]])
      LStmp@modelData[[time_colname]] <- c(1,2,1,2)
      gmodplot <- glmmSeq::ggmodelPlot(object = LStmp,
                                       geneName = xg,
                                       x1var = time_colname,
                                       x2var = covar_colname,
                                       # xlab="Timepoint",
                                       xlab=eval(time_colname),
                                       colours = plotColours,
                                       shapes = shapes,
                                       lineColours = plotColours, 
                                       modelColours = modColours,
                                       modelSize = 10, addModel = TRUE)
      print(gmodplot)
      svg_off()
    }
  }
  ## Return
  return(out_df)
}

## EXAMPLE : glmmSeq_run(tpm_mat = count_mat, time_colname = "TimePoint", covar_colname = "Response", patient_colname = "Patient_id", metadata = annot_df, cores = 1, removeSingles = FALSE)







## Run immunedeconv on a matrix ====
immunedeconv_run <- function(exp_mat = NULL, to_tpm = TRUE, methods = c('quantiseq', 'epic', 'estimate', 'mcp_counter', 'abis', 'cibersort'), is_array = FALSE, is_tumor = TRUE, cibersort_binary_path = NULL, cibersort_lm22_path = NULL, cibersort_absolute = TRUE, cibersortx_resfile = NULL, cibersortx_absolute = TRUE) {
  
  if (to_tpm) {
    ## Normalize to TPM
    message('Transforming data to TPM')
    for (s in colnames(exp_mat)) exp_mat[,s] <- immunedeconv::scale_to_million(sample = exp_mat[,s])
  }
  
  ## EPIC handling
  if ('epic' %in% methods) library(EPIC)
  
  ## Running with (multiple) method(s)
  id_res_all <- lapply(id_methods, function(idm) {
    message('. ', idm)
    if (tolower(idm) == 'cibersort') {
      immunedeconv::set_cibersort_binary(cibersort_binary_path)
      immunedeconv::set_cibersort_mat(cibersort_lm22_path)
      suppressMessages(id_try <- try(id_resC <- immunedeconv::deconvolute_cibersort(gene_expression = exp_mat, arrays = is_array, absolute = cibersort_absolute)))
      id_res <- if (is(id_try, class2 = 'try-error')) NULL else tibble::as_tibble(data.frame('cell_type' = rownames(id_resC), id_resC))
      rm(id_resC)
    } else {
      ## xCell handling
      if (idm == 'xcell') xCell.data <<- immunedeconv::xCell.data
      suppressWarnings(suppressMessages(id_try <- try(id_res <- immunedeconv::deconvolute(gene_expression = exp_mat, method = idm, tumor = is_tumor, arrays = is_array))))
      ## xCell handling
      if (idm == 'xcell' & exists('xCell.data')) rm(xCell.data, envir = globalenv())
      ## ERROR handling
      if (is(id_try, class2 = 'try-error')) id_res <- NULL
    }
    return(id_res)
  })
  names(id_res_all) <- id_methods
  if (cibersort_absolute) names(id_res_all)[names(id_res_all) == 'cibersort'] <- 'cibersort_absolute'
  
  ## Unloading EPIC if needed
  if ('epic' %in% methods & 'EPIC' %in% .packages()) detach("package:EPIC", unload = FALSE) ## unload is set to false as EPIC is actually loaded by immunedeconv
  
  ## Clean CiberSort output (extract global score)
  for (cidword in c('cibersort', 'cibersort_absolute')) {
    if (cidword %in% names(id_res_all)) {
      score_range <- nrow(id_res_all[[cidword]])
      id_res_all[[paste0(cidword, '_score')]] <- id_res_all[[cidword]][score_range,, drop = FALSE]
      id_res_all[[cidword]] <- id_res_all[[cidword]][-c(nrow(id_res_all[[cidword]])),, drop = FALSE]
    }
  }
  
  ## Clean MCPcounter output (extract global scores)
  if ('mcp_counter' %in% names(id_res_all)) {
    score_range <- 3
    id_res_all$mcp_counter_score <- id_res_all$mcp_counter[score_range,, drop = FALSE]
    id_res_all$mcp_counter <- id_res_all$mcp_counter[-c(score_range),, drop = FALSE]
  }
  
  ## Clean XCell output (extract global scores)
  if ('xcell' %in% names(id_res_all)) {
    score_range <- (nrow(id_res_all$xcell)-2):nrow(id_res_all$xcell)
    id_res_all$xcell_score <- id_res_all$xcell[score_range,, drop = FALSE]
    id_res_all$xcell <- id_res_all$xcell[-c(score_range),, drop = FALSE]
  }
  
  ## Add CiberSortX results ?
  if (!is.null(cibersortx_resfile)) {
    cbx_res <- data.table::fread(file = cibersortx_resfile, sep = '\t', header = TRUE, data.table = FALSE)
    cbx_mat <- t(as.matrix(cbx_res[,-1]))
    cbx_tib <- tibble::as_tibble(data.frame('cell_type' = colnames(cbx_res)[-1], cbx_mat))
    colnames(cbx_tib) <- c('cell_type', cbx_res[,1])
    absword <- if(cibersortx_absolute) 'absolute' else NULL
    ## Split results ...
    score_range <- (nrow(cbx_tib)-3):nrow(cbx_tib)
    ### ... quantifications
    id_res_all[[paste(c('cibersortx', absword), collapse = '_')]] <- cbx_tib[-c(score_range),]
    ### ... scores/metrics
    id_res_all[[paste(c('cibersortx', absword, 'score'), collapse = '_')]] <- cbx_tib[score_range,]
    rm(cbx_res, cbx_tib, cbx_mat)
  }
  return(id_res_all)
}


## Perform GSVA on a symbols x samples normalized expression matrix ====
  gsva_run <- function(exp_mat = NULL, gmt_files = NULL, enr_min_genes = 10, species = 'homo sapiens', out_dir = getwd()) {
  ## Checks
  if (is.null(exp_mat)) stop('An expression matrix is required !')
  if (is.null(gmt_files)) stop('No GMT provided !')
  if (!is.matrix(exp_mat)) stop('Provided exp_mat is not a matrix !')
  if (!all(file.exists(gmt_files))) stop('At least one of the provided GMT(s) was not found !')
  if (!dir.exists(paths = out_dir)) stop('Provided out_dir does not exist !')
  
  ## Run
  
  ## Generate GMT names (for output)
  gmt_names <- sub(pattern = '\\.gmt.*$', replacement = '', x = basename(gmt_files))
  
  ## Convert feature names to ENTREZ
  ### Convert species name to org-compatible identifier
  if (tolower(species) == 'homo sapiens') {
    Org <- 'org.Hs'
  } else if (tolower(species) == 'mus musculus') {
    Org <- 'org.Mm'
  } else {
    message('Only "homo sapiens" and "Mus musculus" are supported !')
    Org <- NULL
  }
  ### Convert expression features to ENTREZ
  g_conv <- suppressWarnings(suppressMessages(clusterProfiler::bitr(geneID = rownames(exp_mat), fromType = 'SYMBOL', toType = 'ENTREZID', OrgDb = paste0(Org, '.eg.db'))))
  g_conv <- g_conv[!(duplicated(g_conv$SYMBOL) | duplicated(g_conv$ENTREZID)),]
  s2e <- setNames(object = g_conv$ENTREZID, nm = g_conv$SYMBOL)
  rm(g_conv)
  geo_gsva <- exp_mat[rownames(exp_mat) %in% names(s2e),]
  rownames(geo_gsva) <- s2e[rownames(geo_gsva)]
  rm(s2e, exp_mat)
  
  ## Looping on GMTs
  gsva_all <- lapply(seq_along(gmt_files), function(g) {
    
    gmt_file <- gmt_files[g]
    gmt_name <- gmt_names[g]
    message('. ', gmt_name)
    
    ## Read terms from GMT
    gmt_db <- suppressWarnings(suppressMessages(GSEABase::getGmt(con = gmt_file, geneIdType = GSEABase::EntrezIdentifier(), collectionType = GSEABase::NullCollection())))
    
    ## Create gParam from expression matrix and terms
    g_param <- suppressWarnings(suppressMessages(GSVA::gsvaParam(exprData = geo_gsva, geneSets = gmt_db, kcdf = 'Gaussian', minSize = enr_min_genes)))
    ## Run GSVA
    gsva_res <- suppressWarnings(suppressMessages(GSVA::gsva(param = g_param, verbose = FALSE)))
    
    ### OL detection : grDevices::boxplot.stats
    if(nrow(gsva_res)>=3) {
      bx_res <- lapply(seq_len(ncol(gsva_res)), function(k) {
        es_data <- gsva_res[,k, drop = TRUE]
        es_res <- grDevices::boxplot.stats(x = es_data)
        es_data[!names(es_data) %in% names(es_res$out)] <- NA
        return(es_data)
      })
      bx_mat <- Reduce(f = cbind, x = bx_res)
      dimnames(bx_mat) <- dimnames(gsva_res)
    } else {
      bx_mat <- matrix(NA, nrow = nrow(gsva_res), ncol = ncol(gsva_res), dimnames = dimnames(gsva_res))
    }
    bx_df <- data.frame(data.frame(Term = gsub(pattern = '\\%', replacement = '_', x = rownames(bx_mat)), bx_mat, OCC = ncol(bx_mat) - matrixStats::rowCounts(x = bx_mat, value = NA, na.rm = FALSE)))
    bx_df$FREQ <- bx_df$OCC / ncol(bx_mat)
    rm(bx_mat)
    
    ## OL detection : Rosner test
    if(nrow(gsva_res)>=3) {
      ro_res <- lapply(seq_len(ncol(gsva_res)), function(k) {
        es_data <- gsva_res[,k, drop = TRUE]
        es_res <- EnvStats::rosnerTest(x = es_data, k = ceiling(length(es_data)/2), warn = FALSE)
        es_data[es_res$all.stats$Outlier == FALSE] <- NA
        return(es_data)
      })
      ro_mat <- Reduce(f = cbind, x = ro_res)
      dimnames(ro_mat) <- dimnames(gsva_res)
    } else {
      ro_mat <- matrix(NA, nrow = nrow(gsva_res), ncol = ncol(gsva_res), dimnames = dimnames(gsva_res))
    }
    ro_df <- data.frame(data.frame(Term = gsub(pattern = '\\%', replacement = '_', rownames(ro_mat)), ro_mat, OCC = ncol(ro_mat) - matrixStats::rowCounts(x = ro_mat, value = NA, na.rm = FALSE)))
    ro_df$FREQ <- ro_df$OCC / ncol(ro_mat)
    rm(ro_mat)
    
    ## Aggregate tables to output
    gsva_outlist <- list(GSVA = data.frame(Term = gsub(pattern = '\\%', replacement = '_', rownames(gsva_res)), gsva_res, check.names = FALSE), OL_BOXP_TEST = bx_df, OL_ROSNER_TEST = ro_df)
    rm(bx_df, ro_df)
    
    ## Write with openxlsx
    ### Create workbook
    wb <- openxlsx::createWorkbook(title = paste0(gmt_name, ' GSVA results'))
    ### Define styles
    Hstyle <- openxlsx::createStyle(halign = 'center', valign = 'bottom', textRotation = 90, textDecoration = 'bold')
    FLOATstyle <- openxlsx::createStyle(numFmt = '0.000')
    INTstyle <- openxlsx::createStyle(numFmt = '0')
    PCstyle <- openxlsx::createStyle(numFmt = '0.00%')
    ### Add sheets
    for (l in names(gsva_outlist)) {
      cur.hh <- min(max(sapply(colnames(gsva_outlist[[l]]), nchar)), 30) * 9
      cur.fc <- min(max(sapply(gsva_outlist[[l]][,1], nchar)), 30) * 3
      openxlsx::addWorksheet(wb = wb, sheetName = l)
      openxlsx::setRowHeights(wb = wb, sheet = l, rows = 1, heights = cur.hh)
      openxlsx::addStyle(wb = wb, sheet = l, style = Hstyle, rows = 1, cols = 1:ncol(gsva_outlist[[l]]))
      numstyle_colz <- if(l == 'GSVA') 2:ncol(gsva_outlist[[l]]) else 2:(ncol(gsva_outlist[[l]])-2)
      ### Apply 3-digits float formatting for score columns
      openxlsx::addStyle(wb = wb, sheet = l, style = FLOATstyle, rows = 2:(nrow(gsva_outlist[[l]])+1), cols = numstyle_colz, gridExpand = TRUE, stack = TRUE)
      if(l != 'GSVA') {
        ### Apply integer formatting for OCC column
        openxlsx::addStyle(wb = wb, sheet = l, style = INTstyle, rows = 2:(nrow(gsva_outlist[[l]])+1), cols = ncol(gsva_outlist[[l]]) - 1, gridExpand = TRUE, stack = TRUE)
        ### Apply percent formatting for FREQ column
        openxlsx::addStyle(wb = wb, sheet = l, style = PCstyle, rows = 2:(nrow(gsva_outlist[[l]])+1), cols = ncol(gsva_outlist[[l]]), gridExpand = TRUE, stack = TRUE)
      }
      openxlsx::setColWidths(wb = wb, sheet = l, cols = 2:ncol(gsva_outlist[[l]]), widths = 6)
      openxlsx::setColWidths(wb = wb, sheet = l, cols = 1, widths = cur.fc)
      openxlsx::freezePane(wb = wb, sheet = l, firstRow = TRUE, firstCol = TRUE)
      openxlsx::writeData(wb = wb, sheet = l, x = gsva_outlist[[l]], keepNA = TRUE, na.string = 'NA')
    }
    ## Write
    openxlsx::saveWorkbook(wb = wb, file = paste0(out_dir, '/', gmt_name, '_GSVA_results.xlsx'), overwrite = TRUE)
    rm(wb)
    
    ## Return
    return(gsva_res)
  })
  names(gsva_all) <- gmt_names
  return(gsva_all)
}


## Perform Kruskal-Wallis differential test on GSVA results according to clinical annotation ====
gsva_diff_run <- function(gsva_res = NULL, annot_df = NULL, method = 'KW', paired = FALSE, diff_factor = NULL, max.p = .05, out_dir = getwd()) {
  
  ## Checks
  if (is.null(gsva_res)) stop('An output of gsva_run() is required !')
  if (!is.list(gsva_res)) stop('gsva_res should be a list, the output of gsea_run() !')
  if (is.null(diff_factor)) stop('A list of annotation to perform the differential tests is required !')
  if (!tolower(method) %in% c('kw', 'w')) stop('Only KW (Kruskal-Wallis) or W (Wilcoxon) statistical methods are allowed !')
  if (!is.logical(paired)) stop('paired should be a logical !')
  if (is.null(annot_df)) stop('No annotation table provided !')
  if (!is.numeric(max.p)) stop('max_p should be a numeric in ]0:1] !')
  if (max.p <= 0) stop('max_p should be a numeric in ]0:1] !')
  if (max.p > 1) stop('max_p should be a numeric in ]0:1] !')
  if (!dir.exists(paths = out_dir)) stop('Provided out_dir does not exist !')
  if (paired) message('Using paired mode ...')
  if ((tolower(method) %in% 'kw') & paired) warning('Paired testing is active but KW is requested, so paired is ignored !')
  
  ## Run
  ## Looping on factors to compare
  grd_all <- lapply(diff_factor, function(ppf) {
    message('. ', ppf)
    ## Looping on gsva results
    grdiff_all <- lapply(names(gsva_all), function(ga) {
      message('  . ', ga)
      ## Looping on terms
      kw_l <- sapply(seq_len(nrow(gsva_all[[ga]])), function(x) {
        # message(x)
        data_df <- data.frame(gsva = unname(unlist(gsva_all[[ga]][x,])), class = as.factor(annot_df[[ppf]]))
        ## KW test
        if (tolower(method) %in% 'kw') {
          kw_t <- kruskal.test(gsva ~ class, data = data_df)
          kw_df <- data.frame(Statistic = kw_t$statistic, raw.p = kw_t$p.value, adj.p = 0.0)
        } else if (tolower(method) %in% 'w') {
          # kw_t <- wilcox.test(gsva ~ class, data = data_df, paired = paired)
          kw_t <- wilcox.test(x = data_df$gsva[data_df$class == levels(data_df$class)[2]], y = data_df$gsva[data_df$class == levels(data_df$class)[1]], paired = paired)
          kw_df <- data.frame(Statistic = kw_t$statistic, raw.p = kw_t$p.value, adj.p = 0.0)
        } 
        ## Add classes median
        ksumry <- aggregate(gsva ~ class, data = data_df, summary)
        ksd <- aggregate(gsva ~ class, data = data_df, sd)
        for (kx in seq_len(nrow(ksumry$gsva))) {
          kw_df[[paste0('Median_', ksumry$class[kx])]] <- ksumry$gsva[kx, 'Median']
          kw_df[[paste0('Sd_', ksd$class[kx])]] <- ksd$gsva[kx]
        }
        return(kw_df)
      }, simplify = FALSE)
      kw_res <- data.frame(Term = gsub(pattern = '\\%', replacement = '_', x = rownames(gsva_all[[ga]])), Reduce(f = rbind, x = kw_l))
      rm(kw_l)
      return(kw_res)
    })
    names(grdiff_all) <- names(gsva_all)
    
    ## Add AdjP
    for (l in names(grdiff_all)) grdiff_all[[l]]$adj.p <- p.adjust(p = grdiff_all[[l]]$raw.p, method = "BH")
    
    ## Sort by AdjP, Rawp
    for (l in names(grdiff_all)) grdiff_all[[l]] <- grdiff_all[[l]][order(grdiff_all[[l]]$adj.p, grdiff_all[[l]]$raw.p), ]
    
    ## Output results
    Hstyle <- openxlsx::createStyle(halign = 'center', valign = 'center', textDecoration = 'bold')
    FLOATstyle <- openxlsx::createStyle(numFmt = '0.000')
    SCstyle <- openxlsx::createStyle(numFmt = '0.00E00')
    BLUEstyle <- openxlsx::createStyle(bgFill = 'lightblue')
    wb <- openxlsx::createWorkbook(title = paste0(ppf, ' GSVA DiffTest'))
    for (l in names(grdiff_all)) {
      sname <- strtrim(x = l, width = 31)
      cur.fc <- min(max(sapply(grdiff_all[[l]][,1], nchar)), 30) * 3
      openxlsx::addWorksheet(wb = wb, sheetName = sname)
      openxlsx::addStyle(wb = wb, sheet = sname, style = Hstyle, rows = 1, cols = 1:ncol(grdiff_all[[l]]))
      openxlsx::addStyle(wb = wb, sheet = sname, style = FLOATstyle, rows = 2:(nrow(grdiff_all[[l]])+1), cols = c(2,5:ncol(grdiff_all[[l]])+1), gridExpand = TRUE, stack = TRUE)
      openxlsx::addStyle(wb = wb, sheet = sname, style = SCstyle, rows = 2:(nrow(grdiff_all[[l]])+1), cols = 3:4, gridExpand = TRUE, stack = TRUE)
      openxlsx::conditionalFormatting(wb = wb, sheet = sname, rows = 2:(nrow(grdiff_all[[l]])+1), cols = 3:4, rule = paste0('<', max.p), style = BLUEstyle)
      openxlsx::setColWidths(wb = wb, sheet = sname, cols = 2:4, widths = 10)
      openxlsx::setColWidths(wb = wb, sheet = sname, cols = 1, widths = cur.fc)
      openxlsx::freezePane(wb = wb, sheet = sname, firstRow = TRUE, firstCol = TRUE)
      ## Add sheet
      openxlsx::writeData(wb = wb, sheet = sname, x = grdiff_all[[l]], keepNA = TRUE, na.string = 'NA')
    }
    ## Save XLSX
    pairedword <- if(paired) '.paired' else NULL
    openxlsx::saveWorkbook(wb = wb, file = paste0(out_dir, '/', ppf, '_GSVA_DiffTest.', method, pairedword, '_results.xlsx'), overwrite = TRUE)
    rm(wb)
    return(grdiff_all)
  })
  names(grd_all) <- unlist(diff_factor)
  return(grd_all)
}




### Perform GSEA ====
### . 'geneList' : numeric vector : a named vector of decreasing values, with EntrezIDs as names
### . 'species' : character ; a species name, as in the 'species_name' column of msigdbr::msigdbr_species()
### . 'category' : character ; an MSigDB category, as in the 'gs_cat' column of msigdbr::msigdbr_collections()
### . 'subcategory' : character ; an MSigDB category, as in the 'gs_subcat' column of msigdbr::msigdbr_collections()
### . 'gene2Symbol' : character vector ; a named vector of EntrezIDs, with corresponding Symbol or EnsemblID as names
### . 'seed' : integer ; the random number generation seed
### . 'pvalueCutoff' : numeric ; minimum FDR-adjusted p-value for signficantly enriched terms (see clusterProfiler::GSEA)
### . 'minGSSize' : integer ; minimal size of each geneSet for analyzing (see clusterProfiler::GSEA)
### . '...' : any other parameter to pass to 'func.name'
### NOTE : For input ('geneList'), ALWAYS use all available genes (ie, not limited to significant differentially expressed genes), as intended for GSEA analysis. NEVER use a selection of genes (results will be corrupt). Please also be careful that you may obtain significant GSEA results from a list of values corresponding to NO significant genes (as GSEA only needs the order of these genes). In this case you may talk about "tendencies" of enrichment in your differential expression results.
gsea_run <- function(geneList = NULL, func.name = 'clusterProfiler::GSEA', species = 'Homo sapiens', t2g = NULL, t2g.name = NULL, gene2Symbol = NULL, seed = 1337, pvalueCutoff = 5E-02, minGSSize = 10, verbose = FALSE, ...) {
  
  if (!verbose) options(warn=-1)
  
  ## Checks
  if (any(!is.numeric(geneList))) stop("'geneList' should be a decreasingly sorted numeric vector, named with EntrezIDs.")
  if (length(names(geneList)) == 0) stop("'geneList' should be a decreasingly sorted numeric vector, named with EntrezIDs.")
  if (!all(geneList == sort(geneList, decreasing = TRUE))) stop("'geneList' should be a decreasingly sorted numeric vector, named with EntrezIDs.")
  if (!is.character(func.name)) stop("'func.name' should be a character.")
  if (!is.character(species)) stop("'species' should be a character.")
  valid.species <- msigdbr::msigdbr_species()$species_name
  if (!(species %in% valid.species)) stop(paste0("Unsupported 'species'. Expecting one of : '", paste(valid.species, collapse = "', '"), '.'))
  if (!is.null(t2g) & is.null(t2g.name)) stop("'t2g' provided but no 't2g.name'.")
  if (!is.null(t2g.name) & is.null(t2g)) stop("'t2g.name' provided but no 't2g'.")
  if (!is.null(gene2Symbol)) {
    if (any(!is.character(gene2Symbol))) stop("'gene2Symbol' shoud be a character vector, named with EntrezIDs.")
    if (length(names(gene2Symbol)) == 0) stop("'gene2Symbol' shoud be a character vector, named with EntrezIDs.")
  }
  if (!is.numeric(seed)) stop("'seed' should be an integer.")
  if (!is.numeric(pvalueCutoff)) stop("'pvalueCutoff' should be a positive, < 1, numeric")
  if (!(pvalueCutoff >= 0)) stop("'pvalueCutoff' should be a positive, < 1, numeric")
  if (!(pvalueCutoff <= 1)) stop("'pvalueCutoff' should be a positive, < 1, numeric")
  if (!is.numeric(minGSSize)) stop("'minGSSize' should be an integer.")
  if (!(minGSSize > 0)) stop("'minGSSize' should a non-null positive integer.")
  if (minGSSize < 10) warning("'minGSSize' < 10 : expect no result !")
  
  ## Loading the requested function
  func.split <- unlist(strsplit(func.name, '::'))
  gse.function <- base::get(func.split[2], envir = loadNamespace(func.split[1]))
  
  if (func.name == 'clusterProfiler::GSEA') {
    if (is.null(t2g)) stop("When calling this function with func.name = 'clusterProfiler::GSEA', a value is required for 't2g'")
    if (is.null(t2g.name)) stop("When calling this function with func.name = 'clusterProfiler::enricher', a value is required for 't2g.name'")
    
    ## Functions requiring a TERM2GENE (msigdbr, CellMarkers, ...)
    gsea.res <- gse.function(geneList = geneList, TERM2GENE = t2g, pvalueCutoff = pvalueCutoff, minGSSize = minGSSize, seed = seed, ...)
    func.name <- paste(c(func.name, t2g.name), collapse = '_')
  } else if (func.name == 'meshes::gseMeSH') {
    ## MeSH (requires additional 'MeSHDb', 'database' and 'category' parameters)
    mesh.sp <- paste0(c('MeSH.', substr(unlist(strsplit(species, ' ')), c(1, 1), c(1,2)), '.eg.db'), collapse = '')
    gsea.res <- try(gse.function(geneList = geneList, MeSHDb = mesh.sp, pvalueCutoff = pvalueCutoff, minGSSize = minGSSize, seed = seed, ...), silent = TRUE)
    gc()
    if (is(gsea.res, class2 = 'try-error')) return(ora.res)
  } else {
    if ('kegg' %in% tolower(func.name)) {
      ## KEGG / KEGGM (requires a custom species name in 'organism' parameter)
      kegg.sp <- tolower(paste0(substr(unlist(strsplit(species, ' ')), c(1, 1), c(1,2)), collapse = ''))
      gsea.res <- gse.function(geneList = geneList, organism = kegg.sp, pvalueCutoff = pvalueCutoff, minGSSize = minGSSize, seed = seed, ...)
    } else if (species != 'Homo sapiens') stop(paste0("Function '", func.name, "' can only be used with the 'Homo sapiens' species.")) else {
      ## OTHER (generic functions without TERM2GENE or custom parameters, like those in DOSE package, or clusterProfiler::gseGO)
      gsea.res <- gse.function(geneList = geneList, pvalueCutoff = pvalueCutoff, minGSSize = minGSSize, seed = seed, ...)
    }
  }
  
  ## Adding some useful metadata
  if(!is.null(gsea.res)) {
    gsea.res@organism <- species
    gsea.res@setType <- func.name
    if(!is.null(gene2Symbol)) {
      gsea.res@gene2Symbol <- gene2Symbol
      gsea.res@keytype <- 'ENTREZID'
    }
  }
  
  if (!verbose) options(warn=1)
  
  return(gsea.res)
}

## Create plots for gsea_run() ====
### . 'gseaResult' : gseaResult object ; an output from the gsea_run() function
### . 'comp.name' : character ; The name of the differential expression comparison which resulted in the 'geneList' input to gsea_run(). Actually, only used in plots' title.
### . 'out.dir' : character ; directory to output plots and tables
### . 'heatplot' : integer or NULL ; if integer perform an enrichplot::dotplot() limited to a number of term corresponding to the given integer value. If null, no plot is performed.
### . 'dotplot' : integer or NULL ; if integer perform an enrichplot::dotplot() limited to a number of term corresponding to the given integer value. If null, no plot is performed.
### . 'barplot' : integer or NULL ; if integer perform an enrichplot::barplot() limited to a number of term corresponding to the given integer value. If null, no plot is performed.
### gsea.plot : integer or NULL ; perform per-term enrichment plots like generated by the BROAD GSEA app, limited to the first X terms. No plot if null.
### gsea.plot.type : character (clusterprofiler|broad|both) ; type of GSEA plot to draw (clusterProfiler-style, BROAD-style, or both styles)
### . 'ridgeplot' : integer or NULL ; if integer perform an enrichplot::ridgeplot() limited to a number of term corresponding to the given integer value. If null, no plot is performed.
### . 'cnetplot' : integer or NULL ; if integer perform an enrichplot::cnetplot() limited to a number of term corresponding to the given integer value. If null, no plot is performed.
### . 'emapplot' : integer or NULL ; if integer perform an enrichplot::emapplot() limited to a number of term corresponding to the given integer value. If null, no plot is performed.
### . 'lfc.min' : numeric ; abs(log2FoldChange) value to target as color saturation for KEGG pathview plots.
gsea_output <- function(gseaResult = NULL, comp.name = 'TEST', out.dir = getwd(), heatplot = 100, dotplot = 100, barplot = 100, gsea.plot = 100, gsea.plot.type = 'none', ridgeplot = 100, cnetplot = 10, emapplot = 10, lfc.min = 1, verbose = FALSE) {
  
  if (!verbose) options(warn = -1)
  ## Significant terms ?
  gsea.sig.tf <- gseaResult@result$p.adjust < gseaResult@params$pvalueCutoff
  
  if (any(gsea.sig.tf)) {
    
    ## Creating GSEA output dir
    gname <- sub(pattern = '.*::', replacement = '', x = gseaResult@setType)
    gsea.dir <- paste(c(out.dir, paste0('GSEA_adjp.', gseaResult@params$pvalueCutoff), gname), collapse = '/')
    dir.create(path = gsea.dir, recursive = TRUE)
    
    ## Dumping GSEA results
    saveRDS(gseaResult, file = paste0(gsea.dir, '/GSEA.results.RDS'), compress = 'bzip2')
    
    ## Converting to readable symbols
    gseaResult_readable <- DOSE::setReadable(gseaResult, OrgDb = paste0(msigdbr2org(gseaResult@organism), '.db'))
    ## Writing readable table
    write.table(gseaResult_readable@result, file = paste0(gsea.dir, '/GSEA.results_readable.tsv'), quote = FALSE, sep = "\t", row.names = FALSE)
    WriteXLS::WriteXLS(x = gseaResult_readable@result, ExcelFileName = paste0(gsea.dir, '/GSEA.results_readable.xlsx'), SheetNames = gname, AdjWidth = TRUE, AutoFilter = TRUE, BoldHeaderRow = TRUE, FreezeRow = 1, FreezeCol = 1, na = c(NA, 'NA', 'na', ''))
    
    ## Heatplot (needs readable)
    if (!is.null(heatplot)) {
      suppressMessages(hp <- enrichplot::heatplot(gseaResult_readable, showCategory = heatplot, foldChange = gseaResult@geneList))
      pf <- paste0(gsea.dir, '/GSEA.heatplot.svg')
      ph <- ((min(length(which(gsea.sig.tf)), heatplot) * 12) + 150)
      pw <- min(5000, (5 * nrow(hp$data)) + 500)
      svg(filename = pf, width = pw/96, height = ph/96)
      print(hp)
      svg_off()
      # dev.off()
      # svg_convert(svg_files = pf, format = 'png', height = ph)
    }
    
    ## Dotplot // Barplot
    complot <- c()
    if (!is.null(dotplot)) complot <- c(complot, setNames(dotplot, 'clusterProfiler::dotplot'))
    if (!is.null(barplot)) complot <- c(complot, setNames(barplot, 'enrichplot:::barplot.enrichResult'))
    for (cx in seq_along(complot)) {
      func.split <- unlist(strsplit(names(complot)[cx], ':+'))
      plot.function <- base::get(func.split[2], envir = loadNamespace(func.split[1]))
      gseaBak <- gseaResult
      gseaResult@result$Description <- gsub(pattern = '_', ' ', gseaResult@result$Description, fixed = TRUE)
      suppressMessages(p <- plot.function(gseaResult, showCategory = unname(complot[cx]), title = paste(c(comp.name, gseaResult@setType, 'GSEA'), collapse = "\n"), split = '.sign') + ggplot2::facet_grid(~ .sign) + ggplot2::scale_y_discrete(labels=function(x) stringr::str_wrap(x, width=100)))
      pf <- paste0(gsea.dir, '/GSEA.', func.split[2], '.svg')
      pw <- 1000
      ph <- ((min(length(which(gsea.sig.tf)), unname(complot[cx])) * 20) + 300)
      svg(filename = pf, width = pw/96, height = ph/96)
      print(p)
      svg_off()
      # dev.off()
      # svg_convert(svg_files = pf, format = 'png', height = ph)
      gseaResult <- gseaBak
      rm(gseaBak)
    }
    
    if (!is.null(ridgeplot)) {
      ## Ridgeplot
      gseaBak <- gseaResult
      gseaResult@result$Description <- gsub(pattern = '_', ' ', gseaResult@result$Description, fixed = TRUE)
      rptry <- try(rip <- enrichplot::ridgeplot(gseaResult, showCategory = ridgeplot), silent = TRUE)
      if (!is(rptry, class2 = 'try-error')) {
        
        pf <- paste0(gsea.dir, '/GSEA.ridgeplot.svg')
        ph <- ((min(length(which(gsea.sig.tf)), ridgeplot) * 20) + 300)
        pw <- 1000
        svg(filename = pf, width = pw/96, height = ph/96)
        suppressMessages(print(rip + ggplot2::ggtitle(paste(c(comp.name, gseaResult@setType, 'GSEA'), collapse = "\n")) + ggplot2::scale_y_discrete(labels=function(x) stringr::str_wrap(x, width=100))))
        svg_off()
        # dev.off()
        # svg_convert(svg_files = pf, format = 'png', height = ph)
        gseaResult <- gseaBak
        rm(gseaBak)
      }
    }
    
    ## GSEA plots
    if (!is.null(gsea.plot) & gsea.plot > 0) {
      ### clusterProfiler format
      if (tolower(gsea.plot.type) %in% c('clusterprofiler', 'both')) {
        gseaplot.dir <- paste0(gsea.dir, '/gseaplot_clusterProfiler/')
        dir.create(path = gseaplot.dir, recursive = TRUE)
        pw <- 1024
        ph <- 768
        svg(filename = paste0(gseaplot.dir, '/GSEA.gseaplot_cP_%04d.svg'), width = pw/96, height = ph/96)
        for (x in 1:min(nrow(gseaResult), gsea.plot)) suppressMessages(print(enrichplot::gseaplot(gseaResult, geneSetID = x, title = paste0(toupper(gseaResult@result$Description[x]), "\nNES = ", sprintf("%.2f", gseaResult@result$NES[x]), " // Adj.p = ", sprintf(fmt = "%.1E", gseaResult@result$p.adjust[x])))))
        dev.off()
        svg_list <- list.files(path = gseaplot.dir, pattern = 'GSEA.gseaplot_cP_.*\\.svg$', full.names = TRUE, recursive = FALSE)
        svg_convert(svg_files = svg_list, format = 'png', compress = TRUE, height = ph)
      }
      ### Broad format
      if (tolower(gsea.plot.type) %in% c('broad', 'both')) {
        gseaplot.dir <- paste0(gsea.dir, '/gseaplot_Broad/')
        dir.create(path = gseaplot.dir, recursive = TRUE)
        pw <- 1024
        ph <- 768
        svg(filename = paste0(gseaplot.dir, '/GSEA.gseaplot_Broad_%04d.svg'), width = pw/96, height = ph/96)
        for (x in 1:min(nrow(gseaResult), gsea.plot)) suppressMessages(print(enrichplot::gseaplot2(gseaResult, geneSetID = x, title = paste0(toupper(gseaResult@result$Description[x]), "\nNES = ", sprintf("%.2f", gseaResult@result$NES[x]), " // Adj.p = ", sprintf(fmt = "%.1E", gseaResult@result$p.adjust[x])))))
        dev.off()
        svg_list <- list.files(path = gseaplot.dir, pattern = 'GSEA.gseaplot_Broad_.*\\.svg$', full.names = TRUE, recursive = FALSE)
        svg_convert(svg_files = svg_list, format = 'png', height = ph)
      }
    }
    ## KEGG pathview
    if (grepl(pattern = 'gseKEGG', x = gseaResult@setType)) {
      kegg.sp <- tolower(paste0(substr(unlist(strsplit(gseaResult@organism, ' ')), c(1, 1), c(1,2)), collapse = ''))
      kegg.dir <- paste0(gsea.dir, '/KEGG_pathview/')
      dir.create(path = kegg.dir, recursive = TRUE)
      ori.dir <- getwd()
      setwd(dir = kegg.dir)
      for (x in which(gsea.sig.tf)) {
        k_id <- gseaResult@result$ID[x]
        ptry <- try(suppressWarnings(suppressMessages(pathview::pathview(gene.data = gseaResult@geneList, pathway.id = k_id, species = kegg.sp, limit = list(gene=lfc.min, cpd=1), low=list(gene = "red", cpr = "cornflowerblue"), mid = list(gene = "grey90", cpd = "grey90"), high = list(gene = "blue", cpd = "yellow"), kegg.dir = kegg.dir))), silent = TRUE)
        torem <- paste0(kegg.dir, '/', k_id, '.', c('png', 'xml'))
        # torem <- paste0(kegg.dir, '/', k_id, '.', c('xml'))
        for (x in torem) { if (file.exists(x)) file.remove(x) }
      }
      setwd(dir = ori.dir)
    }
    if (!is.null(cnetplot)) {
      ## Cnetplot (needs readable)
      p <- try(enrichplot::cnetplot(gseaResult_readable, showCategory = cnetplot, circular = FALSE, color.params = list(edge = TRUE)), silent = TRUE)
      if(!is(p, class2 = 'try-error')) {
        pf <- paste0(gsea.dir, '/GSEA.cnetplot_', cnetplot, '.svg')
        pw <- 2000
        ph <- 2000
        svg(filename = pf, width = pw/96, height = ph/96)
        try(print(p + ggplot2::scale_fill_continuous(guide = ggplot2::guide_legend()) + ggplot2::theme(legend.position="bottom")), silent = TRUE)
        svg_off()
        # dev.off()
        # svg_convert(svg_files = pf, format = 'png', height = ph)
      } else message(paste0('Error captured for cnetplot : \n"', p, '"'))
    }
    if (!is.null(emapplot) & length(which(gsea.sig.tf)) > 1) {
      ## Emapplot (needs readable)
      p <- try(enrichplot::emapplot(enrichplot::pairwise_termsim(gseaResult_readable, showCategory = emapplot), showCategory = emapplot, layout.params = list(layout = 'kk')), silent = TRUE)
      if(!is(p, class2 = 'try-error')) {
        pf <- paste0(gsea.dir, '/GSEA.emapplot_', emapplot, '.svg')
        ph <- 1500
        pw <- 1500
        svg(filename = pf, width = pw/96, height = ph/96)
        try(print(p + ggplot2::scale_fill_continuous(guide = ggplot2::guide_legend()) + ggplot2::theme(legend.position="bottom")), silent = TRUE)
        svg_off()
        # dev.off()
        # svg_convert(svg_files = pf, format = 'png', height = ph)
      } else message(paste0('Error captured for emapplot : \n"', p, '"'))
    }
  } else message("No enriched term found.")
  
  if (!verbose) options(warn = 1)
  
}

### Perform ORA ====
### . 'gene' : character vector : a vector of EntrezIDs corresponding to the topN signature to assess for ORA
### . 'species' : character ; a species name, as in the 'species_name' column of msigdbr::msigdbr_species()
### . 'category' : character ; an MSigDB category, as in the 'gs_cat' column of msigdbr::msigdbr_collections()
### . 'subcategory' : character ; an MSigDB category, as in the 'gs_subcat' column of msigdbr::msigdbr_collections()
### . 'gene2Symbol' : character vector ; a named vector of EntrezIDs, with corresponding Symbol or EnsemblID as names
### . 'pvalueCutoff' : numeric ; minimum FDR-adjusted p-value for signficantly enriched terms (see clusterProfiler::GSEA)
### . 'minGSSize' : integer ; minimal size of each geneSet for analyzing (see clusterProfiler::GSEA)
### . '...' : any other parameter to the ORA function
ora_run <- function(gene = NULL, func.name = 'clusterProfiler::enricher', species = 'Homo sapiens', t2g = NULL, t2g.name = NULL, gene2Symbol = NULL, pvalueCutoff = 5E-02, minGSSize = 10, verbose = FALSE, ...) {
  
  if (!verbose) options(warn=-1)
  
  ## Checks
  if (any(!is.character(gene))) stop("'gene' should be a character vector.")
  if (!is.character(func.name)) stop("'func.name' should be a character.")
  if (length(gene) < minGSSize) {
    message("Length of 'gene' should be at least the value of 'minGSSize'.")
    return(new(Class = 'enrichResult', pvalueCutoff = pvalueCutoff, organism = species, ontology = func.name))
  }
  if (!is.character(species)) stop("'species' should be a character.")
  valid.species <- msigdbr::msigdbr_species()$species_name
  if (!(species %in% valid.species)) stop(paste0("Unsupported 'species'. Expecting one of : '", paste(valid.species, collapse = "', '"), '.'))
  if (!is.null(t2g) & is.null(t2g.name)) stop("'t2g' provided but no 't2g.name'.")
  if (!is.null(t2g.name) & is.null(t2g)) stop("'t2g.name' provided but no 't2g'.")
  if (!is.null(gene2Symbol)) {
    if (any(!is.character(gene2Symbol))) stop("'gene2Symbol' shoud be a character vector, named with EntrezIDs.")
    if (length(names(gene2Symbol)) == 0) stop("'gene2Symbol' shoud be a character vector, named with EntrezIDs.")
  }
  if (!is.numeric(pvalueCutoff)) stop("'pvalueCutoff' should be a positive, < 1, numeric")
  if (!(pvalueCutoff >= 0)) stop("'pvalueCutoff' should be a positive, < 1, numeric")
  if (!(pvalueCutoff <= 1)) stop("'pvalueCutoff' should be a positive, < 1, numeric")
  if (!is.numeric(minGSSize)) stop("'minGSSize' should be an integer.")
  if (!(minGSSize > 0)) stop("'minGSSize' should a non-null positive integer.")
  if (minGSSize < 10) warning("'minGSSize' < 10 : expect no result !")
  
  ## Loading the requested function
  func.split <- unlist(strsplit(func.name, '::'))
  or.function <- base::get(func.split[2], envir = loadNamespace(func.split[1]))
  library(paste0(msigdbr2org(species), '.db'), character.only = TRUE)
  if (func.name == 'clusterProfiler::enricher') {
    if (is.null(t2g)) stop("When calling this function with func.name = 'clusterProfiler::enricher', a value is required for 't2g'")
    if (is.null(t2g.name)) stop("When calling this function with func.name = 'clusterProfiler::enricher', a value is required for 't2g.name'")
    ## Functions requiring a TERM2GENE (msigdbr, CellMarkers, ...)
    ora.res <- or.function(gene = gene, TERM2GENE = t2g, pvalueCutoff = pvalueCutoff, minGSSize = minGSSize, ...)
    func.name <- paste(c(func.name, t2g.name), collapse = '_')
  } else if (func.name == 'meshes::enrichMeSH') {
    ## MeSH (requires additional 'MeSHDb', 'database' and 'category' parameters)
    mesh.sp <- paste0(c('MeSH.', substr(unlist(strsplit(species, ' ')), c(1, 1), c(1,2)), '.eg.db'), collapse = '')
    ora.res <- try(or.function(gene = gene, MeSHDb = mesh.sp, pvalueCutoff = pvalueCutoff, minGSSize = minGSSize, ...), silent = TRUE)
    if (is(ora.res, class2 = 'try-error')) return(ora.res)
  } else {
    if ('kegg' %in% tolower(func.name)) {
      ## KEGG / KEGGM (requires a custom species name in 'organism' parameter)
      kegg.sp <- tolower(paste0(substr(unlist(strsplit(species, ' ')), c(1, 1), c(1,2)), collapse = ''))
      ora.res <- or.function(gene = gene, organism = kegg.sp, pvalueCutoff = pvalueCutoff, minGSSize = minGSSize, ...)
    } else if (species != 'Homo sapiens') stop(paste0("Function '", func.name, "' can only be used with the 'Homo sapiens' species.")) else {
      ## OTHER (generic functions without TERM2GENE or custom parameters, like those in DOSE package)
      ora.res <- or.function(gene = gene, pvalueCutoff = pvalueCutoff, minGSSize = minGSSize, ...)
    }
  }
  gc()
  
  message("ORA.RES", is(ora.res))
  
  ## Adding some useful metadata
  if(!is.null(ora.res)) {
    ora.res@ontology <- func.name
    ora.res@organism <- species
    if(!is.null(gene2Symbol)) {
      ora.res@gene2Symbol <- gene2Symbol
      ora.res@keytype <- 'ENTREZID'
    }
  }
  
  if (!verbose) options(warn=1)
  
  return(ora.res)
}

### Create plots for ora_run() ====
### . 'enrichResults' : enrichResults object ; an output from the ora_run() function
### . 'comp.name' : character ; The name of the differential expression comparison which resulted in the 'gene' input to ora_run(). Actually, only used in plots' title.
### . 'out.dir' : character ; directory to output plots and tables
### . 'heatplot' : integer of NULL ; if integer perform an enrichplot::dotplot() limited to a number of term corresponding to the given integer value. If null, no plot is performed.
### . 'geneList' : numeric vector : a named vector of decreasing values, with EntrezIDs as names (the one object that is used as the 'geneList' input for the gsea_run() function). Required if 'heatplot' is non-NULL, and for KEGG pathview.
### . 'dotplot' : integer of NULL ; if integer perform an enrichplot::dotplot() limited to a number of term corresponding to the given integer value. If null, no plot is performed.
### . 'barplot' : integer of NULL ; if integer perform an enrichplot::barplot() limited to a number of term corresponding to the given integer value. If null, no plot is performed.
### . 'cnetplot' : integer of NULL ; if integer perform an enrichplot::cnetplot() limited to a number of term corresponding to the given integer value. If null, no plot is performed.
### . 'emapplot' : integer of NULL ; if integer perform an enrichplot::emapplot() limited to a number of term corresponding to the given integer value. If null, no plot is performed.
### . 'lfc.min' : numeric ; abs(log2FoldChange) value to target as color saturation for KEGG pathview plots.
ora_output <- function(enrichResult = NULL, comp.name = 'TEST', out.dir = getwd(), heatplot = 100, geneList = NULL, dotplot = 100, barplot = 100, cnetplot = 10, emapplot = 10, lfc.min = 1, verbose = FALSE) {
  
  if (!verbose) options(warn = -1)
  
  ## Significant terms ?
  ora.sig.tf <- enrichResult@result$p.adjust < enrichResult@pvalueCutoff
  
  if (any(ora.sig.tf)) {
    
    ## Creating ORA output dir
    # ora.dir <- paste(c(out.dir, paste0('ORA_adjp.', enrichResult@pvalueCutoff), enrichResult@ontology), collapse = '/')
    oname <- sub(pattern = '.*::', replacement = '', x = enrichResult@ontology)
    ora.dir <- paste(c(out.dir, paste0('ORA_adjp.', enrichResult@pvalueCutoff), oname), collapse = '/')
    
    dir.create(path = ora.dir, recursive = TRUE)
    
    ## Dumping ORA results
    saveRDS(enrichResult, file = paste0(ora.dir, '/ORA.results.RDS'), compress = 'bzip2')
    
    ## Converting to readable symbols
    enrichResult_readable <- DOSE::setReadable(enrichResult, OrgDb = paste0(msigdbr2org(enrichResult@organism), '.db'))
    
    ## Writing readable table
    write.table(enrichResult_readable@result, file = paste0(ora.dir, '/ORA.results_readable.tsv'), quote = FALSE, sep = "\t", row.names = FALSE)
    WriteXLS::WriteXLS(x = enrichResult_readable@result, ExcelFileName = paste0(ora.dir, '/ORA.results_readable.xlsx'), SheetNames = oname, AdjWidth = TRUE, AutoFilter = TRUE, BoldHeaderRow = TRUE, FreezeRow = 1, FreezeCol = 1, na = c(NA, 'NA', 'na', ''))
    
    ## Heatplot (needs readable)
    if (!is.null(heatplot) & !is.null(geneList)) {
      hp <- enrichplot::heatplot(enrichResult_readable, showCategory = heatplot, foldChange = geneList)
      pf <- paste0(ora.dir, '/ORA.heatplot.svg')
      ph <- ((min(length(which(ora.sig.tf)), heatplot) * 12) + 150)
      pw <- (min(5000, (5 * nrow(hp$data)) + 500))
      svg(filename = pf, width = pw/96, height = ph/96)
      print(hp)
      svg_off()
      # dev.off()
      # svg_convert(svg_files = pf, format = 'png', height = ph)
    }
    
    ## Dotplot // Barplot
    complot <- c()
    if (!is.null(dotplot)) complot <- c(complot, setNames(dotplot, 'clusterProfiler::dotplot'))
    if (!is.null(barplot)) complot <- c(complot, setNames(barplot, 'enrichplot:::barplot.enrichResult'))
    for (cx in seq_along(complot)) {
      func.split <- unlist(strsplit(names(complot)[cx], ':+'))
      plot.function <- base::get(func.split[2], envir = loadNamespace(func.split[1]))
      enrichResult_bak <- enrichResult
      enrichResult@result$Description <- gsub(pattern = '_', ' ', enrichResult@result$Description, fixed = TRUE)
      pf <- paste0(ora.dir, '/ORA.', func.split[2], '.svg')
      pw <- 1000
      ph <- ((min(length(which(ora.sig.tf)), unname(complot[cx])) * 20) + 300)
      svg(filename = pf, width = pw/96, height = ph/96)
      print(plot.function(enrichResult, showCategory = unname(complot[cx]), title = paste(c(comp.name, enrichResult@ontology, 'ORA'), collapse = "\n")) + ggplot2::scale_y_discrete(labels=function(x) stringr::str_wrap(x, width=100)))
      svg_off()
      # dev.off()
      # svg_convert(svg_files = pf, format = 'png', height = ph)
      enrichResult <- enrichResult_bak
      rm(enrichResult_bak)
    }
    ## KEGG pathview
    if (grepl(pattern = 'enrichKEGG', x = enrichResult@ontology) & !is.null(geneList)) {
      kegg.sp <- tolower(paste0(substr(unlist(strsplit(enrichResult@organism, ' ')), c(1, 1), c(1,2)), collapse = ''))
      kegg.dir <- paste0(ora.dir, '/KEGG_pathview/')
      dir.create(path = kegg.dir, recursive = TRUE)
      library(pathview)
      ori.dir <- getwd()
      setwd(dir = kegg.dir)
      for (x in which(enrichResult@result$p.adjust < enrichResult@pvalueCutoff)) {
        k_id <- enrichResult@result$ID[x]
        ## Custom geneList limited to our topN signature
        cur.geneList <- geneList[enrichResult@gene2Symbol]
        pf <- paste0(kegg.dir, '/', k_id, '.pathview.png')
        ptry <- try(suppressMessages(suppressWarnings(pathview::pathview(gene.data = cur.geneList, pathway.id = k_id, species = kegg.sp, limit = list(gene=lfc.min, cpd=1), low=list(gene = "red", cpr = "cornflowerblue"), mid = list(gene = "grey90", cpd = "grey90"), high = list(gene = "blue", cpd = "yellow"), kegg.dir = kegg.dir))), silent = TRUE)
        # if(!is(ptry, class2 = 'try-error')) {
        #   # svg_convert(svg_files = pf, format = 'png', height = 1100)
        # }
        torem <- paste0(kegg.dir, '/', k_id, '.', c('png', 'xml'))
        # torem <- paste0(kegg.dir, '/', k_id, '.', c('xml'))
        for (x in torem) { if (file.exists(x)) file.remove(x) }
        # if (file.exists(paste0(k_id, '.pathview.png'))) file.rename(from = paste0(k_id, '.pathview.png'), to = pf)
        
      }
      setwd(ori.dir)
    }
    
    if (!is.null(cnetplot)) {
      ## Cnetplot (need readable)
      p <- try(enrichplot::cnetplot(enrichResult_readable, showCategory = cnetplot, circular = FALSE, colorEdge = TRUE), silent = TRUE)
      if(!is(p, class2 = 'try-error')) {
        pf <- paste0(ora.dir, '/ORA.cnetplot_', cnetplot, '.svg')
        ph <- 2000
        pw <- 2000
        svg(filename = pf, width = pw/96, height = ph/96)
        try(print(p + ggplot2::scale_fill_continuous(guide = ggplot2::guide_legend()) + ggplot2::theme(legend.position="bottom")), silent = TRUE)
        svg_off()
        # dev.off()
        # svg_convert(svg_files = pf, format = 'png', height = ph)
      } else message(paste0('Error captured for cnetplot : \n"', p, '"'))
    }
    if (!is.null(emapplot)  & length(which(ora.sig.tf)) > 1) {
      ## Emapplot (need readable)
      p <- try(enrichplot::emapplot(enrichplot::pairwise_termsim(enrichResult_readable, showCategory = emapplot), showCategory = emapplot, layout = 'kk'), silent = TRUE)
      if(!is(p, class2 = 'try-error')) {
        pf <- paste0(ora.dir, '/ORA.emapplot_', emapplot, '.svg')
        ph <- 2000
        pw <- 2000
        svg(filename = pf, width = pw/96, height = ph/96)
        try(print(p + ggplot2::scale_fill_continuous(guide = ggplot2::guide_legend()) + ggplot2::theme(legend.position="bottom")), silent = TRUE) ## Can sometimes raise an error...
        svg_off()
        # dev.off()
        # svg_convert(svg_files = pf, format = 'png', height = ph)
      } else message(paste0('Error captured for emapplot : \n"', p, '"'))
      
    }
  } else message("No enriched term found.")
  
  if (!verbose) options(warn = 1)
  
}

## Aggregate different metrics from multiple DE_run() results ====
### . 'dea_path' :  char;     Path to one or multiple DEA_res output(s).
### . 'summarize' : logical;  If TRUE, returns an aggregated data.frame. If FALSE, a list
### . 'dea_legacy' :    logical;  If TRUE, the function will search for DEA results formatted as TSV. If FALSE, will search for XLSX.
### . 'gsea_legacy' :    logical;  If TRUE, the function will search for GSEA/ORA results formatted as TSV. If FALSE, will search for XLSX.

dea_aggregator <- function(dea_path = getwd(), summarize = TRUE, dea_legacy = FALSE, gsea_legacy = FALSE) {
  ## Checks
  if(!dir.exists(dea_path)) stop('A directory containing DEA_run() results is required !')
  ## Get input files
  if (dea_legacy) {
    res_files <- list.files(path = dea_path, pattern = '_results\\.tsv.*', recursive = TRUE, full.names = TRUE)
  } else {
    res_files <- list.files(path = dea_path, pattern = '_results\\.xlsx', recursive = TRUE, full.names = TRUE)
  }
  if(length(res_files) == 0) stop('No result file found for provided dea_path !')
  
  ## Loop on DEA files
  dea_agg <- lapply(seq_along(res_files), function(rf) {
    ## Get res dir
    split_dir <- rev(unname(unlist(strsplit(x = dirname(res_files[rf]), split = '/'))))
    ## Read DEA results
    if (dea_legacy) {
      res_df <- read.table(file = res_files[rf], header = TRUE, sep = '\t', as.is = TRUE)
    } else {
      res_df <- as.data.frame(readxl::read_excel(path = res_files[rf], sheet = 1, na = c(NA, 'NA', '')))
    }
    ## Get # significant genes
    nsig <- length(which(res_df[,ncol(res_df)] == 1))
    ## Get GSEA results
    if(gsea_legacy) {
      gsea_files <- list.files(path = dirname(res_files[rf]), pattern = 'GSEA.results_readable.tsv', full.names = TRUE, recursive = TRUE)
    } else {
      gsea_files <- list.files(path = dirname(res_files[rf]), pattern = 'GSEA.results_readable.xlsx', full.names = TRUE, recursive = TRUE)
    }
    ## Loop on GSEA files
    gsea_agg <- lapply(seq_along(gsea_files), function(gf) {
      ## Read DEA results
      if (gsea_legacy) {
        gres_df <- read.table(file = gsea_files[gf], header = TRUE, sep = '\t', as.is = TRUE)
      } else {
        gres_df <- as.data.frame(readxl::read_excel(path = gsea_files[gf], sheet = 1, na = c(NA, 'NA', '')))
      }
      return(nrow(gres_df))
    })
    names(gsea_agg) <- vapply(seq_along(gsea_files), function(gf) {
      ## Get gsea dir
      gsplit_dir <- rev(unname(unlist(strsplit(x = dirname(gsea_files[gf]), split = '/'))))
      return(gsub(pattern = 'GSEA_', replacement = '', x = paste(gsplit_dir[1:2], collapse = '.')))
    }, 'a')
    ## Get ORA results
    if(gsea_legacy) {
      ora_files <- list.files(path = dirname(res_files[rf]), pattern = 'ORA.results_readable.tsv', full.names = TRUE, recursive = TRUE)
    } else {
      ora_files <- list.files(path = dirname(res_files[rf]), pattern = 'ORA.results_readable.xlsx', full.names = TRUE, recursive = TRUE)
    }
    ## Loop on ORA files
    ora_agg <- lapply(seq_along(ora_files), function(of) {
      ## Read DEA results
      if (gsea_legacy) {
        ores_df <- read.table(file = ora_files[of], header = TRUE, sep = '\t', as.is = TRUE)
      } else {
        ores_df <- as.data.frame(readxl::read_excel(path = ora_files[of], sheet = 1, na = c(NA, 'NA', '')))
      }
      return(nrow(ores_df))
    })
    names(ora_agg) <- vapply(seq_along(ora_files), function(of) {
      ## Get gsea dir
      osplit_dir <- rev(unname(unlist(strsplit(x = dirname(ora_files[of]), split = '/'))))
      return(gsub(pattern = 'ORA_', replacement = '', x = paste(osplit_dir[1:2], collapse = '.')))
    }, 'a')
    
    ## OUTPUT
    # out_df <- data.frame(Path = dirname(res_files[rf]), Formula = split_dir[2], Comparison = split_dir[1], Sig_params = split_dir[3], Sig_features = nsig)
    out_df <- data.frame(Path = dirname(res_files[rf]), Formula = split_dir[3], Comparison = split_dir[2], Sig_params = split_dir[1], Sig_features = nsig)
    out_df
    return(list(DEA = out_df, GSEA = gsea_agg, ORA = ora_agg))
  })
  
  ## Summarize ?
  if(summarize) {
    message('Summarizing ...')
    ## DEA level
    dea_agg <- Reduce(f = rbind, x = lapply(seq_along(dres), function(x) { dres[[x]]$DEA }))
    sum_agg <- dea_agg
    ## GSEA_level {
    gsea_allbanks <- sort(unique(unlist(lapply(seq_along(dres), function(x) { names(dres[[x]]$GSEA) }))))
    if(length(gsea_allbanks) > 0) {
      gsea_agg <- matrix(0, nrow = length(dres), ncol = length(gsea_allbanks), dimnames = list(seq_along(dres), gsea_allbanks))
      for (x in seq_len(nrow(gsea_agg))) {
        for (bank in colnames(gsea_agg)) {
          if(bank %in% names(dres[[x]]$GSEA)) gsea_agg[x, bank] <- dres[[x]]$GSEA[[bank]]
        }
      }
      colnames(gsea_agg) <- paste0('GSEA_', colnames(gsea_agg))
      sum_agg <- cbind(sum_agg, gsea_agg)
    }
    ## ORA_level {
    ora_allbanks <- sort(unique(unlist(lapply(seq_along(dres), function(x) { names(dres[[x]]$ORA) }))))
    if(length(ora_allbanks) > 0) {
      ora_agg <- matrix(0, nrow = length(dres), ncol = length(ora_allbanks), dimnames = list(seq_along(dres), ora_allbanks))
      for (x in seq_len(nrow(ora_agg))) {
        for (bank in colnames(ora_agg)) {
          if(bank %in% names(dres[[x]]$ORA)) ora_agg[x, bank] <- dres[[x]]$ORA[[bank]]
        }
      }
      colnames(ora_agg) <- paste0('ORA_', colnames(ora_agg))
      sum_agg <- cbind(sum_agg, ora_agg)
    }
  } else {
    return(dea_agg)
  }
}


#..................#
#### BETA / WIP ####
#..................#


## Function to aggregate results from multiple differential analyses as a heatmap of the "top" features from each. Top selection can be TopN, Adjp threshold, quantile. The output is a clustered heatmap (mimicking the heatmap from Seurat for FindAllMarkers results)
## exp.mat                matrix(integer)     Sample x feature (gene) normalized expression matrix. Feature names as rownames.
## dea_res_list           list(data.frames)   List that contains the output table of multiple differential analyses (see diffexp_design)
## annot.df               data.frame          Sample annotations. Should contain a column with the same entries as colnames(exp.mat) and 
## selec_list             list()              List that contains the type of selection to perform on each DEA result
MultHeatMap <- function(exp_mat = NULL, dea_res_list = NULL, annot_df = NULL, selec_list = NULL, logFC_pos = FALSE) {
  
}


#................#
#### GSEA EXAMPLES ####
#................#

## . GSEA/ORA ====
# ## Setting variables
# defile <- '/home/job/WORKSPACE/B21002_DELE_01/B21002_DELE_01_dge/DGE/GSEAapp/Macrophage_type_compairing_Proinf_vs_Basal/Macrophage_type_compairing_Proinf_vs_Basal_complete.tsv'
# out.dir <- dirname(defile)
# comp.name <- basename(dirname(defile))
# species <- 'Homo sapiens'
# my.seed <- 1337L
# lfc.min <- 1
# de.min.p <- 5E-02
# enr.min.p <- 5E-02
# enr.min.genes <- 10
# topN <- 100
# 
# ## PREPARING INPUT (from a '*_complete.tsv' output table from our 'rna-salmon-deseq2' pipeline)
# enr.inputs <- pipe2enr(deseq2.res.file = defile, species = species, geneid.colname = 'Gene_Name', geneid.type = 'SYMBOL', value.colname = 'stat_change', topN.max = topN, topN.order.colname = 'Adjusted_PValue', topN.order.decreasing = FALSE, topN.cutoff = de.min.p, topN.keep.operator = '<')
# 
# ## .. MSIGDB ====
# ### Query any (and in this example, all) MsigDB banks available in the 'msigdbr' package. See http://www.gsea-msigdb.org/gsea/msigdb/collections.jsp
# ### Get available species / collections
# msigdb.collections <- as.data.frame(msigdbr::msigdbr_collections())
# msigdb.species <- as.data.frame(msigdbr::msigdbr_species())
# 
# ### GSEA
# for (x in seq_len(nrow(msigdb.collections))) {
#   my.collec <- unlist(msigdb.collections[x, c("gs_cat", "gs_subcat"), drop = TRUE])
#   ## Import the TERM2GENE object corresponding to the desired category/subcategory combo
#   my.t2g <- msigdb_to_t2g(species = species, category = my.collec[1], subcategory = my.collec[2])
#   my.t2g.name <- unname(if(my.collec[2] == '') my.collec[1] else paste(my.collec, collapse = "_"))
#   ## Run the GSEA
#   my.gsea.res <- gsea_run(geneList = enr.inputs$gsea.genevec, species = species, func.name = 'clusterProfiler::GSEA', t2g = my.t2g, t2g.name = my.t2g.name, gene2Symbol = enr.inputs$gene2Symbol, seed = my.seed, pvalueCutoff = enr.min.p, minGSSize = enr.min.genes)
#   ## Generate plots / outputs
#   gsea_output(gseaResult = my.gsea.res, out.dir = out.dir, comp.name = comp.name)
# }
# 
# ### ORA
# for (x in seq_len(nrow(msigdb.collections))) {
#   my.collec <- unlist(msigdb.collections[x, c("gs_cat", "gs_subcat"), drop = TRUE])
#   ## Import the TERM2GENE object corresponding to the desired category/subcategory combo
#   my.t2g <- msigdb_to_t2g(species = species, category = my.collec[1], subcategory = my.collec[2])
#   my.t2g.name <- ifelse(my.collec[2] == '', my.collec[1], paste(my.collec, collapse = "_"))
#   ## Run the ORA
#   my.ora.res <- ora_run(gene = enr.inputs$ora.genevec, species = species, func.name = 'clusterProfiler::enricher', t2g = my.t2g, t2g.name = my.t2g.name, gene2Symbol = enr.inputs$gene2Symbol, pvalueCutoff = enr.min.p, minGSSize = enr.min.genes)
#   ## Generate plots / outputs
#   ora_output(enrichResult = my.ora.res, out.dir = out.dir, comp.name = comp.name, geneList = enr.inputs$gsea.genevec)
# }
# 
# ## .. DO, NCG, DGN ====
# ## (Disease Ontology, Network of Cancer Genes, DisGeNET)
# ### WARNING : ONLY FOR 'Homo sapiens' !
# 
# ### GSEA
# for (x in c('DOSE::gseDO', 'DOSE::gseNCG', 'DOSE::gseDGN')) {
#   my.gsea.res <- gsea_run(geneList = enr.inputs$gsea.genevec, species = species, func.name = x, t2g = NULL, t2g.name = NULL, gene2Symbol = enr.inputs$gene2Symbol, seed = my.seed, pvalueCutoff = enr.min.p, minGSSize = enr.min.genes)
#   gsea_output(gseaResult = my.gsea.res, out.dir = out.dir, comp.name = comp.name)
# }
# 
# ### ORA
# for (x in c('DOSE::enrichDO', 'DOSE::enrichNCG', 'DOSE::enrichDGN')) {
#   my.ora.res <- ora_run(gene = enr.inputs$ora.genevec, species = species, func.name = x, t2g = NULL, t2g.name = NULL, gene2Symbol = enr.inputs$gene2Symbol, pvalueCutoff = enr.min.p, minGSSize = enr.min.genes)
#   ora_output(enrichResult = my.ora.res, out.dir = out.dir, comp.name = comp.name, geneList = enr.inputs$gsea.genevec)
# }
# 

# ## .. GO (Gene Ontology) ====
# ### This one needs some tweaking !
# 
### GSEA
# func.name <- 'clusterProfiler::gseGO'
# for (x in c('BP', 'CC', 'MF')) {
#   my.gsea.res <- gsea_run(geneList = enr.inputs$gsea.genevec, species = species, func.name = func.name, t2g = NULL, t2g.name = NULL, gene2Symbol = enr.inputs$gene2Symbol, seed = my.seed, pvalueCutoff = enr.min.p, minGSSize = enr.min.genes, OrgDb = get(paste0(msigdbr2org(species), '.db')), ont = x)
#   my.gsea.res@setType <- paste(c(my.gsea.res@setType, x), collapse = '_')
#   gsea_output(gseaResult = my.gsea.res, out.dir = out.dir, comp.name = comp.name)
#   ## Simplify
#   if(nrow(my.gsea.res) > 1) {
#     my.gsea.res@setType <- x
#     my.gsea.res <- enrichplot::pairwise_termsim(my.gsea.res)
#     my.gsea.res <- clusterProfiler::simplify(my.gsea.res, cutoff = 0.7, by = "p.adjust", select_fun = min)
#     my.gsea.res@setType <- paste(c(func.name, x, 'simplified'), collapse = '_')
#     gsea_output(gseaResult = my.gsea.res, out.dir = out.dir, comp.name = comp.name)
#   }
# }
# 
# ### ORA
# func.name <- 'clusterProfiler::enrichGO'
# for (x in c('BP', 'CC', 'MF')) {
#   my.ora.res <- ora_run(gene = enr.inputs$ora.genevec, species = species, func.name = func.name, t2g = NULL, t2g.name = NULL, gene2Symbol = enr.inputs$gene2Symbol, pvalueCutoff = enr.min.p, minGSSize = enr.min.genes, OrgDb = get(paste0(msigdbr2org(species), '.db')), ont = x)
#   my.ora.res@ontology <- paste(c(my.ora.res@ontology, x), collapse = '_')
#   ora_output(enrichResult = my.ora.res, out.dir = out.dir, comp.name = comp.name, geneList = enr.inputs$gsea.genevec)
#   ## Simplify
#   if(nrow(my.ora.res) > 1) {
#     my.ora.res@ontology <- x
#     my.ora.res <- enrichplot::pairwise_termsim(my.ora.res)
#     my.ora.res <- clusterProfiler::simplify(my.ora.res, cutoff = 0.7, by = "p.adjust", select_fun = min)
#     my.ora.res@ontology <- paste(c(func.name, x, 'simplified'), collapse = '_')
#     ora_output(enrichResult = my.ora.res, out.dir = out.dir, comp.name = comp.name, geneList = enr.inputs$gsea.genevec)
#   }
# }
# 

# ## .. WP (WikiPathways) ====
# ### GSEA
# func.name <- 'clusterProfiler::gseWP'
# my.gsea.res <- gsea_run(geneList = enr.inputs$gsea.genevec, organism = species, func.name = func.name, t2g = NULL, t2g.name = NULL, gene2Symbol = enr.inputs$gene2Symbol, seed = my.seed, pvalueCutoff = enr.min.p, minGSSize = enr.min.genes)
# gsea_output(gseaResult = my.gsea.res, out.dir = out.dir, comp.name = comp.name)
# ### ORA
# func.name <- 'clusterProfiler::enrichWP'
# my.ora.res <- ora_run(gene = enr.inputs$ora.genevec, organism = species, func.name = func.name, t2g = NULL, t2g.name = NULL, gene2Symbol = enr.inputs$gene2Symbol, pvalueCutoff = enr.min.p, minGSSize = enr.min.genes)
# ora_output(enrichResult = my.ora.res, out.dir = out.dir, comp.name = comp.name, geneList = enr.inputs$gsea.genevec)


# ## .. REACTOME ====
# reactome.org <- tolower(convert_species_name(OrgDb = get(paste0(msigdbr2org(species = species), '.db'))))
# ### GSEA
# func.name <- 'ReactomePA::gsePathway'
# my.gsea.res <- gsea_run(geneList = enr.inputs$gsea.genevec, organism = reactome.org, func.name = func.name, t2g = NULL, t2g.name = NULL, gene2Symbol = enr.inputs$gene2Symbol, seed = my.seed, pvalueCutoff = enr.min.p, minGSSize = enr.min.genes)
# my.gsea.res@setType <- paste0(func.name, '_Reactome')
# gsea_output(gseaResult = my.gsea.res, out.dir = out.dir, comp.name = comp.name)
# ### ORA
# func.name <- 'ReactomePA::enrichPathway'
# my.ora.res <- ora_run(gene = enr.inputs$ora.genevec, organism = reactome.org, func.name = func.name, t2g = NULL, t2g.name = NULL, gene2Symbol = enr.inputs$gene2Symbol, pvalueCutoff = enr.min.p, minGSSize = enr.min.genes)
# my.ora.res@ontology <- paste0(func.name, '_Reactome')
# ora_output(enrichResult = my.ora.res, out.dir = out.dir, comp.name = comp.name, geneList = enr.inputs$gsea.genevec)

# ## KEGG/MKEGG
# ### NOTE1 : It's the same way to call the 'gsea_run' / 'ora_run' as it is for 'DO', 'NCG' or 'DGN', but here it's compatible with many more species than homo sapiens.
# ### NOTE2 : for this case, additional KEGG pathway plots will be generated.
# ### NOTE3 : for this case, an internet connection is required to query the KEGG website.
# 
# ### GSEA
# for (x in c('clusterProfiler::gseKEGG', 'clusterProfiler::gseMKEGG')) {
#   my.gsea.res <- gsea_run(geneList = enr.inputs$gsea.genevec, species = species, func.name = x, t2g = NULL, t2g.name = NULL, gene2Symbol = enr.inputs$gene2Symbol, seed = my.seed, pvalueCutoff = enr.min.p, minGSSize = enr.min.genes)
#   gsea_output(gseaResult = my.gsea.res, out.dir = out.dir, comp.name = comp.name, lfc.min = lfc.min)
# }
# 
# ### ORA
# for (x in c('clusterProfiler::enrichKEGG', 'clusterProfiler::enrichMKEGG')) {
#   my.ora.res <- ora_run(gene = enr.inputs$ora.genevec, species = species, func.name = x, t2g = NULL, t2g.name = NULL, gene2Symbol = enr.inputs$gene2Symbol, pvalueCutoff = enr.min.p, minGSSize = enr.min.genes)
#   ora_output(enrichResult = my.ora.res, out.dir = out.dir, comp.name = comp.name, geneList = enr.inputs$gsea.genevec, lfc.min = lfc.min)
# }
# 
# 
# ## CELLMARKER
# ### Assess cell types from an online table
# ### NOTE : It's the same way to call the 'gsea_run' / 'ora_run' functions as for MSIGDB, but with a single bank (so, no loop).
# 
# ### Import the CellMarker bank
# `%>%` <- dplyr::`%>%`
# cell_markers <- vroom::vroom('http://bio-bigdata.hrbmu.edu.cn/CellMarker/download/Human_cell_markers.txt') %>% tidyr::unite("cellMarker", tissueType, cancerType, cellName, sep=", ") %>% dplyr::select(cellMarker, geneID) %>% dplyr::mutate(geneID = strsplit(geneID, ', '))
# 
# ### GSEA
# my.gsea.res <- gsea_run(geneList = enr.inputs$gsea.genevec, species = species, func.name = 'clusterProfiler::GSEA', t2g = cell_markers, t2g.name = 'CellMarker', gene2Symbol = enr.inputs$gene2Symbol, seed = my.seed, pvalueCutoff = enr.min.p, minGSSize = enr.min.genes)
# gsea_output(gseaResult = my.gsea.res, out.dir = out.dir, comp.name = comp.name)
# 
# #### ORA
# my.ora.res <- ora_run(gene = enr.inputs$ora.genevec, species = species, func.name = 'clusterProfiler::enricher', t2g = cell_markers, t2g.name = 'CellMarkers', gene2Symbol = enr.inputs$gene2Symbol, pvalueCutoff = enr.min.p, minGSSize = enr.min.genes)
# ora_output(enrichResult = my.ora.res, out.dir = out.dir, comp.name = comp.name, geneList = enr.inputs$gsea.genevec)

# 
# ## MESH (WARNING : MEMORY OGRE AND SLOW !! Big DBs, 3 sources, 16 categories ! 64 GB of RAM required for most bases !
# ### Requires additional parameters :
# ### . 'MeSHDb' : character ; name of a MeSH [NO : AUTO FROM SPECIES NAME]
# ### . 'database' : character ; MeSH source type (can be 'gendoo' = text-mining, 'gene2pubmed' = manual curation by NCBI team, 'RBBH' = sequence homology with BLASTP search @ E-value < 1E-50)
# ### . 'category' : character ; name of a MeSH category sub-db (namely 'A', 'B', 'C', 'D', 'G').
# ### NOTE : see https://yulab-smu.top/biomedical-knowledge-mining-book/meshes-semantic-similarity.html
# 
# ### List of requested MeSH DBs
# mesh.dbs <- c('gendoo', 'gene2pubmed', 'RBBH') ## 'RBBH' is not available for Homo sapiens.
# ### List of requested MeSH categories
# mesh.categories <- toupper(letters[-c(15:21,23:25)]) ## More categories are available, but some do not seem to work with Homo sapiens for some of the DBs.
# ### Building the MeSH package name corresponding to the current species
# mesh.sp <- paste0(c('MeSH.', substr(unlist(strsplit(species, ' ')), c(1, 1), c(1,2)), '.eg.db'), collapse = '')
# ### Checking which MeSH DBs are available for the current species.
# mesh.dbs <- MeSHDbi::listDatabases(eval(parse(text = paste0(mesh.sp, '::', mesh.sp))))[,1]
# 
# ### ORA
# #### WARNING !! the 'gene2pubmed' requires a lot of RAM (~12 GB) !!
# mesh.func.name <- 'meshes::enrichMeSH'
# for (y in mesh.dbs) {
#   for (x in mesh.categories) {
#     message(paste0(y, ' ', x))
#     if (y %in% mesh.dbs) {
#       my.ora.res <- ora_run(gene = enr.inputs$ora.genevec, species = species, func.name = mesh.func.name, t2g = NULL, t2g.name = NULL, gene2Symbol = enr.inputs$gene2Symbol, pvalueCutoff = enr.min.p, minGSSize = enr.min.genes, database = y, category = x)
#       if(!is(my.ora.res, class2 = 'try-error')) {
#         ## Little hack specific to MeSH results (as I was not able to get the value of extra parameters 'database' and 'category' from within the 'gsea_run()' function)
#         my.ora.res@ontology <- paste(c(mesh.func.name, y, x), collapse = '_')
#         ora_output(enrichResult = my.ora.res, out.dir = out.dir, comp.name = comp.name, geneList = enr.inputs$gsea.genevec)
#       }
#     } else message(paste0("Unsupported MeSH database '", y, "'. Expecting one of : '", paste(mesh.dbs, collapse = "', '"), "'."))
#   }
# }
# 
# 
# ### GSEA
# #### WARNING !! Needs too much memory for a laptop (probably over 64 GB of RAM, easily...). SO, not recommended out of flamingo.
# mesh.func.name <- 'meshes::gseMeSH'
# for (y in mesh.dbs) {
#   for (x in mesh.categories) {
#     message(paste0(y, ' ', x))
#     if (y %in% mesh.dbs) {
#       my.gsea.res <- try(gsea_run(geneList = enr.inputs$gsea.genevec, species = species, func.name = mesh.func.name, t2g = NULL, t2g.name = NULL, gene2Symbol = enr.inputs$gene2Symbol, seed = my.seed, pvalueCutoff = enr.min.p, minGSSize = enr.min.genes, database = y, category = x), silent = TRUE)
#       if (!is(my.gsea.res, class2 = 'try-error')) {
#         ## Little hack specific to MeSH results (as I was not able to get the value of extra parameters 'database' and 'category' from within the 'gsea_run()' function)
#         my.gsea.res@setType <- paste(c(mesh.func.name, y, x), collapse = '_')
#         gsea_output(gseaResult = my.gsea.res, out.dir = out.dir, comp.name = comp.name)
#       }
#     } else message(paste0("Unsupported MeSH database '", y, "'. Expecting one of : '", paste(mesh.dbs, collapse = "', '"), "'."))
#   }
# }

# ## .. Custom GMT ====