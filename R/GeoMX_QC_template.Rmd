---
title: "BIGRCODE GeoMX RTxxx.xx QC (RNA)"
author: "Firstname LASTNAME<BR>anyone@gustaveroussy.fr"
date: "`r format(Sys.time(), '%Y/%m/%d')`"
output:
  html_document: 
    background: black
    fig_height: 10
    fig_width: 15
    highlight: tango  ## Theme for the code chunks
    number_sections: true  ## Adds number to headers (sections)
    theme: flatly  ## CSS theme for the HTML page
    toc: true  ## Adds a table of content
    toc_float:  ## TOC options
      collapsed: true  ## By default, the TOC is folded
    smooth_scroll: true ## Smooth scroll of the HTML page
    self_contained: true ## Includes all plots/images within the HTML
    code_download: true ## Adds a button to download the Rmd
    code_folding: show
    thumbnails: false
    lightbox: true
    fig_caption: false
    gallery: true
    use_bookdown: true
always_allow_html: true ## Allow plain HTML code in the Rmd
---

# Working environment setup

## Variables

```{r setup_var, message = FALSE}

## DIRECTORIES / INPUT FILES

### DIR : Main rootname (project dir)
root_dir <- '~'

### INPUT : GeoMX DSP output(s) (MS XLSX) after background correction. Can be a vector of characters, each a path to a DSP output file.
input_table_files <- c('')

### INPUT : Optional additional sample annotation (MS XLSX) file path. It has to be synched (same length, same sample names, same order) with the annotations from the DSP output, and first column has to be the same as this output column "SegmentDisplayName". Keep as NULL if no file to provide
annot_filename <- NULL


## OTHER PARAMETERS

### Analysis tag name
analysis_name <- 'My_analysis'

### LIST of CATEGORICAL/DISCRETE data types to enlight (by split/coloring) in plots, and assess as covariates. Keys are displayed names, values are annotation table column names
box_categ <- list(
  'Cell Type' = 'SegmentLabel'
  , 'Slide' = 'SlideName'
  , 'Batch' = 'Batch'
  , 'ROI' = 'ROILabel'
  , 'AOI' = 'AOILabel'
  , 'ROI Comments' = 'ROIComments'
)

## FLAGS to use to filter bad profiles out (should be filled after QC analysis)
flags_to_use <- c('QC_Low_Raw_Reads', 'OL_sparsity', 'OL_AQM_NORM_boxplot')



## BASIC PARAMETERS

### ANNOTATION : sample names column
annot_sn <- 'SegmentDisplayName'
### Number of max different distant colors to generate in the RGB space, for boxplots/PCAs (should cover all possible classes in any of the requested annotation)
ncolors <- 20
### Fixing seed
my_seed <- 1337
### Residual value to add for raw counts to log conversion 
epsilon <- 1
### Maximal sparsity level (by default 50%)
sparse_max <- .5
### DESeq2 normalization method (only VST supported yet)
norm_method <- 'vst'

```

## Setup

```{r setup_set, message = FALSE}

## Sourcing outside scripts (for plotting/DEA/GSEA functions)
source("/home/job/gits/customscripts/R/RNA_functions.R")

## Clean annotations colname variables
box_categ <- lapply(box_categ, function(x) gsub(pattern = "\\W", replacement = '.', x = x))
flags_to_use <- lapply(flags_to_use, function(x) gsub(pattern = "\\W", replacement = '.', x = x))


### Results output dir
out_dir <- paste0(root_dir, '/RESULTS')

## Generate a color palette
listcol <- distinct_color_maker(n_colors = ncolors, my_seed = my_seed)

## Early setup (folders)
analysis_name <- paste(c(analysis_name, format(Sys.time(), '%Y%m%d%H%M%S')), collapse = '_')
work_dir <- paste(c(out_dir, analysis_name, 'QC'), collapse = '/')
dir.create(work_dir, recursive = TRUE)
setwd(work_dir)

## Backup original graphical parameters
oripar <- par(no.readonly = TRUE)

```


## Loading data

```{r data_load}

## Load count data
geo_data <- geomx_xlsx_parser(geomx_files = input_table_files, split_qcflags = TRUE, qcflags_colname = 'QCFlags', batch_colname = 'Batch', add_aoilabel = TRUE)

## Sample names
colnames(geo_data$TargetCountMatrix)

## Annotations+QC (segment properties)
annot_df <- geo_data$SegmentProperties
rownames(annot_df) <- annot_df$SegmentDisplayName
colnames(annot_df)
table(annot_df$SegmentLabel)

## Clean colnames
colnames(annot_df) <- gsub(pattern = "\\W", replacement = '.', x = colnames(annot_df))

## Load additional annotations (needs to be synched with the current annot_df). WARNING : except for the annot_sn common column name, any column name in the additional table which is already present in the initial one will REPLACE the initial one !
if (!is.null(annot_filename)) {
  comp_df <- as.data.frame(readxl::read_excel(path =  annot_filename, na = c('', 'na', 'NA')))
  ## Clean colnames
  colnames(comp_df) <- gsub(pattern = "\\W", replacement = '.', x = colnames(comp_df))
  ## Test if both tables have the merging column
  if (all(annot_df[[annot_sn]] == comp_df[[annot_sn]])) {
    ## Looking for common column names
    com_colz <- colnames(comp_df)[colnames(comp_df) %in% colnames(annot_df)]
    ## Removing the obvious one
    com_colz <- com_colz[-c(which(com_colz == annot_sn))]
    ## If there are, remove them from the initial table
    if (length(com_colz) > 0) annot_df <- annot_df[,-c(which(colnames(annot_df) %in% com_colz))]
    ## Merge tables
    annot_df <- merge(x = annot_df, comp_df, by = annot_sn)
    rownames(annot_df) <- annot_df[[annot_sn]]
  } else stop('Initial and additional annotation tables are NOT synched !')
}

## Convert box_categ entries to factors
for (bcfac in box_categ) annot_df[[bcfac]] <- as.factor(annot_df[[bcfac]])

## Write out the prepped annot/QC table
qc_filename <- paste0(work_dir, '/', analysis_name, '_AnnotQC.xlsx')
writexl::write_xlsx(x = annot_df, path = qc_filename, format_headers = TRUE)


## Clean QC flag columns & add QC columns to the box_categ list
qc_cols <- grep(pattern = '^QC_', x = colnames(annot_df), ignore.case = FALSE, value = TRUE)
if (length(qc_cols) > 0) {
  for (qcc in qc_cols) {
    annot_df[[qcc]] <- as.logical(annot_df[[qcc]])
    box_categ[[qcc]] <- qcc
  }
}

## Synch
### Convert counts df to matrix
geo_int <- geo_data$TargetCountMatrix
### Samples (initial)
ini_nsamp <- ncol(geo_int)
### Sort data by ROI/AOI names
geo_int <- geo_int[, order(colnames(geo_int))]
### Sort annotation by ROI/AOI names
annot_df <- annot_df[order(annot_df[[annot_sn]]),]
### Restrict data
geo_int <- geo_int[,colnames(geo_int) %in% annot_df[[annot_sn]]]
### Restrict annotation
annot_df <- annot_df[annot_df[[annot_sn]] %in% colnames(geo_int),]
### Check
all(colnames(geo_int) == annot_df[[annot_sn]])
### Samples
ncol(geo_int) == ini_nsamp

```


# Data preprocessing

* Converting counts data to log10(+1).

```{r countmat}

## Correct for false 1
geo_int <- round(geo_int) - 1
saveRDS(geo_int, file = paste0(work_dir, '/rawcounts_', ncol(geo_int), 's.RDS'), compress = 'bzip2')

## Log10 transformation
geo_l10 <- raw2log(x = geo_int, log_base = 10, epsilon = epsilon)
saveRDS(geo_l10, file = paste0(work_dir, '/l10counts', epsilon, '_', ncol(geo_l10), 's.RDS'), compress = 'bzip2')

```


# RAW QC

## Sample-level sparsity

Here we check the sparsity level (the amount of 0-counts) for each sample.

```{r raw_sparsity}
ms <- matrix_sparsity(mat = geo_int)
## Get outliers
annot_df$OL_sparsity <- ms$columns > sparse_max
## Add outliers to QC flags
if (any(annot_df$OL_sparsity)) box_categ[['OL : Sparsity']] <- 'OL_sparsity'
table(annot_df$OL_sparsity)
## Plot
plot(ms$columns, type = 'b', xaxs = 'i', ylim = c(0,1.1), pch = '.', cex = 4, xaxt = 'n', xlab = 'Samples', yaxs = 'i', ylab = 'Sparsity level', main = 'Sample-level sparsity')
points(which(annot_df$OL_sparsity), ms$columns[annot_df$OL_sparsity], pch = 20, col = 'brown')
abline(h = c(ms$global, sparse_max), lty = 3, col = c(4,2), lwd = 3)
```

*Conclusion* :

* Lorem.
* Ipsum.
* Dolor.

## Boxplots

Boxplots of log-transformed raw counts (ie, log10(counts+1)) for control types and expression data.

```{r raw_boxp, message=FALSE}


## RAW Boxplots
for (bc in seq_along(box_categ))categ.boxplot(x = geo_l10, annot_df = annot_df, col_item = box_categ[[bc]], title = names(box_categ)[bc], y_lab = "Raw counts (log10)", my_seed = my_seed)

```

*Conclusion* :

* Lorem.
* Ipsum.
* Dolor.

## Array Quality Metrics

```{r aqm_raw}
## Handling null samples (samples with NO read)
geo_temp <- geo_int
ncount <- colSums(geo_temp)
geo_temp[,ncount == 0] <- 1

aqm_tag <- 'AQM_RAW'
aqmR_dir <- paste(c(work_dir, aqm_tag), collapse = '/')
dir.create(path = aqmR_dir, recursive = TRUE)
annot_df <- AQM_run(mat = geo_temp, pheno_df = annot_df, pheno_colnames = unname(unlist(box_categ)), to_log = FALSE, title = aqm_tag, out_dir = aqmR_dir, save_results = FALSE)

aqm_mods <- c('heatmap', 'boxplot', 'pca', 'density', 'meansd', 'maplot')
for (am in aqm_mods) {
  ol_tag <- paste(c('OL', aqm_tag, am), collapse = '_')
  if(any(annot_df[[ol_tag]])) {
    message(am)
    rownames(annot_df)[annot_df[[ol_tag]]]
  }
}

```

*Conclusion* :

* Lorem.
* Ipsum.
* Dolor.


# Normalization

Expression is first normalized by computing scaling factors, taking care of batch, then using variance stabilization.

The method used is :

```{r normmethod}
norm_method
```


```{r norm, message=FALSE}
## Convert matrix to DESeqDataSet
de2 <- DESeq2::DESeqDataSetFromMatrix(countData = geo_temp, colData = annot_df, design = ~0)
## Computing size factors and dispersion
try(de2 <- DESeq2::estimateSizeFactors(object = de2))
saveRDS(de2, file = paste0(work_dir, '/DESeq2Obj_Raw.RDS'), compress = 'bzip2')
## Normalization
if (tolower(norm_method) == 'vst') {
  message('Normalizing using vst ...')
  de2.norm <- DESeq2::vst(object = de2, blind = TRUE, nsub = 200)
} else if (tolower(norm_method) == 'rlog') {
  message('Normalizing using rlog ...')
  de2.norm <- DESeq2::rlog(object = de2, blind = TRUE)
}
## Extract the normalized matrix
geo_norm <- SummarizedExperiment::assay(de2.norm, normalized = TRUE)
## Save it
saveRDS(de2.norm, file = paste0(work_dir, '/DESeq2Obj_Norm.', tolower(norm_method), '.RDS'), compress = 'bzip2')
## Add the sizeFactor as a new sample annotation
annot_df$sizeFactor <- de2.norm$sizeFactor
```

# Norm QC

## Boxplot

Boxplot of normalized expression, after normalisation.

```{r norm_boxp, message=FALSE}
## NORM Boxplot
for (bc in seq_along(box_categ))categ.boxplot(x = geo_norm, annot_df = annot_df, col_item = box_categ[[bc]], title = names(box_categ)[bc], y_lab = "Normalized counts", my_seed = my_seed)
```

*Conclusion* :

* Lorem.
* Ipsum.
* Dolor.

## Array Quality Metrics

```{r aqm_norm}
aqm_tag <- 'AQM_NORM'
aqmN_dir <- paste(c(work_dir, aqm_tag), collapse = '/')
dir.create(path = aqmN_dir, recursive = TRUE)
annot_df <- AQM_run(mat = geo_norm, pheno_df = annot_df, pheno_colnames = unname(unlist(box_categ)), to_log = FALSE, title = aqm_tag, out_dir = aqmN_dir, save_results = FALSE)

aqm_mods <- c('heatmap', 'boxplot', 'pca', 'density', 'meansd', 'maplot')
for (am in aqm_mods) {
  ol_tag <- paste(c('OL', aqm_tag, am), collapse = '_')
  if(any(annot_df[[ol_tag]])) {
    message(am)
    rownames(annot_df)[annot_df[[ol_tag]]]
  }
}

```

*Conclusion* :

* Lorem.
* Ipsum.
* Dolor.

## PCA

PCA is used to evaluate how the data dimensionality could be reduced from our multiple samples. Working on human data, we do not expect by default a high representation of the variance by a very limited set of very first components. It is also used to detect outlying samples, and in best cases gives ideas of the data structure (ie, most evident clusters).

```{r pca, message=FALSE}
## PCAs on normalized assay
for (bc in names(box_categ)) {
  de2.pca.batch <- DESeq2::plotPCA(de2.norm, intgroup = box_categ[[bc]])
  print(de2.pca.batch + ggplot2::geom_point(data = data.frame(PC1 = get_medoid(x = de2.pca.batch$data$PC1, split = de2.pca.batch$data$group), PC2 = get_medoid(x = de2.pca.batch$data$PC2, split = de2.pca.batch$data$group), group = unique(de2.pca.batch$data$group)), shape = 13, size = 8) + ggplot2::labs(title = bc))
}

```

*Conclusion* :

* Lorem.
* Ipsum.
* Dolor.

# Outlier filtering

Here we will filter outlying samples thanks to the multiple metrics we generated

```{r qc_filt}

samples_keep <- unname(!matrixStats::rowAnys(as.matrix(annot_df[,flags_to_use])))

## Discarded sample(s)
colnames(geo_norm)[!samples_keep]

```

*Conclusion* :

* Lorem.
* Ipsum.
* Dolor.

# Saving

```{r}

out.de2 <- DESeq2::DESeqDataSetFromMatrix(countData = geo_int[,samples_keep], colData = annot_df[samples_keep,], design = ~0)
saveRDS(object = out.de2, file = paste0(work_dir, '/Raw_outlier.filtered_', length(which(samples_keep)), 's.RDS'), compress = 'bzip2')

```

# Rsession

```{r sessioninfo}

sessionInfo()

```
